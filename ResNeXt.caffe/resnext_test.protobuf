layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  transform_param {
    crop_size: 28
    mean_file: "../CIFAR10/mean.binaryproto"
  }
  data_param {
    source: "../CIFAR10/cifar10_test_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Convolution3"
  top: "Convolution3"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution4"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Convolution5"
  top: "Convolution5"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution6"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Convolution7"
  top: "Convolution7"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution8"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution10"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution12"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution14"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Convolution15"
  top: "Convolution15"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution16"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Convolution17"
  top: "Convolution17"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution18"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Convolution19"
  top: "Convolution19"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution20"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution22"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Convolution22"
  top: "Convolution23"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Convolution23"
  top: "Convolution23"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution24"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Convolution25"
  top: "Convolution25"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution26"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Convolution27"
  top: "Convolution27"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution28"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Convolution29"
  top: "Convolution29"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution30"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution30"
  top: "Convolution30"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "Convolution31"
  top: "Convolution31"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution32"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
  bottom: "Convolution32"
  top: "Convolution32"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale32"
  type: "Scale"
  bottom: "Convolution32"
  top: "Convolution32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU32"
  type: "ReLU"
  bottom: "Convolution32"
  top: "Convolution32"
}
layer {
  name: "Convolution33"
  type: "Convolution"
  bottom: "Convolution32"
  top: "Convolution33"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm33"
  type: "BatchNorm"
  bottom: "Convolution33"
  top: "Convolution33"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale33"
  type: "Scale"
  bottom: "Convolution33"
  top: "Convolution33"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "Convolution33"
  top: "Convolution33"
}
layer {
  name: "Convolution34"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution34"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm34"
  type: "BatchNorm"
  bottom: "Convolution34"
  top: "Convolution34"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale34"
  type: "Scale"
  bottom: "Convolution34"
  top: "Convolution34"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "Convolution34"
  top: "Convolution34"
}
layer {
  name: "Convolution35"
  type: "Convolution"
  bottom: "Convolution34"
  top: "Convolution35"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm35"
  type: "BatchNorm"
  bottom: "Convolution35"
  top: "Convolution35"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale35"
  type: "Scale"
  bottom: "Convolution35"
  top: "Convolution35"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU35"
  type: "ReLU"
  bottom: "Convolution35"
  top: "Convolution35"
}
layer {
  name: "Convolution36"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution36"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm36"
  type: "BatchNorm"
  bottom: "Convolution36"
  top: "Convolution36"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale36"
  type: "Scale"
  bottom: "Convolution36"
  top: "Convolution36"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU36"
  type: "ReLU"
  bottom: "Convolution36"
  top: "Convolution36"
}
layer {
  name: "Convolution37"
  type: "Convolution"
  bottom: "Convolution36"
  top: "Convolution37"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm37"
  type: "BatchNorm"
  bottom: "Convolution37"
  top: "Convolution37"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale37"
  type: "Scale"
  bottom: "Convolution37"
  top: "Convolution37"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU37"
  type: "ReLU"
  bottom: "Convolution37"
  top: "Convolution37"
}
layer {
  name: "Convolution38"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution38"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm38"
  type: "BatchNorm"
  bottom: "Convolution38"
  top: "Convolution38"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale38"
  type: "Scale"
  bottom: "Convolution38"
  top: "Convolution38"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU38"
  type: "ReLU"
  bottom: "Convolution38"
  top: "Convolution38"
}
layer {
  name: "Convolution39"
  type: "Convolution"
  bottom: "Convolution38"
  top: "Convolution39"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm39"
  type: "BatchNorm"
  bottom: "Convolution39"
  top: "Convolution39"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale39"
  type: "Scale"
  bottom: "Convolution39"
  top: "Convolution39"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU39"
  type: "ReLU"
  bottom: "Convolution39"
  top: "Convolution39"
}
layer {
  name: "Convolution40"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution40"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm40"
  type: "BatchNorm"
  bottom: "Convolution40"
  top: "Convolution40"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale40"
  type: "Scale"
  bottom: "Convolution40"
  top: "Convolution40"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU40"
  type: "ReLU"
  bottom: "Convolution40"
  top: "Convolution40"
}
layer {
  name: "Convolution41"
  type: "Convolution"
  bottom: "Convolution40"
  top: "Convolution41"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm41"
  type: "BatchNorm"
  bottom: "Convolution41"
  top: "Convolution41"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale41"
  type: "Scale"
  bottom: "Convolution41"
  top: "Convolution41"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU41"
  type: "ReLU"
  bottom: "Convolution41"
  top: "Convolution41"
}
layer {
  name: "Convolution42"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution42"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm42"
  type: "BatchNorm"
  bottom: "Convolution42"
  top: "Convolution42"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale42"
  type: "Scale"
  bottom: "Convolution42"
  top: "Convolution42"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU42"
  type: "ReLU"
  bottom: "Convolution42"
  top: "Convolution42"
}
layer {
  name: "Convolution43"
  type: "Convolution"
  bottom: "Convolution42"
  top: "Convolution43"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm43"
  type: "BatchNorm"
  bottom: "Convolution43"
  top: "Convolution43"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale43"
  type: "Scale"
  bottom: "Convolution43"
  top: "Convolution43"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU43"
  type: "ReLU"
  bottom: "Convolution43"
  top: "Convolution43"
}
layer {
  name: "Convolution44"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution44"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm44"
  type: "BatchNorm"
  bottom: "Convolution44"
  top: "Convolution44"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale44"
  type: "Scale"
  bottom: "Convolution44"
  top: "Convolution44"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU44"
  type: "ReLU"
  bottom: "Convolution44"
  top: "Convolution44"
}
layer {
  name: "Convolution45"
  type: "Convolution"
  bottom: "Convolution44"
  top: "Convolution45"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm45"
  type: "BatchNorm"
  bottom: "Convolution45"
  top: "Convolution45"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale45"
  type: "Scale"
  bottom: "Convolution45"
  top: "Convolution45"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU45"
  type: "ReLU"
  bottom: "Convolution45"
  top: "Convolution45"
}
layer {
  name: "Convolution46"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution46"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm46"
  type: "BatchNorm"
  bottom: "Convolution46"
  top: "Convolution46"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale46"
  type: "Scale"
  bottom: "Convolution46"
  top: "Convolution46"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU46"
  type: "ReLU"
  bottom: "Convolution46"
  top: "Convolution46"
}
layer {
  name: "Convolution47"
  type: "Convolution"
  bottom: "Convolution46"
  top: "Convolution47"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm47"
  type: "BatchNorm"
  bottom: "Convolution47"
  top: "Convolution47"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale47"
  type: "Scale"
  bottom: "Convolution47"
  top: "Convolution47"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU47"
  type: "ReLU"
  bottom: "Convolution47"
  top: "Convolution47"
}
layer {
  name: "Convolution48"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution48"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm48"
  type: "BatchNorm"
  bottom: "Convolution48"
  top: "Convolution48"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale48"
  type: "Scale"
  bottom: "Convolution48"
  top: "Convolution48"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU48"
  type: "ReLU"
  bottom: "Convolution48"
  top: "Convolution48"
}
layer {
  name: "Convolution49"
  type: "Convolution"
  bottom: "Convolution48"
  top: "Convolution49"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm49"
  type: "BatchNorm"
  bottom: "Convolution49"
  top: "Convolution49"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale49"
  type: "Scale"
  bottom: "Convolution49"
  top: "Convolution49"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU49"
  type: "ReLU"
  bottom: "Convolution49"
  top: "Convolution49"
}
layer {
  name: "Convolution50"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution50"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm50"
  type: "BatchNorm"
  bottom: "Convolution50"
  top: "Convolution50"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale50"
  type: "Scale"
  bottom: "Convolution50"
  top: "Convolution50"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU50"
  type: "ReLU"
  bottom: "Convolution50"
  top: "Convolution50"
}
layer {
  name: "Convolution51"
  type: "Convolution"
  bottom: "Convolution50"
  top: "Convolution51"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm51"
  type: "BatchNorm"
  bottom: "Convolution51"
  top: "Convolution51"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale51"
  type: "Scale"
  bottom: "Convolution51"
  top: "Convolution51"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU51"
  type: "ReLU"
  bottom: "Convolution51"
  top: "Convolution51"
}
layer {
  name: "Convolution52"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution52"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm52"
  type: "BatchNorm"
  bottom: "Convolution52"
  top: "Convolution52"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale52"
  type: "Scale"
  bottom: "Convolution52"
  top: "Convolution52"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU52"
  type: "ReLU"
  bottom: "Convolution52"
  top: "Convolution52"
}
layer {
  name: "Convolution53"
  type: "Convolution"
  bottom: "Convolution52"
  top: "Convolution53"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm53"
  type: "BatchNorm"
  bottom: "Convolution53"
  top: "Convolution53"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale53"
  type: "Scale"
  bottom: "Convolution53"
  top: "Convolution53"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU53"
  type: "ReLU"
  bottom: "Convolution53"
  top: "Convolution53"
}
layer {
  name: "Convolution54"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution54"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm54"
  type: "BatchNorm"
  bottom: "Convolution54"
  top: "Convolution54"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale54"
  type: "Scale"
  bottom: "Convolution54"
  top: "Convolution54"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU54"
  type: "ReLU"
  bottom: "Convolution54"
  top: "Convolution54"
}
layer {
  name: "Convolution55"
  type: "Convolution"
  bottom: "Convolution54"
  top: "Convolution55"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm55"
  type: "BatchNorm"
  bottom: "Convolution55"
  top: "Convolution55"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale55"
  type: "Scale"
  bottom: "Convolution55"
  top: "Convolution55"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU55"
  type: "ReLU"
  bottom: "Convolution55"
  top: "Convolution55"
}
layer {
  name: "Convolution56"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution56"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm56"
  type: "BatchNorm"
  bottom: "Convolution56"
  top: "Convolution56"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale56"
  type: "Scale"
  bottom: "Convolution56"
  top: "Convolution56"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU56"
  type: "ReLU"
  bottom: "Convolution56"
  top: "Convolution56"
}
layer {
  name: "Convolution57"
  type: "Convolution"
  bottom: "Convolution56"
  top: "Convolution57"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm57"
  type: "BatchNorm"
  bottom: "Convolution57"
  top: "Convolution57"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale57"
  type: "Scale"
  bottom: "Convolution57"
  top: "Convolution57"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU57"
  type: "ReLU"
  bottom: "Convolution57"
  top: "Convolution57"
}
layer {
  name: "Convolution58"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution58"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm58"
  type: "BatchNorm"
  bottom: "Convolution58"
  top: "Convolution58"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale58"
  type: "Scale"
  bottom: "Convolution58"
  top: "Convolution58"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU58"
  type: "ReLU"
  bottom: "Convolution58"
  top: "Convolution58"
}
layer {
  name: "Convolution59"
  type: "Convolution"
  bottom: "Convolution58"
  top: "Convolution59"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm59"
  type: "BatchNorm"
  bottom: "Convolution59"
  top: "Convolution59"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale59"
  type: "Scale"
  bottom: "Convolution59"
  top: "Convolution59"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU59"
  type: "ReLU"
  bottom: "Convolution59"
  top: "Convolution59"
}
layer {
  name: "Convolution60"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution60"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm60"
  type: "BatchNorm"
  bottom: "Convolution60"
  top: "Convolution60"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale60"
  type: "Scale"
  bottom: "Convolution60"
  top: "Convolution60"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU60"
  type: "ReLU"
  bottom: "Convolution60"
  top: "Convolution60"
}
layer {
  name: "Convolution61"
  type: "Convolution"
  bottom: "Convolution60"
  top: "Convolution61"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm61"
  type: "BatchNorm"
  bottom: "Convolution61"
  top: "Convolution61"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale61"
  type: "Scale"
  bottom: "Convolution61"
  top: "Convolution61"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU61"
  type: "ReLU"
  bottom: "Convolution61"
  top: "Convolution61"
}
layer {
  name: "Convolution62"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution62"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm62"
  type: "BatchNorm"
  bottom: "Convolution62"
  top: "Convolution62"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale62"
  type: "Scale"
  bottom: "Convolution62"
  top: "Convolution62"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU62"
  type: "ReLU"
  bottom: "Convolution62"
  top: "Convolution62"
}
layer {
  name: "Convolution63"
  type: "Convolution"
  bottom: "Convolution62"
  top: "Convolution63"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm63"
  type: "BatchNorm"
  bottom: "Convolution63"
  top: "Convolution63"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale63"
  type: "Scale"
  bottom: "Convolution63"
  top: "Convolution63"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU63"
  type: "ReLU"
  bottom: "Convolution63"
  top: "Convolution63"
}
layer {
  name: "Convolution64"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution64"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm64"
  type: "BatchNorm"
  bottom: "Convolution64"
  top: "Convolution64"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale64"
  type: "Scale"
  bottom: "Convolution64"
  top: "Convolution64"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU64"
  type: "ReLU"
  bottom: "Convolution64"
  top: "Convolution64"
}
layer {
  name: "Convolution65"
  type: "Convolution"
  bottom: "Convolution64"
  top: "Convolution65"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm65"
  type: "BatchNorm"
  bottom: "Convolution65"
  top: "Convolution65"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale65"
  type: "Scale"
  bottom: "Convolution65"
  top: "Convolution65"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU65"
  type: "ReLU"
  bottom: "Convolution65"
  top: "Convolution65"
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "Convolution3"
  bottom: "Convolution5"
  bottom: "Convolution7"
  bottom: "Convolution9"
  bottom: "Convolution11"
  bottom: "Convolution13"
  bottom: "Convolution15"
  bottom: "Convolution17"
  bottom: "Convolution19"
  bottom: "Convolution21"
  bottom: "Convolution23"
  bottom: "Convolution25"
  bottom: "Convolution27"
  bottom: "Convolution29"
  bottom: "Convolution31"
  bottom: "Convolution33"
  bottom: "Convolution35"
  bottom: "Convolution37"
  bottom: "Convolution39"
  bottom: "Convolution41"
  bottom: "Convolution43"
  bottom: "Convolution45"
  bottom: "Convolution47"
  bottom: "Convolution49"
  bottom: "Convolution51"
  bottom: "Convolution53"
  bottom: "Convolution55"
  bottom: "Convolution57"
  bottom: "Convolution59"
  bottom: "Convolution61"
  bottom: "Convolution63"
  bottom: "Convolution65"
  top: "Concat1"
}
layer {
  name: "Convolution66"
  type: "Convolution"
  bottom: "Concat1"
  top: "Convolution66"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm66"
  type: "BatchNorm"
  bottom: "Convolution66"
  top: "Convolution66"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale66"
  type: "Scale"
  bottom: "Convolution66"
  top: "Convolution66"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU66"
  type: "ReLU"
  bottom: "Convolution66"
  top: "Convolution66"
}
layer {
  name: "Convolution67"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution67"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm67"
  type: "BatchNorm"
  bottom: "Convolution67"
  top: "Convolution67"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale67"
  type: "Scale"
  bottom: "Convolution67"
  top: "Convolution67"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU67"
  type: "ReLU"
  bottom: "Convolution67"
  top: "Convolution67"
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution66"
  bottom: "Convolution67"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution68"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution68"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm68"
  type: "BatchNorm"
  bottom: "Convolution68"
  top: "Convolution68"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale68"
  type: "Scale"
  bottom: "Convolution68"
  top: "Convolution68"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU68"
  type: "ReLU"
  bottom: "Convolution68"
  top: "Convolution68"
}
layer {
  name: "Convolution69"
  type: "Convolution"
  bottom: "Convolution68"
  top: "Convolution69"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm69"
  type: "BatchNorm"
  bottom: "Convolution69"
  top: "Convolution69"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale69"
  type: "Scale"
  bottom: "Convolution69"
  top: "Convolution69"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU69"
  type: "ReLU"
  bottom: "Convolution69"
  top: "Convolution69"
}
layer {
  name: "Convolution70"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution70"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm70"
  type: "BatchNorm"
  bottom: "Convolution70"
  top: "Convolution70"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale70"
  type: "Scale"
  bottom: "Convolution70"
  top: "Convolution70"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU70"
  type: "ReLU"
  bottom: "Convolution70"
  top: "Convolution70"
}
layer {
  name: "Convolution71"
  type: "Convolution"
  bottom: "Convolution70"
  top: "Convolution71"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm71"
  type: "BatchNorm"
  bottom: "Convolution71"
  top: "Convolution71"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale71"
  type: "Scale"
  bottom: "Convolution71"
  top: "Convolution71"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU71"
  type: "ReLU"
  bottom: "Convolution71"
  top: "Convolution71"
}
layer {
  name: "Convolution72"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution72"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm72"
  type: "BatchNorm"
  bottom: "Convolution72"
  top: "Convolution72"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale72"
  type: "Scale"
  bottom: "Convolution72"
  top: "Convolution72"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU72"
  type: "ReLU"
  bottom: "Convolution72"
  top: "Convolution72"
}
layer {
  name: "Convolution73"
  type: "Convolution"
  bottom: "Convolution72"
  top: "Convolution73"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm73"
  type: "BatchNorm"
  bottom: "Convolution73"
  top: "Convolution73"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale73"
  type: "Scale"
  bottom: "Convolution73"
  top: "Convolution73"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU73"
  type: "ReLU"
  bottom: "Convolution73"
  top: "Convolution73"
}
layer {
  name: "Convolution74"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution74"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm74"
  type: "BatchNorm"
  bottom: "Convolution74"
  top: "Convolution74"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale74"
  type: "Scale"
  bottom: "Convolution74"
  top: "Convolution74"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU74"
  type: "ReLU"
  bottom: "Convolution74"
  top: "Convolution74"
}
layer {
  name: "Convolution75"
  type: "Convolution"
  bottom: "Convolution74"
  top: "Convolution75"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm75"
  type: "BatchNorm"
  bottom: "Convolution75"
  top: "Convolution75"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale75"
  type: "Scale"
  bottom: "Convolution75"
  top: "Convolution75"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU75"
  type: "ReLU"
  bottom: "Convolution75"
  top: "Convolution75"
}
layer {
  name: "Convolution76"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution76"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm76"
  type: "BatchNorm"
  bottom: "Convolution76"
  top: "Convolution76"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale76"
  type: "Scale"
  bottom: "Convolution76"
  top: "Convolution76"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU76"
  type: "ReLU"
  bottom: "Convolution76"
  top: "Convolution76"
}
layer {
  name: "Convolution77"
  type: "Convolution"
  bottom: "Convolution76"
  top: "Convolution77"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm77"
  type: "BatchNorm"
  bottom: "Convolution77"
  top: "Convolution77"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale77"
  type: "Scale"
  bottom: "Convolution77"
  top: "Convolution77"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU77"
  type: "ReLU"
  bottom: "Convolution77"
  top: "Convolution77"
}
layer {
  name: "Convolution78"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution78"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm78"
  type: "BatchNorm"
  bottom: "Convolution78"
  top: "Convolution78"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale78"
  type: "Scale"
  bottom: "Convolution78"
  top: "Convolution78"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU78"
  type: "ReLU"
  bottom: "Convolution78"
  top: "Convolution78"
}
layer {
  name: "Convolution79"
  type: "Convolution"
  bottom: "Convolution78"
  top: "Convolution79"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm79"
  type: "BatchNorm"
  bottom: "Convolution79"
  top: "Convolution79"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale79"
  type: "Scale"
  bottom: "Convolution79"
  top: "Convolution79"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU79"
  type: "ReLU"
  bottom: "Convolution79"
  top: "Convolution79"
}
layer {
  name: "Convolution80"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution80"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm80"
  type: "BatchNorm"
  bottom: "Convolution80"
  top: "Convolution80"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale80"
  type: "Scale"
  bottom: "Convolution80"
  top: "Convolution80"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU80"
  type: "ReLU"
  bottom: "Convolution80"
  top: "Convolution80"
}
layer {
  name: "Convolution81"
  type: "Convolution"
  bottom: "Convolution80"
  top: "Convolution81"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm81"
  type: "BatchNorm"
  bottom: "Convolution81"
  top: "Convolution81"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale81"
  type: "Scale"
  bottom: "Convolution81"
  top: "Convolution81"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU81"
  type: "ReLU"
  bottom: "Convolution81"
  top: "Convolution81"
}
layer {
  name: "Convolution82"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution82"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm82"
  type: "BatchNorm"
  bottom: "Convolution82"
  top: "Convolution82"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale82"
  type: "Scale"
  bottom: "Convolution82"
  top: "Convolution82"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU82"
  type: "ReLU"
  bottom: "Convolution82"
  top: "Convolution82"
}
layer {
  name: "Convolution83"
  type: "Convolution"
  bottom: "Convolution82"
  top: "Convolution83"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm83"
  type: "BatchNorm"
  bottom: "Convolution83"
  top: "Convolution83"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale83"
  type: "Scale"
  bottom: "Convolution83"
  top: "Convolution83"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU83"
  type: "ReLU"
  bottom: "Convolution83"
  top: "Convolution83"
}
layer {
  name: "Convolution84"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution84"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm84"
  type: "BatchNorm"
  bottom: "Convolution84"
  top: "Convolution84"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale84"
  type: "Scale"
  bottom: "Convolution84"
  top: "Convolution84"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU84"
  type: "ReLU"
  bottom: "Convolution84"
  top: "Convolution84"
}
layer {
  name: "Convolution85"
  type: "Convolution"
  bottom: "Convolution84"
  top: "Convolution85"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm85"
  type: "BatchNorm"
  bottom: "Convolution85"
  top: "Convolution85"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale85"
  type: "Scale"
  bottom: "Convolution85"
  top: "Convolution85"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU85"
  type: "ReLU"
  bottom: "Convolution85"
  top: "Convolution85"
}
layer {
  name: "Convolution86"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution86"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm86"
  type: "BatchNorm"
  bottom: "Convolution86"
  top: "Convolution86"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale86"
  type: "Scale"
  bottom: "Convolution86"
  top: "Convolution86"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU86"
  type: "ReLU"
  bottom: "Convolution86"
  top: "Convolution86"
}
layer {
  name: "Convolution87"
  type: "Convolution"
  bottom: "Convolution86"
  top: "Convolution87"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm87"
  type: "BatchNorm"
  bottom: "Convolution87"
  top: "Convolution87"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale87"
  type: "Scale"
  bottom: "Convolution87"
  top: "Convolution87"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU87"
  type: "ReLU"
  bottom: "Convolution87"
  top: "Convolution87"
}
layer {
  name: "Convolution88"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution88"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm88"
  type: "BatchNorm"
  bottom: "Convolution88"
  top: "Convolution88"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale88"
  type: "Scale"
  bottom: "Convolution88"
  top: "Convolution88"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU88"
  type: "ReLU"
  bottom: "Convolution88"
  top: "Convolution88"
}
layer {
  name: "Convolution89"
  type: "Convolution"
  bottom: "Convolution88"
  top: "Convolution89"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm89"
  type: "BatchNorm"
  bottom: "Convolution89"
  top: "Convolution89"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale89"
  type: "Scale"
  bottom: "Convolution89"
  top: "Convolution89"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU89"
  type: "ReLU"
  bottom: "Convolution89"
  top: "Convolution89"
}
layer {
  name: "Convolution90"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution90"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm90"
  type: "BatchNorm"
  bottom: "Convolution90"
  top: "Convolution90"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale90"
  type: "Scale"
  bottom: "Convolution90"
  top: "Convolution90"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU90"
  type: "ReLU"
  bottom: "Convolution90"
  top: "Convolution90"
}
layer {
  name: "Convolution91"
  type: "Convolution"
  bottom: "Convolution90"
  top: "Convolution91"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm91"
  type: "BatchNorm"
  bottom: "Convolution91"
  top: "Convolution91"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale91"
  type: "Scale"
  bottom: "Convolution91"
  top: "Convolution91"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU91"
  type: "ReLU"
  bottom: "Convolution91"
  top: "Convolution91"
}
layer {
  name: "Convolution92"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution92"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm92"
  type: "BatchNorm"
  bottom: "Convolution92"
  top: "Convolution92"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale92"
  type: "Scale"
  bottom: "Convolution92"
  top: "Convolution92"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU92"
  type: "ReLU"
  bottom: "Convolution92"
  top: "Convolution92"
}
layer {
  name: "Convolution93"
  type: "Convolution"
  bottom: "Convolution92"
  top: "Convolution93"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm93"
  type: "BatchNorm"
  bottom: "Convolution93"
  top: "Convolution93"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale93"
  type: "Scale"
  bottom: "Convolution93"
  top: "Convolution93"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU93"
  type: "ReLU"
  bottom: "Convolution93"
  top: "Convolution93"
}
layer {
  name: "Convolution94"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution94"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm94"
  type: "BatchNorm"
  bottom: "Convolution94"
  top: "Convolution94"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale94"
  type: "Scale"
  bottom: "Convolution94"
  top: "Convolution94"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU94"
  type: "ReLU"
  bottom: "Convolution94"
  top: "Convolution94"
}
layer {
  name: "Convolution95"
  type: "Convolution"
  bottom: "Convolution94"
  top: "Convolution95"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm95"
  type: "BatchNorm"
  bottom: "Convolution95"
  top: "Convolution95"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale95"
  type: "Scale"
  bottom: "Convolution95"
  top: "Convolution95"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU95"
  type: "ReLU"
  bottom: "Convolution95"
  top: "Convolution95"
}
layer {
  name: "Convolution96"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution96"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm96"
  type: "BatchNorm"
  bottom: "Convolution96"
  top: "Convolution96"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale96"
  type: "Scale"
  bottom: "Convolution96"
  top: "Convolution96"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU96"
  type: "ReLU"
  bottom: "Convolution96"
  top: "Convolution96"
}
layer {
  name: "Convolution97"
  type: "Convolution"
  bottom: "Convolution96"
  top: "Convolution97"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm97"
  type: "BatchNorm"
  bottom: "Convolution97"
  top: "Convolution97"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale97"
  type: "Scale"
  bottom: "Convolution97"
  top: "Convolution97"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU97"
  type: "ReLU"
  bottom: "Convolution97"
  top: "Convolution97"
}
layer {
  name: "Convolution98"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution98"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm98"
  type: "BatchNorm"
  bottom: "Convolution98"
  top: "Convolution98"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale98"
  type: "Scale"
  bottom: "Convolution98"
  top: "Convolution98"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU98"
  type: "ReLU"
  bottom: "Convolution98"
  top: "Convolution98"
}
layer {
  name: "Convolution99"
  type: "Convolution"
  bottom: "Convolution98"
  top: "Convolution99"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm99"
  type: "BatchNorm"
  bottom: "Convolution99"
  top: "Convolution99"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale99"
  type: "Scale"
  bottom: "Convolution99"
  top: "Convolution99"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU99"
  type: "ReLU"
  bottom: "Convolution99"
  top: "Convolution99"
}
layer {
  name: "Convolution100"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution100"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm100"
  type: "BatchNorm"
  bottom: "Convolution100"
  top: "Convolution100"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale100"
  type: "Scale"
  bottom: "Convolution100"
  top: "Convolution100"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU100"
  type: "ReLU"
  bottom: "Convolution100"
  top: "Convolution100"
}
layer {
  name: "Convolution101"
  type: "Convolution"
  bottom: "Convolution100"
  top: "Convolution101"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm101"
  type: "BatchNorm"
  bottom: "Convolution101"
  top: "Convolution101"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale101"
  type: "Scale"
  bottom: "Convolution101"
  top: "Convolution101"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU101"
  type: "ReLU"
  bottom: "Convolution101"
  top: "Convolution101"
}
layer {
  name: "Convolution102"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution102"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm102"
  type: "BatchNorm"
  bottom: "Convolution102"
  top: "Convolution102"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale102"
  type: "Scale"
  bottom: "Convolution102"
  top: "Convolution102"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU102"
  type: "ReLU"
  bottom: "Convolution102"
  top: "Convolution102"
}
layer {
  name: "Convolution103"
  type: "Convolution"
  bottom: "Convolution102"
  top: "Convolution103"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm103"
  type: "BatchNorm"
  bottom: "Convolution103"
  top: "Convolution103"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale103"
  type: "Scale"
  bottom: "Convolution103"
  top: "Convolution103"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU103"
  type: "ReLU"
  bottom: "Convolution103"
  top: "Convolution103"
}
layer {
  name: "Convolution104"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution104"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm104"
  type: "BatchNorm"
  bottom: "Convolution104"
  top: "Convolution104"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale104"
  type: "Scale"
  bottom: "Convolution104"
  top: "Convolution104"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU104"
  type: "ReLU"
  bottom: "Convolution104"
  top: "Convolution104"
}
layer {
  name: "Convolution105"
  type: "Convolution"
  bottom: "Convolution104"
  top: "Convolution105"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm105"
  type: "BatchNorm"
  bottom: "Convolution105"
  top: "Convolution105"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale105"
  type: "Scale"
  bottom: "Convolution105"
  top: "Convolution105"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU105"
  type: "ReLU"
  bottom: "Convolution105"
  top: "Convolution105"
}
layer {
  name: "Convolution106"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution106"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm106"
  type: "BatchNorm"
  bottom: "Convolution106"
  top: "Convolution106"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale106"
  type: "Scale"
  bottom: "Convolution106"
  top: "Convolution106"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU106"
  type: "ReLU"
  bottom: "Convolution106"
  top: "Convolution106"
}
layer {
  name: "Convolution107"
  type: "Convolution"
  bottom: "Convolution106"
  top: "Convolution107"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm107"
  type: "BatchNorm"
  bottom: "Convolution107"
  top: "Convolution107"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale107"
  type: "Scale"
  bottom: "Convolution107"
  top: "Convolution107"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU107"
  type: "ReLU"
  bottom: "Convolution107"
  top: "Convolution107"
}
layer {
  name: "Convolution108"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution108"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm108"
  type: "BatchNorm"
  bottom: "Convolution108"
  top: "Convolution108"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale108"
  type: "Scale"
  bottom: "Convolution108"
  top: "Convolution108"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU108"
  type: "ReLU"
  bottom: "Convolution108"
  top: "Convolution108"
}
layer {
  name: "Convolution109"
  type: "Convolution"
  bottom: "Convolution108"
  top: "Convolution109"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm109"
  type: "BatchNorm"
  bottom: "Convolution109"
  top: "Convolution109"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale109"
  type: "Scale"
  bottom: "Convolution109"
  top: "Convolution109"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU109"
  type: "ReLU"
  bottom: "Convolution109"
  top: "Convolution109"
}
layer {
  name: "Convolution110"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution110"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm110"
  type: "BatchNorm"
  bottom: "Convolution110"
  top: "Convolution110"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale110"
  type: "Scale"
  bottom: "Convolution110"
  top: "Convolution110"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU110"
  type: "ReLU"
  bottom: "Convolution110"
  top: "Convolution110"
}
layer {
  name: "Convolution111"
  type: "Convolution"
  bottom: "Convolution110"
  top: "Convolution111"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm111"
  type: "BatchNorm"
  bottom: "Convolution111"
  top: "Convolution111"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale111"
  type: "Scale"
  bottom: "Convolution111"
  top: "Convolution111"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU111"
  type: "ReLU"
  bottom: "Convolution111"
  top: "Convolution111"
}
layer {
  name: "Convolution112"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution112"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm112"
  type: "BatchNorm"
  bottom: "Convolution112"
  top: "Convolution112"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale112"
  type: "Scale"
  bottom: "Convolution112"
  top: "Convolution112"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU112"
  type: "ReLU"
  bottom: "Convolution112"
  top: "Convolution112"
}
layer {
  name: "Convolution113"
  type: "Convolution"
  bottom: "Convolution112"
  top: "Convolution113"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm113"
  type: "BatchNorm"
  bottom: "Convolution113"
  top: "Convolution113"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale113"
  type: "Scale"
  bottom: "Convolution113"
  top: "Convolution113"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU113"
  type: "ReLU"
  bottom: "Convolution113"
  top: "Convolution113"
}
layer {
  name: "Convolution114"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution114"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm114"
  type: "BatchNorm"
  bottom: "Convolution114"
  top: "Convolution114"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale114"
  type: "Scale"
  bottom: "Convolution114"
  top: "Convolution114"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU114"
  type: "ReLU"
  bottom: "Convolution114"
  top: "Convolution114"
}
layer {
  name: "Convolution115"
  type: "Convolution"
  bottom: "Convolution114"
  top: "Convolution115"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm115"
  type: "BatchNorm"
  bottom: "Convolution115"
  top: "Convolution115"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale115"
  type: "Scale"
  bottom: "Convolution115"
  top: "Convolution115"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU115"
  type: "ReLU"
  bottom: "Convolution115"
  top: "Convolution115"
}
layer {
  name: "Convolution116"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution116"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm116"
  type: "BatchNorm"
  bottom: "Convolution116"
  top: "Convolution116"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale116"
  type: "Scale"
  bottom: "Convolution116"
  top: "Convolution116"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU116"
  type: "ReLU"
  bottom: "Convolution116"
  top: "Convolution116"
}
layer {
  name: "Convolution117"
  type: "Convolution"
  bottom: "Convolution116"
  top: "Convolution117"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm117"
  type: "BatchNorm"
  bottom: "Convolution117"
  top: "Convolution117"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale117"
  type: "Scale"
  bottom: "Convolution117"
  top: "Convolution117"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU117"
  type: "ReLU"
  bottom: "Convolution117"
  top: "Convolution117"
}
layer {
  name: "Convolution118"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution118"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm118"
  type: "BatchNorm"
  bottom: "Convolution118"
  top: "Convolution118"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale118"
  type: "Scale"
  bottom: "Convolution118"
  top: "Convolution118"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU118"
  type: "ReLU"
  bottom: "Convolution118"
  top: "Convolution118"
}
layer {
  name: "Convolution119"
  type: "Convolution"
  bottom: "Convolution118"
  top: "Convolution119"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm119"
  type: "BatchNorm"
  bottom: "Convolution119"
  top: "Convolution119"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale119"
  type: "Scale"
  bottom: "Convolution119"
  top: "Convolution119"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU119"
  type: "ReLU"
  bottom: "Convolution119"
  top: "Convolution119"
}
layer {
  name: "Convolution120"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution120"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm120"
  type: "BatchNorm"
  bottom: "Convolution120"
  top: "Convolution120"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale120"
  type: "Scale"
  bottom: "Convolution120"
  top: "Convolution120"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU120"
  type: "ReLU"
  bottom: "Convolution120"
  top: "Convolution120"
}
layer {
  name: "Convolution121"
  type: "Convolution"
  bottom: "Convolution120"
  top: "Convolution121"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm121"
  type: "BatchNorm"
  bottom: "Convolution121"
  top: "Convolution121"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale121"
  type: "Scale"
  bottom: "Convolution121"
  top: "Convolution121"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU121"
  type: "ReLU"
  bottom: "Convolution121"
  top: "Convolution121"
}
layer {
  name: "Convolution122"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution122"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm122"
  type: "BatchNorm"
  bottom: "Convolution122"
  top: "Convolution122"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale122"
  type: "Scale"
  bottom: "Convolution122"
  top: "Convolution122"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU122"
  type: "ReLU"
  bottom: "Convolution122"
  top: "Convolution122"
}
layer {
  name: "Convolution123"
  type: "Convolution"
  bottom: "Convolution122"
  top: "Convolution123"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm123"
  type: "BatchNorm"
  bottom: "Convolution123"
  top: "Convolution123"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale123"
  type: "Scale"
  bottom: "Convolution123"
  top: "Convolution123"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU123"
  type: "ReLU"
  bottom: "Convolution123"
  top: "Convolution123"
}
layer {
  name: "Convolution124"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution124"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm124"
  type: "BatchNorm"
  bottom: "Convolution124"
  top: "Convolution124"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale124"
  type: "Scale"
  bottom: "Convolution124"
  top: "Convolution124"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU124"
  type: "ReLU"
  bottom: "Convolution124"
  top: "Convolution124"
}
layer {
  name: "Convolution125"
  type: "Convolution"
  bottom: "Convolution124"
  top: "Convolution125"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm125"
  type: "BatchNorm"
  bottom: "Convolution125"
  top: "Convolution125"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale125"
  type: "Scale"
  bottom: "Convolution125"
  top: "Convolution125"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU125"
  type: "ReLU"
  bottom: "Convolution125"
  top: "Convolution125"
}
layer {
  name: "Convolution126"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution126"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm126"
  type: "BatchNorm"
  bottom: "Convolution126"
  top: "Convolution126"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale126"
  type: "Scale"
  bottom: "Convolution126"
  top: "Convolution126"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU126"
  type: "ReLU"
  bottom: "Convolution126"
  top: "Convolution126"
}
layer {
  name: "Convolution127"
  type: "Convolution"
  bottom: "Convolution126"
  top: "Convolution127"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm127"
  type: "BatchNorm"
  bottom: "Convolution127"
  top: "Convolution127"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale127"
  type: "Scale"
  bottom: "Convolution127"
  top: "Convolution127"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU127"
  type: "ReLU"
  bottom: "Convolution127"
  top: "Convolution127"
}
layer {
  name: "Convolution128"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution128"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm128"
  type: "BatchNorm"
  bottom: "Convolution128"
  top: "Convolution128"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale128"
  type: "Scale"
  bottom: "Convolution128"
  top: "Convolution128"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU128"
  type: "ReLU"
  bottom: "Convolution128"
  top: "Convolution128"
}
layer {
  name: "Convolution129"
  type: "Convolution"
  bottom: "Convolution128"
  top: "Convolution129"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm129"
  type: "BatchNorm"
  bottom: "Convolution129"
  top: "Convolution129"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale129"
  type: "Scale"
  bottom: "Convolution129"
  top: "Convolution129"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU129"
  type: "ReLU"
  bottom: "Convolution129"
  top: "Convolution129"
}
layer {
  name: "Convolution130"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution130"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm130"
  type: "BatchNorm"
  bottom: "Convolution130"
  top: "Convolution130"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale130"
  type: "Scale"
  bottom: "Convolution130"
  top: "Convolution130"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU130"
  type: "ReLU"
  bottom: "Convolution130"
  top: "Convolution130"
}
layer {
  name: "Convolution131"
  type: "Convolution"
  bottom: "Convolution130"
  top: "Convolution131"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm131"
  type: "BatchNorm"
  bottom: "Convolution131"
  top: "Convolution131"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale131"
  type: "Scale"
  bottom: "Convolution131"
  top: "Convolution131"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU131"
  type: "ReLU"
  bottom: "Convolution131"
  top: "Convolution131"
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "Convolution69"
  bottom: "Convolution71"
  bottom: "Convolution73"
  bottom: "Convolution75"
  bottom: "Convolution77"
  bottom: "Convolution79"
  bottom: "Convolution81"
  bottom: "Convolution83"
  bottom: "Convolution85"
  bottom: "Convolution87"
  bottom: "Convolution89"
  bottom: "Convolution91"
  bottom: "Convolution93"
  bottom: "Convolution95"
  bottom: "Convolution97"
  bottom: "Convolution99"
  bottom: "Convolution101"
  bottom: "Convolution103"
  bottom: "Convolution105"
  bottom: "Convolution107"
  bottom: "Convolution109"
  bottom: "Convolution111"
  bottom: "Convolution113"
  bottom: "Convolution115"
  bottom: "Convolution117"
  bottom: "Convolution119"
  bottom: "Convolution121"
  bottom: "Convolution123"
  bottom: "Convolution125"
  bottom: "Convolution127"
  bottom: "Convolution129"
  bottom: "Convolution131"
  top: "Concat2"
}
layer {
  name: "Convolution132"
  type: "Convolution"
  bottom: "Concat2"
  top: "Convolution132"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm132"
  type: "BatchNorm"
  bottom: "Convolution132"
  top: "Convolution132"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale132"
  type: "Scale"
  bottom: "Convolution132"
  top: "Convolution132"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU132"
  type: "ReLU"
  bottom: "Convolution132"
  top: "Convolution132"
}
layer {
  name: "Convolution133"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution133"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm133"
  type: "BatchNorm"
  bottom: "Convolution133"
  top: "Convolution133"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale133"
  type: "Scale"
  bottom: "Convolution133"
  top: "Convolution133"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU133"
  type: "ReLU"
  bottom: "Convolution133"
  top: "Convolution133"
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Convolution132"
  bottom: "Convolution133"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution134"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution134"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm134"
  type: "BatchNorm"
  bottom: "Convolution134"
  top: "Convolution134"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale134"
  type: "Scale"
  bottom: "Convolution134"
  top: "Convolution134"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU134"
  type: "ReLU"
  bottom: "Convolution134"
  top: "Convolution134"
}
layer {
  name: "Convolution135"
  type: "Convolution"
  bottom: "Convolution134"
  top: "Convolution135"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm135"
  type: "BatchNorm"
  bottom: "Convolution135"
  top: "Convolution135"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale135"
  type: "Scale"
  bottom: "Convolution135"
  top: "Convolution135"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU135"
  type: "ReLU"
  bottom: "Convolution135"
  top: "Convolution135"
}
layer {
  name: "Convolution136"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution136"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm136"
  type: "BatchNorm"
  bottom: "Convolution136"
  top: "Convolution136"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale136"
  type: "Scale"
  bottom: "Convolution136"
  top: "Convolution136"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU136"
  type: "ReLU"
  bottom: "Convolution136"
  top: "Convolution136"
}
layer {
  name: "Convolution137"
  type: "Convolution"
  bottom: "Convolution136"
  top: "Convolution137"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm137"
  type: "BatchNorm"
  bottom: "Convolution137"
  top: "Convolution137"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale137"
  type: "Scale"
  bottom: "Convolution137"
  top: "Convolution137"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU137"
  type: "ReLU"
  bottom: "Convolution137"
  top: "Convolution137"
}
layer {
  name: "Convolution138"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution138"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm138"
  type: "BatchNorm"
  bottom: "Convolution138"
  top: "Convolution138"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale138"
  type: "Scale"
  bottom: "Convolution138"
  top: "Convolution138"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU138"
  type: "ReLU"
  bottom: "Convolution138"
  top: "Convolution138"
}
layer {
  name: "Convolution139"
  type: "Convolution"
  bottom: "Convolution138"
  top: "Convolution139"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm139"
  type: "BatchNorm"
  bottom: "Convolution139"
  top: "Convolution139"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale139"
  type: "Scale"
  bottom: "Convolution139"
  top: "Convolution139"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU139"
  type: "ReLU"
  bottom: "Convolution139"
  top: "Convolution139"
}
layer {
  name: "Convolution140"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution140"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm140"
  type: "BatchNorm"
  bottom: "Convolution140"
  top: "Convolution140"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale140"
  type: "Scale"
  bottom: "Convolution140"
  top: "Convolution140"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU140"
  type: "ReLU"
  bottom: "Convolution140"
  top: "Convolution140"
}
layer {
  name: "Convolution141"
  type: "Convolution"
  bottom: "Convolution140"
  top: "Convolution141"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm141"
  type: "BatchNorm"
  bottom: "Convolution141"
  top: "Convolution141"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale141"
  type: "Scale"
  bottom: "Convolution141"
  top: "Convolution141"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU141"
  type: "ReLU"
  bottom: "Convolution141"
  top: "Convolution141"
}
layer {
  name: "Convolution142"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution142"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm142"
  type: "BatchNorm"
  bottom: "Convolution142"
  top: "Convolution142"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale142"
  type: "Scale"
  bottom: "Convolution142"
  top: "Convolution142"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU142"
  type: "ReLU"
  bottom: "Convolution142"
  top: "Convolution142"
}
layer {
  name: "Convolution143"
  type: "Convolution"
  bottom: "Convolution142"
  top: "Convolution143"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm143"
  type: "BatchNorm"
  bottom: "Convolution143"
  top: "Convolution143"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale143"
  type: "Scale"
  bottom: "Convolution143"
  top: "Convolution143"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU143"
  type: "ReLU"
  bottom: "Convolution143"
  top: "Convolution143"
}
layer {
  name: "Convolution144"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution144"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm144"
  type: "BatchNorm"
  bottom: "Convolution144"
  top: "Convolution144"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale144"
  type: "Scale"
  bottom: "Convolution144"
  top: "Convolution144"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU144"
  type: "ReLU"
  bottom: "Convolution144"
  top: "Convolution144"
}
layer {
  name: "Convolution145"
  type: "Convolution"
  bottom: "Convolution144"
  top: "Convolution145"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm145"
  type: "BatchNorm"
  bottom: "Convolution145"
  top: "Convolution145"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale145"
  type: "Scale"
  bottom: "Convolution145"
  top: "Convolution145"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU145"
  type: "ReLU"
  bottom: "Convolution145"
  top: "Convolution145"
}
layer {
  name: "Convolution146"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution146"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm146"
  type: "BatchNorm"
  bottom: "Convolution146"
  top: "Convolution146"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale146"
  type: "Scale"
  bottom: "Convolution146"
  top: "Convolution146"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU146"
  type: "ReLU"
  bottom: "Convolution146"
  top: "Convolution146"
}
layer {
  name: "Convolution147"
  type: "Convolution"
  bottom: "Convolution146"
  top: "Convolution147"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm147"
  type: "BatchNorm"
  bottom: "Convolution147"
  top: "Convolution147"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale147"
  type: "Scale"
  bottom: "Convolution147"
  top: "Convolution147"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU147"
  type: "ReLU"
  bottom: "Convolution147"
  top: "Convolution147"
}
layer {
  name: "Convolution148"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution148"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm148"
  type: "BatchNorm"
  bottom: "Convolution148"
  top: "Convolution148"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale148"
  type: "Scale"
  bottom: "Convolution148"
  top: "Convolution148"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU148"
  type: "ReLU"
  bottom: "Convolution148"
  top: "Convolution148"
}
layer {
  name: "Convolution149"
  type: "Convolution"
  bottom: "Convolution148"
  top: "Convolution149"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm149"
  type: "BatchNorm"
  bottom: "Convolution149"
  top: "Convolution149"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale149"
  type: "Scale"
  bottom: "Convolution149"
  top: "Convolution149"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU149"
  type: "ReLU"
  bottom: "Convolution149"
  top: "Convolution149"
}
layer {
  name: "Convolution150"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution150"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm150"
  type: "BatchNorm"
  bottom: "Convolution150"
  top: "Convolution150"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale150"
  type: "Scale"
  bottom: "Convolution150"
  top: "Convolution150"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU150"
  type: "ReLU"
  bottom: "Convolution150"
  top: "Convolution150"
}
layer {
  name: "Convolution151"
  type: "Convolution"
  bottom: "Convolution150"
  top: "Convolution151"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm151"
  type: "BatchNorm"
  bottom: "Convolution151"
  top: "Convolution151"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale151"
  type: "Scale"
  bottom: "Convolution151"
  top: "Convolution151"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU151"
  type: "ReLU"
  bottom: "Convolution151"
  top: "Convolution151"
}
layer {
  name: "Convolution152"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution152"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm152"
  type: "BatchNorm"
  bottom: "Convolution152"
  top: "Convolution152"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale152"
  type: "Scale"
  bottom: "Convolution152"
  top: "Convolution152"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU152"
  type: "ReLU"
  bottom: "Convolution152"
  top: "Convolution152"
}
layer {
  name: "Convolution153"
  type: "Convolution"
  bottom: "Convolution152"
  top: "Convolution153"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm153"
  type: "BatchNorm"
  bottom: "Convolution153"
  top: "Convolution153"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale153"
  type: "Scale"
  bottom: "Convolution153"
  top: "Convolution153"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU153"
  type: "ReLU"
  bottom: "Convolution153"
  top: "Convolution153"
}
layer {
  name: "Convolution154"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution154"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm154"
  type: "BatchNorm"
  bottom: "Convolution154"
  top: "Convolution154"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale154"
  type: "Scale"
  bottom: "Convolution154"
  top: "Convolution154"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU154"
  type: "ReLU"
  bottom: "Convolution154"
  top: "Convolution154"
}
layer {
  name: "Convolution155"
  type: "Convolution"
  bottom: "Convolution154"
  top: "Convolution155"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm155"
  type: "BatchNorm"
  bottom: "Convolution155"
  top: "Convolution155"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale155"
  type: "Scale"
  bottom: "Convolution155"
  top: "Convolution155"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU155"
  type: "ReLU"
  bottom: "Convolution155"
  top: "Convolution155"
}
layer {
  name: "Convolution156"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution156"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm156"
  type: "BatchNorm"
  bottom: "Convolution156"
  top: "Convolution156"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale156"
  type: "Scale"
  bottom: "Convolution156"
  top: "Convolution156"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU156"
  type: "ReLU"
  bottom: "Convolution156"
  top: "Convolution156"
}
layer {
  name: "Convolution157"
  type: "Convolution"
  bottom: "Convolution156"
  top: "Convolution157"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm157"
  type: "BatchNorm"
  bottom: "Convolution157"
  top: "Convolution157"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale157"
  type: "Scale"
  bottom: "Convolution157"
  top: "Convolution157"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU157"
  type: "ReLU"
  bottom: "Convolution157"
  top: "Convolution157"
}
layer {
  name: "Convolution158"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution158"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm158"
  type: "BatchNorm"
  bottom: "Convolution158"
  top: "Convolution158"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale158"
  type: "Scale"
  bottom: "Convolution158"
  top: "Convolution158"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU158"
  type: "ReLU"
  bottom: "Convolution158"
  top: "Convolution158"
}
layer {
  name: "Convolution159"
  type: "Convolution"
  bottom: "Convolution158"
  top: "Convolution159"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm159"
  type: "BatchNorm"
  bottom: "Convolution159"
  top: "Convolution159"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale159"
  type: "Scale"
  bottom: "Convolution159"
  top: "Convolution159"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU159"
  type: "ReLU"
  bottom: "Convolution159"
  top: "Convolution159"
}
layer {
  name: "Convolution160"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution160"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm160"
  type: "BatchNorm"
  bottom: "Convolution160"
  top: "Convolution160"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale160"
  type: "Scale"
  bottom: "Convolution160"
  top: "Convolution160"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU160"
  type: "ReLU"
  bottom: "Convolution160"
  top: "Convolution160"
}
layer {
  name: "Convolution161"
  type: "Convolution"
  bottom: "Convolution160"
  top: "Convolution161"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm161"
  type: "BatchNorm"
  bottom: "Convolution161"
  top: "Convolution161"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale161"
  type: "Scale"
  bottom: "Convolution161"
  top: "Convolution161"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU161"
  type: "ReLU"
  bottom: "Convolution161"
  top: "Convolution161"
}
layer {
  name: "Convolution162"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution162"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm162"
  type: "BatchNorm"
  bottom: "Convolution162"
  top: "Convolution162"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale162"
  type: "Scale"
  bottom: "Convolution162"
  top: "Convolution162"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU162"
  type: "ReLU"
  bottom: "Convolution162"
  top: "Convolution162"
}
layer {
  name: "Convolution163"
  type: "Convolution"
  bottom: "Convolution162"
  top: "Convolution163"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm163"
  type: "BatchNorm"
  bottom: "Convolution163"
  top: "Convolution163"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale163"
  type: "Scale"
  bottom: "Convolution163"
  top: "Convolution163"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU163"
  type: "ReLU"
  bottom: "Convolution163"
  top: "Convolution163"
}
layer {
  name: "Convolution164"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution164"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm164"
  type: "BatchNorm"
  bottom: "Convolution164"
  top: "Convolution164"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale164"
  type: "Scale"
  bottom: "Convolution164"
  top: "Convolution164"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU164"
  type: "ReLU"
  bottom: "Convolution164"
  top: "Convolution164"
}
layer {
  name: "Convolution165"
  type: "Convolution"
  bottom: "Convolution164"
  top: "Convolution165"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm165"
  type: "BatchNorm"
  bottom: "Convolution165"
  top: "Convolution165"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale165"
  type: "Scale"
  bottom: "Convolution165"
  top: "Convolution165"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU165"
  type: "ReLU"
  bottom: "Convolution165"
  top: "Convolution165"
}
layer {
  name: "Convolution166"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution166"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm166"
  type: "BatchNorm"
  bottom: "Convolution166"
  top: "Convolution166"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale166"
  type: "Scale"
  bottom: "Convolution166"
  top: "Convolution166"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU166"
  type: "ReLU"
  bottom: "Convolution166"
  top: "Convolution166"
}
layer {
  name: "Convolution167"
  type: "Convolution"
  bottom: "Convolution166"
  top: "Convolution167"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm167"
  type: "BatchNorm"
  bottom: "Convolution167"
  top: "Convolution167"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale167"
  type: "Scale"
  bottom: "Convolution167"
  top: "Convolution167"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU167"
  type: "ReLU"
  bottom: "Convolution167"
  top: "Convolution167"
}
layer {
  name: "Convolution168"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution168"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm168"
  type: "BatchNorm"
  bottom: "Convolution168"
  top: "Convolution168"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale168"
  type: "Scale"
  bottom: "Convolution168"
  top: "Convolution168"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU168"
  type: "ReLU"
  bottom: "Convolution168"
  top: "Convolution168"
}
layer {
  name: "Convolution169"
  type: "Convolution"
  bottom: "Convolution168"
  top: "Convolution169"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm169"
  type: "BatchNorm"
  bottom: "Convolution169"
  top: "Convolution169"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale169"
  type: "Scale"
  bottom: "Convolution169"
  top: "Convolution169"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU169"
  type: "ReLU"
  bottom: "Convolution169"
  top: "Convolution169"
}
layer {
  name: "Convolution170"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution170"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm170"
  type: "BatchNorm"
  bottom: "Convolution170"
  top: "Convolution170"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale170"
  type: "Scale"
  bottom: "Convolution170"
  top: "Convolution170"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU170"
  type: "ReLU"
  bottom: "Convolution170"
  top: "Convolution170"
}
layer {
  name: "Convolution171"
  type: "Convolution"
  bottom: "Convolution170"
  top: "Convolution171"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm171"
  type: "BatchNorm"
  bottom: "Convolution171"
  top: "Convolution171"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale171"
  type: "Scale"
  bottom: "Convolution171"
  top: "Convolution171"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU171"
  type: "ReLU"
  bottom: "Convolution171"
  top: "Convolution171"
}
layer {
  name: "Convolution172"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution172"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm172"
  type: "BatchNorm"
  bottom: "Convolution172"
  top: "Convolution172"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale172"
  type: "Scale"
  bottom: "Convolution172"
  top: "Convolution172"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU172"
  type: "ReLU"
  bottom: "Convolution172"
  top: "Convolution172"
}
layer {
  name: "Convolution173"
  type: "Convolution"
  bottom: "Convolution172"
  top: "Convolution173"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm173"
  type: "BatchNorm"
  bottom: "Convolution173"
  top: "Convolution173"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale173"
  type: "Scale"
  bottom: "Convolution173"
  top: "Convolution173"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU173"
  type: "ReLU"
  bottom: "Convolution173"
  top: "Convolution173"
}
layer {
  name: "Convolution174"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution174"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm174"
  type: "BatchNorm"
  bottom: "Convolution174"
  top: "Convolution174"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale174"
  type: "Scale"
  bottom: "Convolution174"
  top: "Convolution174"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU174"
  type: "ReLU"
  bottom: "Convolution174"
  top: "Convolution174"
}
layer {
  name: "Convolution175"
  type: "Convolution"
  bottom: "Convolution174"
  top: "Convolution175"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm175"
  type: "BatchNorm"
  bottom: "Convolution175"
  top: "Convolution175"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale175"
  type: "Scale"
  bottom: "Convolution175"
  top: "Convolution175"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU175"
  type: "ReLU"
  bottom: "Convolution175"
  top: "Convolution175"
}
layer {
  name: "Convolution176"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution176"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm176"
  type: "BatchNorm"
  bottom: "Convolution176"
  top: "Convolution176"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale176"
  type: "Scale"
  bottom: "Convolution176"
  top: "Convolution176"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU176"
  type: "ReLU"
  bottom: "Convolution176"
  top: "Convolution176"
}
layer {
  name: "Convolution177"
  type: "Convolution"
  bottom: "Convolution176"
  top: "Convolution177"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm177"
  type: "BatchNorm"
  bottom: "Convolution177"
  top: "Convolution177"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale177"
  type: "Scale"
  bottom: "Convolution177"
  top: "Convolution177"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU177"
  type: "ReLU"
  bottom: "Convolution177"
  top: "Convolution177"
}
layer {
  name: "Convolution178"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution178"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm178"
  type: "BatchNorm"
  bottom: "Convolution178"
  top: "Convolution178"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale178"
  type: "Scale"
  bottom: "Convolution178"
  top: "Convolution178"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU178"
  type: "ReLU"
  bottom: "Convolution178"
  top: "Convolution178"
}
layer {
  name: "Convolution179"
  type: "Convolution"
  bottom: "Convolution178"
  top: "Convolution179"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm179"
  type: "BatchNorm"
  bottom: "Convolution179"
  top: "Convolution179"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale179"
  type: "Scale"
  bottom: "Convolution179"
  top: "Convolution179"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU179"
  type: "ReLU"
  bottom: "Convolution179"
  top: "Convolution179"
}
layer {
  name: "Convolution180"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution180"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm180"
  type: "BatchNorm"
  bottom: "Convolution180"
  top: "Convolution180"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale180"
  type: "Scale"
  bottom: "Convolution180"
  top: "Convolution180"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU180"
  type: "ReLU"
  bottom: "Convolution180"
  top: "Convolution180"
}
layer {
  name: "Convolution181"
  type: "Convolution"
  bottom: "Convolution180"
  top: "Convolution181"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm181"
  type: "BatchNorm"
  bottom: "Convolution181"
  top: "Convolution181"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale181"
  type: "Scale"
  bottom: "Convolution181"
  top: "Convolution181"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU181"
  type: "ReLU"
  bottom: "Convolution181"
  top: "Convolution181"
}
layer {
  name: "Convolution182"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution182"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm182"
  type: "BatchNorm"
  bottom: "Convolution182"
  top: "Convolution182"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale182"
  type: "Scale"
  bottom: "Convolution182"
  top: "Convolution182"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU182"
  type: "ReLU"
  bottom: "Convolution182"
  top: "Convolution182"
}
layer {
  name: "Convolution183"
  type: "Convolution"
  bottom: "Convolution182"
  top: "Convolution183"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm183"
  type: "BatchNorm"
  bottom: "Convolution183"
  top: "Convolution183"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale183"
  type: "Scale"
  bottom: "Convolution183"
  top: "Convolution183"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU183"
  type: "ReLU"
  bottom: "Convolution183"
  top: "Convolution183"
}
layer {
  name: "Convolution184"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution184"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm184"
  type: "BatchNorm"
  bottom: "Convolution184"
  top: "Convolution184"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale184"
  type: "Scale"
  bottom: "Convolution184"
  top: "Convolution184"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU184"
  type: "ReLU"
  bottom: "Convolution184"
  top: "Convolution184"
}
layer {
  name: "Convolution185"
  type: "Convolution"
  bottom: "Convolution184"
  top: "Convolution185"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm185"
  type: "BatchNorm"
  bottom: "Convolution185"
  top: "Convolution185"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale185"
  type: "Scale"
  bottom: "Convolution185"
  top: "Convolution185"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU185"
  type: "ReLU"
  bottom: "Convolution185"
  top: "Convolution185"
}
layer {
  name: "Convolution186"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution186"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm186"
  type: "BatchNorm"
  bottom: "Convolution186"
  top: "Convolution186"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale186"
  type: "Scale"
  bottom: "Convolution186"
  top: "Convolution186"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU186"
  type: "ReLU"
  bottom: "Convolution186"
  top: "Convolution186"
}
layer {
  name: "Convolution187"
  type: "Convolution"
  bottom: "Convolution186"
  top: "Convolution187"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm187"
  type: "BatchNorm"
  bottom: "Convolution187"
  top: "Convolution187"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale187"
  type: "Scale"
  bottom: "Convolution187"
  top: "Convolution187"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU187"
  type: "ReLU"
  bottom: "Convolution187"
  top: "Convolution187"
}
layer {
  name: "Convolution188"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution188"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm188"
  type: "BatchNorm"
  bottom: "Convolution188"
  top: "Convolution188"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale188"
  type: "Scale"
  bottom: "Convolution188"
  top: "Convolution188"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU188"
  type: "ReLU"
  bottom: "Convolution188"
  top: "Convolution188"
}
layer {
  name: "Convolution189"
  type: "Convolution"
  bottom: "Convolution188"
  top: "Convolution189"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm189"
  type: "BatchNorm"
  bottom: "Convolution189"
  top: "Convolution189"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale189"
  type: "Scale"
  bottom: "Convolution189"
  top: "Convolution189"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU189"
  type: "ReLU"
  bottom: "Convolution189"
  top: "Convolution189"
}
layer {
  name: "Convolution190"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution190"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm190"
  type: "BatchNorm"
  bottom: "Convolution190"
  top: "Convolution190"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale190"
  type: "Scale"
  bottom: "Convolution190"
  top: "Convolution190"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU190"
  type: "ReLU"
  bottom: "Convolution190"
  top: "Convolution190"
}
layer {
  name: "Convolution191"
  type: "Convolution"
  bottom: "Convolution190"
  top: "Convolution191"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm191"
  type: "BatchNorm"
  bottom: "Convolution191"
  top: "Convolution191"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale191"
  type: "Scale"
  bottom: "Convolution191"
  top: "Convolution191"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU191"
  type: "ReLU"
  bottom: "Convolution191"
  top: "Convolution191"
}
layer {
  name: "Convolution192"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution192"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm192"
  type: "BatchNorm"
  bottom: "Convolution192"
  top: "Convolution192"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale192"
  type: "Scale"
  bottom: "Convolution192"
  top: "Convolution192"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU192"
  type: "ReLU"
  bottom: "Convolution192"
  top: "Convolution192"
}
layer {
  name: "Convolution193"
  type: "Convolution"
  bottom: "Convolution192"
  top: "Convolution193"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm193"
  type: "BatchNorm"
  bottom: "Convolution193"
  top: "Convolution193"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale193"
  type: "Scale"
  bottom: "Convolution193"
  top: "Convolution193"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU193"
  type: "ReLU"
  bottom: "Convolution193"
  top: "Convolution193"
}
layer {
  name: "Convolution194"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution194"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm194"
  type: "BatchNorm"
  bottom: "Convolution194"
  top: "Convolution194"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale194"
  type: "Scale"
  bottom: "Convolution194"
  top: "Convolution194"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU194"
  type: "ReLU"
  bottom: "Convolution194"
  top: "Convolution194"
}
layer {
  name: "Convolution195"
  type: "Convolution"
  bottom: "Convolution194"
  top: "Convolution195"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm195"
  type: "BatchNorm"
  bottom: "Convolution195"
  top: "Convolution195"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale195"
  type: "Scale"
  bottom: "Convolution195"
  top: "Convolution195"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU195"
  type: "ReLU"
  bottom: "Convolution195"
  top: "Convolution195"
}
layer {
  name: "Convolution196"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution196"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm196"
  type: "BatchNorm"
  bottom: "Convolution196"
  top: "Convolution196"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale196"
  type: "Scale"
  bottom: "Convolution196"
  top: "Convolution196"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU196"
  type: "ReLU"
  bottom: "Convolution196"
  top: "Convolution196"
}
layer {
  name: "Convolution197"
  type: "Convolution"
  bottom: "Convolution196"
  top: "Convolution197"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm197"
  type: "BatchNorm"
  bottom: "Convolution197"
  top: "Convolution197"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale197"
  type: "Scale"
  bottom: "Convolution197"
  top: "Convolution197"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU197"
  type: "ReLU"
  bottom: "Convolution197"
  top: "Convolution197"
}
layer {
  name: "Concat3"
  type: "Concat"
  bottom: "Convolution135"
  bottom: "Convolution137"
  bottom: "Convolution139"
  bottom: "Convolution141"
  bottom: "Convolution143"
  bottom: "Convolution145"
  bottom: "Convolution147"
  bottom: "Convolution149"
  bottom: "Convolution151"
  bottom: "Convolution153"
  bottom: "Convolution155"
  bottom: "Convolution157"
  bottom: "Convolution159"
  bottom: "Convolution161"
  bottom: "Convolution163"
  bottom: "Convolution165"
  bottom: "Convolution167"
  bottom: "Convolution169"
  bottom: "Convolution171"
  bottom: "Convolution173"
  bottom: "Convolution175"
  bottom: "Convolution177"
  bottom: "Convolution179"
  bottom: "Convolution181"
  bottom: "Convolution183"
  bottom: "Convolution185"
  bottom: "Convolution187"
  bottom: "Convolution189"
  bottom: "Convolution191"
  bottom: "Convolution193"
  bottom: "Convolution195"
  bottom: "Convolution197"
  top: "Concat3"
}
layer {
  name: "Convolution198"
  type: "Convolution"
  bottom: "Concat3"
  top: "Convolution198"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm198"
  type: "BatchNorm"
  bottom: "Convolution198"
  top: "Convolution198"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale198"
  type: "Scale"
  bottom: "Convolution198"
  top: "Convolution198"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU198"
  type: "ReLU"
  bottom: "Convolution198"
  top: "Convolution198"
}
layer {
  name: "Convolution199"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution199"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm199"
  type: "BatchNorm"
  bottom: "Convolution199"
  top: "Convolution199"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale199"
  type: "Scale"
  bottom: "Convolution199"
  top: "Convolution199"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU199"
  type: "ReLU"
  bottom: "Convolution199"
  top: "Convolution199"
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Convolution198"
  bottom: "Convolution199"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution200"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution200"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm200"
  type: "BatchNorm"
  bottom: "Convolution200"
  top: "Convolution200"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale200"
  type: "Scale"
  bottom: "Convolution200"
  top: "Convolution200"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU200"
  type: "ReLU"
  bottom: "Convolution200"
  top: "Convolution200"
}
layer {
  name: "Convolution201"
  type: "Convolution"
  bottom: "Convolution200"
  top: "Convolution201"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm201"
  type: "BatchNorm"
  bottom: "Convolution201"
  top: "Convolution201"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale201"
  type: "Scale"
  bottom: "Convolution201"
  top: "Convolution201"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU201"
  type: "ReLU"
  bottom: "Convolution201"
  top: "Convolution201"
}
layer {
  name: "Convolution202"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution202"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm202"
  type: "BatchNorm"
  bottom: "Convolution202"
  top: "Convolution202"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale202"
  type: "Scale"
  bottom: "Convolution202"
  top: "Convolution202"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU202"
  type: "ReLU"
  bottom: "Convolution202"
  top: "Convolution202"
}
layer {
  name: "Convolution203"
  type: "Convolution"
  bottom: "Convolution202"
  top: "Convolution203"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm203"
  type: "BatchNorm"
  bottom: "Convolution203"
  top: "Convolution203"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale203"
  type: "Scale"
  bottom: "Convolution203"
  top: "Convolution203"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU203"
  type: "ReLU"
  bottom: "Convolution203"
  top: "Convolution203"
}
layer {
  name: "Convolution204"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution204"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm204"
  type: "BatchNorm"
  bottom: "Convolution204"
  top: "Convolution204"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale204"
  type: "Scale"
  bottom: "Convolution204"
  top: "Convolution204"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU204"
  type: "ReLU"
  bottom: "Convolution204"
  top: "Convolution204"
}
layer {
  name: "Convolution205"
  type: "Convolution"
  bottom: "Convolution204"
  top: "Convolution205"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm205"
  type: "BatchNorm"
  bottom: "Convolution205"
  top: "Convolution205"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale205"
  type: "Scale"
  bottom: "Convolution205"
  top: "Convolution205"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU205"
  type: "ReLU"
  bottom: "Convolution205"
  top: "Convolution205"
}
layer {
  name: "Convolution206"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution206"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm206"
  type: "BatchNorm"
  bottom: "Convolution206"
  top: "Convolution206"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale206"
  type: "Scale"
  bottom: "Convolution206"
  top: "Convolution206"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU206"
  type: "ReLU"
  bottom: "Convolution206"
  top: "Convolution206"
}
layer {
  name: "Convolution207"
  type: "Convolution"
  bottom: "Convolution206"
  top: "Convolution207"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm207"
  type: "BatchNorm"
  bottom: "Convolution207"
  top: "Convolution207"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale207"
  type: "Scale"
  bottom: "Convolution207"
  top: "Convolution207"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU207"
  type: "ReLU"
  bottom: "Convolution207"
  top: "Convolution207"
}
layer {
  name: "Convolution208"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution208"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm208"
  type: "BatchNorm"
  bottom: "Convolution208"
  top: "Convolution208"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale208"
  type: "Scale"
  bottom: "Convolution208"
  top: "Convolution208"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU208"
  type: "ReLU"
  bottom: "Convolution208"
  top: "Convolution208"
}
layer {
  name: "Convolution209"
  type: "Convolution"
  bottom: "Convolution208"
  top: "Convolution209"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm209"
  type: "BatchNorm"
  bottom: "Convolution209"
  top: "Convolution209"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale209"
  type: "Scale"
  bottom: "Convolution209"
  top: "Convolution209"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU209"
  type: "ReLU"
  bottom: "Convolution209"
  top: "Convolution209"
}
layer {
  name: "Convolution210"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution210"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm210"
  type: "BatchNorm"
  bottom: "Convolution210"
  top: "Convolution210"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale210"
  type: "Scale"
  bottom: "Convolution210"
  top: "Convolution210"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU210"
  type: "ReLU"
  bottom: "Convolution210"
  top: "Convolution210"
}
layer {
  name: "Convolution211"
  type: "Convolution"
  bottom: "Convolution210"
  top: "Convolution211"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm211"
  type: "BatchNorm"
  bottom: "Convolution211"
  top: "Convolution211"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale211"
  type: "Scale"
  bottom: "Convolution211"
  top: "Convolution211"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU211"
  type: "ReLU"
  bottom: "Convolution211"
  top: "Convolution211"
}
layer {
  name: "Convolution212"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution212"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm212"
  type: "BatchNorm"
  bottom: "Convolution212"
  top: "Convolution212"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale212"
  type: "Scale"
  bottom: "Convolution212"
  top: "Convolution212"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU212"
  type: "ReLU"
  bottom: "Convolution212"
  top: "Convolution212"
}
layer {
  name: "Convolution213"
  type: "Convolution"
  bottom: "Convolution212"
  top: "Convolution213"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm213"
  type: "BatchNorm"
  bottom: "Convolution213"
  top: "Convolution213"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale213"
  type: "Scale"
  bottom: "Convolution213"
  top: "Convolution213"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU213"
  type: "ReLU"
  bottom: "Convolution213"
  top: "Convolution213"
}
layer {
  name: "Convolution214"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution214"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm214"
  type: "BatchNorm"
  bottom: "Convolution214"
  top: "Convolution214"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale214"
  type: "Scale"
  bottom: "Convolution214"
  top: "Convolution214"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU214"
  type: "ReLU"
  bottom: "Convolution214"
  top: "Convolution214"
}
layer {
  name: "Convolution215"
  type: "Convolution"
  bottom: "Convolution214"
  top: "Convolution215"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm215"
  type: "BatchNorm"
  bottom: "Convolution215"
  top: "Convolution215"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale215"
  type: "Scale"
  bottom: "Convolution215"
  top: "Convolution215"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU215"
  type: "ReLU"
  bottom: "Convolution215"
  top: "Convolution215"
}
layer {
  name: "Convolution216"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution216"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm216"
  type: "BatchNorm"
  bottom: "Convolution216"
  top: "Convolution216"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale216"
  type: "Scale"
  bottom: "Convolution216"
  top: "Convolution216"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU216"
  type: "ReLU"
  bottom: "Convolution216"
  top: "Convolution216"
}
layer {
  name: "Convolution217"
  type: "Convolution"
  bottom: "Convolution216"
  top: "Convolution217"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm217"
  type: "BatchNorm"
  bottom: "Convolution217"
  top: "Convolution217"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale217"
  type: "Scale"
  bottom: "Convolution217"
  top: "Convolution217"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU217"
  type: "ReLU"
  bottom: "Convolution217"
  top: "Convolution217"
}
layer {
  name: "Convolution218"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution218"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm218"
  type: "BatchNorm"
  bottom: "Convolution218"
  top: "Convolution218"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale218"
  type: "Scale"
  bottom: "Convolution218"
  top: "Convolution218"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU218"
  type: "ReLU"
  bottom: "Convolution218"
  top: "Convolution218"
}
layer {
  name: "Convolution219"
  type: "Convolution"
  bottom: "Convolution218"
  top: "Convolution219"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm219"
  type: "BatchNorm"
  bottom: "Convolution219"
  top: "Convolution219"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale219"
  type: "Scale"
  bottom: "Convolution219"
  top: "Convolution219"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU219"
  type: "ReLU"
  bottom: "Convolution219"
  top: "Convolution219"
}
layer {
  name: "Convolution220"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution220"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm220"
  type: "BatchNorm"
  bottom: "Convolution220"
  top: "Convolution220"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale220"
  type: "Scale"
  bottom: "Convolution220"
  top: "Convolution220"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU220"
  type: "ReLU"
  bottom: "Convolution220"
  top: "Convolution220"
}
layer {
  name: "Convolution221"
  type: "Convolution"
  bottom: "Convolution220"
  top: "Convolution221"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm221"
  type: "BatchNorm"
  bottom: "Convolution221"
  top: "Convolution221"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale221"
  type: "Scale"
  bottom: "Convolution221"
  top: "Convolution221"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU221"
  type: "ReLU"
  bottom: "Convolution221"
  top: "Convolution221"
}
layer {
  name: "Convolution222"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution222"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm222"
  type: "BatchNorm"
  bottom: "Convolution222"
  top: "Convolution222"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale222"
  type: "Scale"
  bottom: "Convolution222"
  top: "Convolution222"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU222"
  type: "ReLU"
  bottom: "Convolution222"
  top: "Convolution222"
}
layer {
  name: "Convolution223"
  type: "Convolution"
  bottom: "Convolution222"
  top: "Convolution223"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm223"
  type: "BatchNorm"
  bottom: "Convolution223"
  top: "Convolution223"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale223"
  type: "Scale"
  bottom: "Convolution223"
  top: "Convolution223"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU223"
  type: "ReLU"
  bottom: "Convolution223"
  top: "Convolution223"
}
layer {
  name: "Convolution224"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution224"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm224"
  type: "BatchNorm"
  bottom: "Convolution224"
  top: "Convolution224"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale224"
  type: "Scale"
  bottom: "Convolution224"
  top: "Convolution224"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU224"
  type: "ReLU"
  bottom: "Convolution224"
  top: "Convolution224"
}
layer {
  name: "Convolution225"
  type: "Convolution"
  bottom: "Convolution224"
  top: "Convolution225"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm225"
  type: "BatchNorm"
  bottom: "Convolution225"
  top: "Convolution225"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale225"
  type: "Scale"
  bottom: "Convolution225"
  top: "Convolution225"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU225"
  type: "ReLU"
  bottom: "Convolution225"
  top: "Convolution225"
}
layer {
  name: "Convolution226"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution226"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm226"
  type: "BatchNorm"
  bottom: "Convolution226"
  top: "Convolution226"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale226"
  type: "Scale"
  bottom: "Convolution226"
  top: "Convolution226"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU226"
  type: "ReLU"
  bottom: "Convolution226"
  top: "Convolution226"
}
layer {
  name: "Convolution227"
  type: "Convolution"
  bottom: "Convolution226"
  top: "Convolution227"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm227"
  type: "BatchNorm"
  bottom: "Convolution227"
  top: "Convolution227"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale227"
  type: "Scale"
  bottom: "Convolution227"
  top: "Convolution227"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU227"
  type: "ReLU"
  bottom: "Convolution227"
  top: "Convolution227"
}
layer {
  name: "Convolution228"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution228"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm228"
  type: "BatchNorm"
  bottom: "Convolution228"
  top: "Convolution228"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale228"
  type: "Scale"
  bottom: "Convolution228"
  top: "Convolution228"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU228"
  type: "ReLU"
  bottom: "Convolution228"
  top: "Convolution228"
}
layer {
  name: "Convolution229"
  type: "Convolution"
  bottom: "Convolution228"
  top: "Convolution229"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm229"
  type: "BatchNorm"
  bottom: "Convolution229"
  top: "Convolution229"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale229"
  type: "Scale"
  bottom: "Convolution229"
  top: "Convolution229"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU229"
  type: "ReLU"
  bottom: "Convolution229"
  top: "Convolution229"
}
layer {
  name: "Convolution230"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution230"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm230"
  type: "BatchNorm"
  bottom: "Convolution230"
  top: "Convolution230"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale230"
  type: "Scale"
  bottom: "Convolution230"
  top: "Convolution230"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU230"
  type: "ReLU"
  bottom: "Convolution230"
  top: "Convolution230"
}
layer {
  name: "Convolution231"
  type: "Convolution"
  bottom: "Convolution230"
  top: "Convolution231"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm231"
  type: "BatchNorm"
  bottom: "Convolution231"
  top: "Convolution231"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale231"
  type: "Scale"
  bottom: "Convolution231"
  top: "Convolution231"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU231"
  type: "ReLU"
  bottom: "Convolution231"
  top: "Convolution231"
}
layer {
  name: "Convolution232"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution232"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm232"
  type: "BatchNorm"
  bottom: "Convolution232"
  top: "Convolution232"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale232"
  type: "Scale"
  bottom: "Convolution232"
  top: "Convolution232"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU232"
  type: "ReLU"
  bottom: "Convolution232"
  top: "Convolution232"
}
layer {
  name: "Convolution233"
  type: "Convolution"
  bottom: "Convolution232"
  top: "Convolution233"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm233"
  type: "BatchNorm"
  bottom: "Convolution233"
  top: "Convolution233"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale233"
  type: "Scale"
  bottom: "Convolution233"
  top: "Convolution233"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU233"
  type: "ReLU"
  bottom: "Convolution233"
  top: "Convolution233"
}
layer {
  name: "Convolution234"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution234"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm234"
  type: "BatchNorm"
  bottom: "Convolution234"
  top: "Convolution234"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale234"
  type: "Scale"
  bottom: "Convolution234"
  top: "Convolution234"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU234"
  type: "ReLU"
  bottom: "Convolution234"
  top: "Convolution234"
}
layer {
  name: "Convolution235"
  type: "Convolution"
  bottom: "Convolution234"
  top: "Convolution235"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm235"
  type: "BatchNorm"
  bottom: "Convolution235"
  top: "Convolution235"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale235"
  type: "Scale"
  bottom: "Convolution235"
  top: "Convolution235"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU235"
  type: "ReLU"
  bottom: "Convolution235"
  top: "Convolution235"
}
layer {
  name: "Convolution236"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution236"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm236"
  type: "BatchNorm"
  bottom: "Convolution236"
  top: "Convolution236"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale236"
  type: "Scale"
  bottom: "Convolution236"
  top: "Convolution236"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU236"
  type: "ReLU"
  bottom: "Convolution236"
  top: "Convolution236"
}
layer {
  name: "Convolution237"
  type: "Convolution"
  bottom: "Convolution236"
  top: "Convolution237"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm237"
  type: "BatchNorm"
  bottom: "Convolution237"
  top: "Convolution237"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale237"
  type: "Scale"
  bottom: "Convolution237"
  top: "Convolution237"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU237"
  type: "ReLU"
  bottom: "Convolution237"
  top: "Convolution237"
}
layer {
  name: "Convolution238"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution238"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm238"
  type: "BatchNorm"
  bottom: "Convolution238"
  top: "Convolution238"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale238"
  type: "Scale"
  bottom: "Convolution238"
  top: "Convolution238"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU238"
  type: "ReLU"
  bottom: "Convolution238"
  top: "Convolution238"
}
layer {
  name: "Convolution239"
  type: "Convolution"
  bottom: "Convolution238"
  top: "Convolution239"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm239"
  type: "BatchNorm"
  bottom: "Convolution239"
  top: "Convolution239"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale239"
  type: "Scale"
  bottom: "Convolution239"
  top: "Convolution239"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU239"
  type: "ReLU"
  bottom: "Convolution239"
  top: "Convolution239"
}
layer {
  name: "Convolution240"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution240"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm240"
  type: "BatchNorm"
  bottom: "Convolution240"
  top: "Convolution240"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale240"
  type: "Scale"
  bottom: "Convolution240"
  top: "Convolution240"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU240"
  type: "ReLU"
  bottom: "Convolution240"
  top: "Convolution240"
}
layer {
  name: "Convolution241"
  type: "Convolution"
  bottom: "Convolution240"
  top: "Convolution241"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm241"
  type: "BatchNorm"
  bottom: "Convolution241"
  top: "Convolution241"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale241"
  type: "Scale"
  bottom: "Convolution241"
  top: "Convolution241"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU241"
  type: "ReLU"
  bottom: "Convolution241"
  top: "Convolution241"
}
layer {
  name: "Convolution242"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution242"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm242"
  type: "BatchNorm"
  bottom: "Convolution242"
  top: "Convolution242"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale242"
  type: "Scale"
  bottom: "Convolution242"
  top: "Convolution242"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU242"
  type: "ReLU"
  bottom: "Convolution242"
  top: "Convolution242"
}
layer {
  name: "Convolution243"
  type: "Convolution"
  bottom: "Convolution242"
  top: "Convolution243"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm243"
  type: "BatchNorm"
  bottom: "Convolution243"
  top: "Convolution243"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale243"
  type: "Scale"
  bottom: "Convolution243"
  top: "Convolution243"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU243"
  type: "ReLU"
  bottom: "Convolution243"
  top: "Convolution243"
}
layer {
  name: "Convolution244"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution244"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm244"
  type: "BatchNorm"
  bottom: "Convolution244"
  top: "Convolution244"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale244"
  type: "Scale"
  bottom: "Convolution244"
  top: "Convolution244"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU244"
  type: "ReLU"
  bottom: "Convolution244"
  top: "Convolution244"
}
layer {
  name: "Convolution245"
  type: "Convolution"
  bottom: "Convolution244"
  top: "Convolution245"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm245"
  type: "BatchNorm"
  bottom: "Convolution245"
  top: "Convolution245"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale245"
  type: "Scale"
  bottom: "Convolution245"
  top: "Convolution245"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU245"
  type: "ReLU"
  bottom: "Convolution245"
  top: "Convolution245"
}
layer {
  name: "Convolution246"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution246"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm246"
  type: "BatchNorm"
  bottom: "Convolution246"
  top: "Convolution246"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale246"
  type: "Scale"
  bottom: "Convolution246"
  top: "Convolution246"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU246"
  type: "ReLU"
  bottom: "Convolution246"
  top: "Convolution246"
}
layer {
  name: "Convolution247"
  type: "Convolution"
  bottom: "Convolution246"
  top: "Convolution247"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm247"
  type: "BatchNorm"
  bottom: "Convolution247"
  top: "Convolution247"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale247"
  type: "Scale"
  bottom: "Convolution247"
  top: "Convolution247"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU247"
  type: "ReLU"
  bottom: "Convolution247"
  top: "Convolution247"
}
layer {
  name: "Convolution248"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution248"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm248"
  type: "BatchNorm"
  bottom: "Convolution248"
  top: "Convolution248"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale248"
  type: "Scale"
  bottom: "Convolution248"
  top: "Convolution248"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU248"
  type: "ReLU"
  bottom: "Convolution248"
  top: "Convolution248"
}
layer {
  name: "Convolution249"
  type: "Convolution"
  bottom: "Convolution248"
  top: "Convolution249"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm249"
  type: "BatchNorm"
  bottom: "Convolution249"
  top: "Convolution249"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale249"
  type: "Scale"
  bottom: "Convolution249"
  top: "Convolution249"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU249"
  type: "ReLU"
  bottom: "Convolution249"
  top: "Convolution249"
}
layer {
  name: "Convolution250"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution250"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm250"
  type: "BatchNorm"
  bottom: "Convolution250"
  top: "Convolution250"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale250"
  type: "Scale"
  bottom: "Convolution250"
  top: "Convolution250"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU250"
  type: "ReLU"
  bottom: "Convolution250"
  top: "Convolution250"
}
layer {
  name: "Convolution251"
  type: "Convolution"
  bottom: "Convolution250"
  top: "Convolution251"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm251"
  type: "BatchNorm"
  bottom: "Convolution251"
  top: "Convolution251"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale251"
  type: "Scale"
  bottom: "Convolution251"
  top: "Convolution251"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU251"
  type: "ReLU"
  bottom: "Convolution251"
  top: "Convolution251"
}
layer {
  name: "Convolution252"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution252"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm252"
  type: "BatchNorm"
  bottom: "Convolution252"
  top: "Convolution252"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale252"
  type: "Scale"
  bottom: "Convolution252"
  top: "Convolution252"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU252"
  type: "ReLU"
  bottom: "Convolution252"
  top: "Convolution252"
}
layer {
  name: "Convolution253"
  type: "Convolution"
  bottom: "Convolution252"
  top: "Convolution253"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm253"
  type: "BatchNorm"
  bottom: "Convolution253"
  top: "Convolution253"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale253"
  type: "Scale"
  bottom: "Convolution253"
  top: "Convolution253"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU253"
  type: "ReLU"
  bottom: "Convolution253"
  top: "Convolution253"
}
layer {
  name: "Convolution254"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution254"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm254"
  type: "BatchNorm"
  bottom: "Convolution254"
  top: "Convolution254"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale254"
  type: "Scale"
  bottom: "Convolution254"
  top: "Convolution254"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU254"
  type: "ReLU"
  bottom: "Convolution254"
  top: "Convolution254"
}
layer {
  name: "Convolution255"
  type: "Convolution"
  bottom: "Convolution254"
  top: "Convolution255"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm255"
  type: "BatchNorm"
  bottom: "Convolution255"
  top: "Convolution255"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale255"
  type: "Scale"
  bottom: "Convolution255"
  top: "Convolution255"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU255"
  type: "ReLU"
  bottom: "Convolution255"
  top: "Convolution255"
}
layer {
  name: "Convolution256"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution256"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm256"
  type: "BatchNorm"
  bottom: "Convolution256"
  top: "Convolution256"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale256"
  type: "Scale"
  bottom: "Convolution256"
  top: "Convolution256"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU256"
  type: "ReLU"
  bottom: "Convolution256"
  top: "Convolution256"
}
layer {
  name: "Convolution257"
  type: "Convolution"
  bottom: "Convolution256"
  top: "Convolution257"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm257"
  type: "BatchNorm"
  bottom: "Convolution257"
  top: "Convolution257"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale257"
  type: "Scale"
  bottom: "Convolution257"
  top: "Convolution257"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU257"
  type: "ReLU"
  bottom: "Convolution257"
  top: "Convolution257"
}
layer {
  name: "Convolution258"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution258"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm258"
  type: "BatchNorm"
  bottom: "Convolution258"
  top: "Convolution258"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale258"
  type: "Scale"
  bottom: "Convolution258"
  top: "Convolution258"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU258"
  type: "ReLU"
  bottom: "Convolution258"
  top: "Convolution258"
}
layer {
  name: "Convolution259"
  type: "Convolution"
  bottom: "Convolution258"
  top: "Convolution259"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm259"
  type: "BatchNorm"
  bottom: "Convolution259"
  top: "Convolution259"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale259"
  type: "Scale"
  bottom: "Convolution259"
  top: "Convolution259"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU259"
  type: "ReLU"
  bottom: "Convolution259"
  top: "Convolution259"
}
layer {
  name: "Convolution260"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution260"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm260"
  type: "BatchNorm"
  bottom: "Convolution260"
  top: "Convolution260"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale260"
  type: "Scale"
  bottom: "Convolution260"
  top: "Convolution260"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU260"
  type: "ReLU"
  bottom: "Convolution260"
  top: "Convolution260"
}
layer {
  name: "Convolution261"
  type: "Convolution"
  bottom: "Convolution260"
  top: "Convolution261"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm261"
  type: "BatchNorm"
  bottom: "Convolution261"
  top: "Convolution261"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale261"
  type: "Scale"
  bottom: "Convolution261"
  top: "Convolution261"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU261"
  type: "ReLU"
  bottom: "Convolution261"
  top: "Convolution261"
}
layer {
  name: "Convolution262"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution262"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm262"
  type: "BatchNorm"
  bottom: "Convolution262"
  top: "Convolution262"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale262"
  type: "Scale"
  bottom: "Convolution262"
  top: "Convolution262"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU262"
  type: "ReLU"
  bottom: "Convolution262"
  top: "Convolution262"
}
layer {
  name: "Convolution263"
  type: "Convolution"
  bottom: "Convolution262"
  top: "Convolution263"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm263"
  type: "BatchNorm"
  bottom: "Convolution263"
  top: "Convolution263"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale263"
  type: "Scale"
  bottom: "Convolution263"
  top: "Convolution263"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU263"
  type: "ReLU"
  bottom: "Convolution263"
  top: "Convolution263"
}
layer {
  name: "Concat4"
  type: "Concat"
  bottom: "Convolution201"
  bottom: "Convolution203"
  bottom: "Convolution205"
  bottom: "Convolution207"
  bottom: "Convolution209"
  bottom: "Convolution211"
  bottom: "Convolution213"
  bottom: "Convolution215"
  bottom: "Convolution217"
  bottom: "Convolution219"
  bottom: "Convolution221"
  bottom: "Convolution223"
  bottom: "Convolution225"
  bottom: "Convolution227"
  bottom: "Convolution229"
  bottom: "Convolution231"
  bottom: "Convolution233"
  bottom: "Convolution235"
  bottom: "Convolution237"
  bottom: "Convolution239"
  bottom: "Convolution241"
  bottom: "Convolution243"
  bottom: "Convolution245"
  bottom: "Convolution247"
  bottom: "Convolution249"
  bottom: "Convolution251"
  bottom: "Convolution253"
  bottom: "Convolution255"
  bottom: "Convolution257"
  bottom: "Convolution259"
  bottom: "Convolution261"
  bottom: "Convolution263"
  top: "Concat4"
}
layer {
  name: "Convolution264"
  type: "Convolution"
  bottom: "Concat4"
  top: "Convolution264"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm264"
  type: "BatchNorm"
  bottom: "Convolution264"
  top: "Convolution264"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale264"
  type: "Scale"
  bottom: "Convolution264"
  top: "Convolution264"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU264"
  type: "ReLU"
  bottom: "Convolution264"
  top: "Convolution264"
}
layer {
  name: "Convolution265"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution265"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm265"
  type: "BatchNorm"
  bottom: "Convolution265"
  top: "Convolution265"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale265"
  type: "Scale"
  bottom: "Convolution265"
  top: "Convolution265"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU265"
  type: "ReLU"
  bottom: "Convolution265"
  top: "Convolution265"
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution264"
  bottom: "Convolution265"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution266"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution266"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm266"
  type: "BatchNorm"
  bottom: "Convolution266"
  top: "Convolution266"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale266"
  type: "Scale"
  bottom: "Convolution266"
  top: "Convolution266"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU266"
  type: "ReLU"
  bottom: "Convolution266"
  top: "Convolution266"
}
layer {
  name: "Convolution267"
  type: "Convolution"
  bottom: "Convolution266"
  top: "Convolution267"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm267"
  type: "BatchNorm"
  bottom: "Convolution267"
  top: "Convolution267"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale267"
  type: "Scale"
  bottom: "Convolution267"
  top: "Convolution267"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU267"
  type: "ReLU"
  bottom: "Convolution267"
  top: "Convolution267"
}
layer {
  name: "Convolution268"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution268"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm268"
  type: "BatchNorm"
  bottom: "Convolution268"
  top: "Convolution268"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale268"
  type: "Scale"
  bottom: "Convolution268"
  top: "Convolution268"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU268"
  type: "ReLU"
  bottom: "Convolution268"
  top: "Convolution268"
}
layer {
  name: "Convolution269"
  type: "Convolution"
  bottom: "Convolution268"
  top: "Convolution269"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm269"
  type: "BatchNorm"
  bottom: "Convolution269"
  top: "Convolution269"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale269"
  type: "Scale"
  bottom: "Convolution269"
  top: "Convolution269"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU269"
  type: "ReLU"
  bottom: "Convolution269"
  top: "Convolution269"
}
layer {
  name: "Convolution270"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution270"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm270"
  type: "BatchNorm"
  bottom: "Convolution270"
  top: "Convolution270"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale270"
  type: "Scale"
  bottom: "Convolution270"
  top: "Convolution270"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU270"
  type: "ReLU"
  bottom: "Convolution270"
  top: "Convolution270"
}
layer {
  name: "Convolution271"
  type: "Convolution"
  bottom: "Convolution270"
  top: "Convolution271"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm271"
  type: "BatchNorm"
  bottom: "Convolution271"
  top: "Convolution271"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale271"
  type: "Scale"
  bottom: "Convolution271"
  top: "Convolution271"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU271"
  type: "ReLU"
  bottom: "Convolution271"
  top: "Convolution271"
}
layer {
  name: "Convolution272"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution272"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm272"
  type: "BatchNorm"
  bottom: "Convolution272"
  top: "Convolution272"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale272"
  type: "Scale"
  bottom: "Convolution272"
  top: "Convolution272"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU272"
  type: "ReLU"
  bottom: "Convolution272"
  top: "Convolution272"
}
layer {
  name: "Convolution273"
  type: "Convolution"
  bottom: "Convolution272"
  top: "Convolution273"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm273"
  type: "BatchNorm"
  bottom: "Convolution273"
  top: "Convolution273"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale273"
  type: "Scale"
  bottom: "Convolution273"
  top: "Convolution273"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU273"
  type: "ReLU"
  bottom: "Convolution273"
  top: "Convolution273"
}
layer {
  name: "Convolution274"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution274"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm274"
  type: "BatchNorm"
  bottom: "Convolution274"
  top: "Convolution274"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale274"
  type: "Scale"
  bottom: "Convolution274"
  top: "Convolution274"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU274"
  type: "ReLU"
  bottom: "Convolution274"
  top: "Convolution274"
}
layer {
  name: "Convolution275"
  type: "Convolution"
  bottom: "Convolution274"
  top: "Convolution275"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm275"
  type: "BatchNorm"
  bottom: "Convolution275"
  top: "Convolution275"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale275"
  type: "Scale"
  bottom: "Convolution275"
  top: "Convolution275"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU275"
  type: "ReLU"
  bottom: "Convolution275"
  top: "Convolution275"
}
layer {
  name: "Convolution276"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution276"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm276"
  type: "BatchNorm"
  bottom: "Convolution276"
  top: "Convolution276"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale276"
  type: "Scale"
  bottom: "Convolution276"
  top: "Convolution276"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU276"
  type: "ReLU"
  bottom: "Convolution276"
  top: "Convolution276"
}
layer {
  name: "Convolution277"
  type: "Convolution"
  bottom: "Convolution276"
  top: "Convolution277"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm277"
  type: "BatchNorm"
  bottom: "Convolution277"
  top: "Convolution277"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale277"
  type: "Scale"
  bottom: "Convolution277"
  top: "Convolution277"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU277"
  type: "ReLU"
  bottom: "Convolution277"
  top: "Convolution277"
}
layer {
  name: "Convolution278"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution278"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm278"
  type: "BatchNorm"
  bottom: "Convolution278"
  top: "Convolution278"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale278"
  type: "Scale"
  bottom: "Convolution278"
  top: "Convolution278"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU278"
  type: "ReLU"
  bottom: "Convolution278"
  top: "Convolution278"
}
layer {
  name: "Convolution279"
  type: "Convolution"
  bottom: "Convolution278"
  top: "Convolution279"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm279"
  type: "BatchNorm"
  bottom: "Convolution279"
  top: "Convolution279"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale279"
  type: "Scale"
  bottom: "Convolution279"
  top: "Convolution279"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU279"
  type: "ReLU"
  bottom: "Convolution279"
  top: "Convolution279"
}
layer {
  name: "Convolution280"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution280"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm280"
  type: "BatchNorm"
  bottom: "Convolution280"
  top: "Convolution280"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale280"
  type: "Scale"
  bottom: "Convolution280"
  top: "Convolution280"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU280"
  type: "ReLU"
  bottom: "Convolution280"
  top: "Convolution280"
}
layer {
  name: "Convolution281"
  type: "Convolution"
  bottom: "Convolution280"
  top: "Convolution281"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm281"
  type: "BatchNorm"
  bottom: "Convolution281"
  top: "Convolution281"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale281"
  type: "Scale"
  bottom: "Convolution281"
  top: "Convolution281"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU281"
  type: "ReLU"
  bottom: "Convolution281"
  top: "Convolution281"
}
layer {
  name: "Convolution282"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution282"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm282"
  type: "BatchNorm"
  bottom: "Convolution282"
  top: "Convolution282"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale282"
  type: "Scale"
  bottom: "Convolution282"
  top: "Convolution282"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU282"
  type: "ReLU"
  bottom: "Convolution282"
  top: "Convolution282"
}
layer {
  name: "Convolution283"
  type: "Convolution"
  bottom: "Convolution282"
  top: "Convolution283"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm283"
  type: "BatchNorm"
  bottom: "Convolution283"
  top: "Convolution283"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale283"
  type: "Scale"
  bottom: "Convolution283"
  top: "Convolution283"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU283"
  type: "ReLU"
  bottom: "Convolution283"
  top: "Convolution283"
}
layer {
  name: "Convolution284"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution284"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm284"
  type: "BatchNorm"
  bottom: "Convolution284"
  top: "Convolution284"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale284"
  type: "Scale"
  bottom: "Convolution284"
  top: "Convolution284"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU284"
  type: "ReLU"
  bottom: "Convolution284"
  top: "Convolution284"
}
layer {
  name: "Convolution285"
  type: "Convolution"
  bottom: "Convolution284"
  top: "Convolution285"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm285"
  type: "BatchNorm"
  bottom: "Convolution285"
  top: "Convolution285"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale285"
  type: "Scale"
  bottom: "Convolution285"
  top: "Convolution285"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU285"
  type: "ReLU"
  bottom: "Convolution285"
  top: "Convolution285"
}
layer {
  name: "Convolution286"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution286"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm286"
  type: "BatchNorm"
  bottom: "Convolution286"
  top: "Convolution286"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale286"
  type: "Scale"
  bottom: "Convolution286"
  top: "Convolution286"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU286"
  type: "ReLU"
  bottom: "Convolution286"
  top: "Convolution286"
}
layer {
  name: "Convolution287"
  type: "Convolution"
  bottom: "Convolution286"
  top: "Convolution287"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm287"
  type: "BatchNorm"
  bottom: "Convolution287"
  top: "Convolution287"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale287"
  type: "Scale"
  bottom: "Convolution287"
  top: "Convolution287"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU287"
  type: "ReLU"
  bottom: "Convolution287"
  top: "Convolution287"
}
layer {
  name: "Convolution288"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution288"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm288"
  type: "BatchNorm"
  bottom: "Convolution288"
  top: "Convolution288"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale288"
  type: "Scale"
  bottom: "Convolution288"
  top: "Convolution288"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU288"
  type: "ReLU"
  bottom: "Convolution288"
  top: "Convolution288"
}
layer {
  name: "Convolution289"
  type: "Convolution"
  bottom: "Convolution288"
  top: "Convolution289"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm289"
  type: "BatchNorm"
  bottom: "Convolution289"
  top: "Convolution289"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale289"
  type: "Scale"
  bottom: "Convolution289"
  top: "Convolution289"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU289"
  type: "ReLU"
  bottom: "Convolution289"
  top: "Convolution289"
}
layer {
  name: "Convolution290"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution290"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm290"
  type: "BatchNorm"
  bottom: "Convolution290"
  top: "Convolution290"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale290"
  type: "Scale"
  bottom: "Convolution290"
  top: "Convolution290"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU290"
  type: "ReLU"
  bottom: "Convolution290"
  top: "Convolution290"
}
layer {
  name: "Convolution291"
  type: "Convolution"
  bottom: "Convolution290"
  top: "Convolution291"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm291"
  type: "BatchNorm"
  bottom: "Convolution291"
  top: "Convolution291"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale291"
  type: "Scale"
  bottom: "Convolution291"
  top: "Convolution291"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU291"
  type: "ReLU"
  bottom: "Convolution291"
  top: "Convolution291"
}
layer {
  name: "Convolution292"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution292"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm292"
  type: "BatchNorm"
  bottom: "Convolution292"
  top: "Convolution292"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale292"
  type: "Scale"
  bottom: "Convolution292"
  top: "Convolution292"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU292"
  type: "ReLU"
  bottom: "Convolution292"
  top: "Convolution292"
}
layer {
  name: "Convolution293"
  type: "Convolution"
  bottom: "Convolution292"
  top: "Convolution293"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm293"
  type: "BatchNorm"
  bottom: "Convolution293"
  top: "Convolution293"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale293"
  type: "Scale"
  bottom: "Convolution293"
  top: "Convolution293"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU293"
  type: "ReLU"
  bottom: "Convolution293"
  top: "Convolution293"
}
layer {
  name: "Convolution294"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution294"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm294"
  type: "BatchNorm"
  bottom: "Convolution294"
  top: "Convolution294"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale294"
  type: "Scale"
  bottom: "Convolution294"
  top: "Convolution294"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU294"
  type: "ReLU"
  bottom: "Convolution294"
  top: "Convolution294"
}
layer {
  name: "Convolution295"
  type: "Convolution"
  bottom: "Convolution294"
  top: "Convolution295"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm295"
  type: "BatchNorm"
  bottom: "Convolution295"
  top: "Convolution295"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale295"
  type: "Scale"
  bottom: "Convolution295"
  top: "Convolution295"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU295"
  type: "ReLU"
  bottom: "Convolution295"
  top: "Convolution295"
}
layer {
  name: "Convolution296"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution296"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm296"
  type: "BatchNorm"
  bottom: "Convolution296"
  top: "Convolution296"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale296"
  type: "Scale"
  bottom: "Convolution296"
  top: "Convolution296"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU296"
  type: "ReLU"
  bottom: "Convolution296"
  top: "Convolution296"
}
layer {
  name: "Convolution297"
  type: "Convolution"
  bottom: "Convolution296"
  top: "Convolution297"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm297"
  type: "BatchNorm"
  bottom: "Convolution297"
  top: "Convolution297"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale297"
  type: "Scale"
  bottom: "Convolution297"
  top: "Convolution297"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU297"
  type: "ReLU"
  bottom: "Convolution297"
  top: "Convolution297"
}
layer {
  name: "Convolution298"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution298"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm298"
  type: "BatchNorm"
  bottom: "Convolution298"
  top: "Convolution298"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale298"
  type: "Scale"
  bottom: "Convolution298"
  top: "Convolution298"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU298"
  type: "ReLU"
  bottom: "Convolution298"
  top: "Convolution298"
}
layer {
  name: "Convolution299"
  type: "Convolution"
  bottom: "Convolution298"
  top: "Convolution299"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm299"
  type: "BatchNorm"
  bottom: "Convolution299"
  top: "Convolution299"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale299"
  type: "Scale"
  bottom: "Convolution299"
  top: "Convolution299"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU299"
  type: "ReLU"
  bottom: "Convolution299"
  top: "Convolution299"
}
layer {
  name: "Convolution300"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution300"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm300"
  type: "BatchNorm"
  bottom: "Convolution300"
  top: "Convolution300"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale300"
  type: "Scale"
  bottom: "Convolution300"
  top: "Convolution300"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU300"
  type: "ReLU"
  bottom: "Convolution300"
  top: "Convolution300"
}
layer {
  name: "Convolution301"
  type: "Convolution"
  bottom: "Convolution300"
  top: "Convolution301"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm301"
  type: "BatchNorm"
  bottom: "Convolution301"
  top: "Convolution301"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale301"
  type: "Scale"
  bottom: "Convolution301"
  top: "Convolution301"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU301"
  type: "ReLU"
  bottom: "Convolution301"
  top: "Convolution301"
}
layer {
  name: "Convolution302"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution302"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm302"
  type: "BatchNorm"
  bottom: "Convolution302"
  top: "Convolution302"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale302"
  type: "Scale"
  bottom: "Convolution302"
  top: "Convolution302"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU302"
  type: "ReLU"
  bottom: "Convolution302"
  top: "Convolution302"
}
layer {
  name: "Convolution303"
  type: "Convolution"
  bottom: "Convolution302"
  top: "Convolution303"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm303"
  type: "BatchNorm"
  bottom: "Convolution303"
  top: "Convolution303"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale303"
  type: "Scale"
  bottom: "Convolution303"
  top: "Convolution303"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU303"
  type: "ReLU"
  bottom: "Convolution303"
  top: "Convolution303"
}
layer {
  name: "Convolution304"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution304"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm304"
  type: "BatchNorm"
  bottom: "Convolution304"
  top: "Convolution304"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale304"
  type: "Scale"
  bottom: "Convolution304"
  top: "Convolution304"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU304"
  type: "ReLU"
  bottom: "Convolution304"
  top: "Convolution304"
}
layer {
  name: "Convolution305"
  type: "Convolution"
  bottom: "Convolution304"
  top: "Convolution305"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm305"
  type: "BatchNorm"
  bottom: "Convolution305"
  top: "Convolution305"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale305"
  type: "Scale"
  bottom: "Convolution305"
  top: "Convolution305"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU305"
  type: "ReLU"
  bottom: "Convolution305"
  top: "Convolution305"
}
layer {
  name: "Convolution306"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution306"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm306"
  type: "BatchNorm"
  bottom: "Convolution306"
  top: "Convolution306"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale306"
  type: "Scale"
  bottom: "Convolution306"
  top: "Convolution306"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU306"
  type: "ReLU"
  bottom: "Convolution306"
  top: "Convolution306"
}
layer {
  name: "Convolution307"
  type: "Convolution"
  bottom: "Convolution306"
  top: "Convolution307"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm307"
  type: "BatchNorm"
  bottom: "Convolution307"
  top: "Convolution307"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale307"
  type: "Scale"
  bottom: "Convolution307"
  top: "Convolution307"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU307"
  type: "ReLU"
  bottom: "Convolution307"
  top: "Convolution307"
}
layer {
  name: "Convolution308"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution308"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm308"
  type: "BatchNorm"
  bottom: "Convolution308"
  top: "Convolution308"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale308"
  type: "Scale"
  bottom: "Convolution308"
  top: "Convolution308"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU308"
  type: "ReLU"
  bottom: "Convolution308"
  top: "Convolution308"
}
layer {
  name: "Convolution309"
  type: "Convolution"
  bottom: "Convolution308"
  top: "Convolution309"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm309"
  type: "BatchNorm"
  bottom: "Convolution309"
  top: "Convolution309"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale309"
  type: "Scale"
  bottom: "Convolution309"
  top: "Convolution309"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU309"
  type: "ReLU"
  bottom: "Convolution309"
  top: "Convolution309"
}
layer {
  name: "Convolution310"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution310"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm310"
  type: "BatchNorm"
  bottom: "Convolution310"
  top: "Convolution310"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale310"
  type: "Scale"
  bottom: "Convolution310"
  top: "Convolution310"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU310"
  type: "ReLU"
  bottom: "Convolution310"
  top: "Convolution310"
}
layer {
  name: "Convolution311"
  type: "Convolution"
  bottom: "Convolution310"
  top: "Convolution311"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm311"
  type: "BatchNorm"
  bottom: "Convolution311"
  top: "Convolution311"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale311"
  type: "Scale"
  bottom: "Convolution311"
  top: "Convolution311"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU311"
  type: "ReLU"
  bottom: "Convolution311"
  top: "Convolution311"
}
layer {
  name: "Convolution312"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution312"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm312"
  type: "BatchNorm"
  bottom: "Convolution312"
  top: "Convolution312"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale312"
  type: "Scale"
  bottom: "Convolution312"
  top: "Convolution312"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU312"
  type: "ReLU"
  bottom: "Convolution312"
  top: "Convolution312"
}
layer {
  name: "Convolution313"
  type: "Convolution"
  bottom: "Convolution312"
  top: "Convolution313"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm313"
  type: "BatchNorm"
  bottom: "Convolution313"
  top: "Convolution313"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale313"
  type: "Scale"
  bottom: "Convolution313"
  top: "Convolution313"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU313"
  type: "ReLU"
  bottom: "Convolution313"
  top: "Convolution313"
}
layer {
  name: "Convolution314"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution314"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm314"
  type: "BatchNorm"
  bottom: "Convolution314"
  top: "Convolution314"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale314"
  type: "Scale"
  bottom: "Convolution314"
  top: "Convolution314"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU314"
  type: "ReLU"
  bottom: "Convolution314"
  top: "Convolution314"
}
layer {
  name: "Convolution315"
  type: "Convolution"
  bottom: "Convolution314"
  top: "Convolution315"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm315"
  type: "BatchNorm"
  bottom: "Convolution315"
  top: "Convolution315"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale315"
  type: "Scale"
  bottom: "Convolution315"
  top: "Convolution315"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU315"
  type: "ReLU"
  bottom: "Convolution315"
  top: "Convolution315"
}
layer {
  name: "Convolution316"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution316"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm316"
  type: "BatchNorm"
  bottom: "Convolution316"
  top: "Convolution316"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale316"
  type: "Scale"
  bottom: "Convolution316"
  top: "Convolution316"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU316"
  type: "ReLU"
  bottom: "Convolution316"
  top: "Convolution316"
}
layer {
  name: "Convolution317"
  type: "Convolution"
  bottom: "Convolution316"
  top: "Convolution317"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm317"
  type: "BatchNorm"
  bottom: "Convolution317"
  top: "Convolution317"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale317"
  type: "Scale"
  bottom: "Convolution317"
  top: "Convolution317"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU317"
  type: "ReLU"
  bottom: "Convolution317"
  top: "Convolution317"
}
layer {
  name: "Convolution318"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution318"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm318"
  type: "BatchNorm"
  bottom: "Convolution318"
  top: "Convolution318"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale318"
  type: "Scale"
  bottom: "Convolution318"
  top: "Convolution318"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU318"
  type: "ReLU"
  bottom: "Convolution318"
  top: "Convolution318"
}
layer {
  name: "Convolution319"
  type: "Convolution"
  bottom: "Convolution318"
  top: "Convolution319"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm319"
  type: "BatchNorm"
  bottom: "Convolution319"
  top: "Convolution319"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale319"
  type: "Scale"
  bottom: "Convolution319"
  top: "Convolution319"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU319"
  type: "ReLU"
  bottom: "Convolution319"
  top: "Convolution319"
}
layer {
  name: "Convolution320"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution320"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm320"
  type: "BatchNorm"
  bottom: "Convolution320"
  top: "Convolution320"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale320"
  type: "Scale"
  bottom: "Convolution320"
  top: "Convolution320"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU320"
  type: "ReLU"
  bottom: "Convolution320"
  top: "Convolution320"
}
layer {
  name: "Convolution321"
  type: "Convolution"
  bottom: "Convolution320"
  top: "Convolution321"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm321"
  type: "BatchNorm"
  bottom: "Convolution321"
  top: "Convolution321"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale321"
  type: "Scale"
  bottom: "Convolution321"
  top: "Convolution321"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU321"
  type: "ReLU"
  bottom: "Convolution321"
  top: "Convolution321"
}
layer {
  name: "Convolution322"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution322"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm322"
  type: "BatchNorm"
  bottom: "Convolution322"
  top: "Convolution322"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale322"
  type: "Scale"
  bottom: "Convolution322"
  top: "Convolution322"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU322"
  type: "ReLU"
  bottom: "Convolution322"
  top: "Convolution322"
}
layer {
  name: "Convolution323"
  type: "Convolution"
  bottom: "Convolution322"
  top: "Convolution323"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm323"
  type: "BatchNorm"
  bottom: "Convolution323"
  top: "Convolution323"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale323"
  type: "Scale"
  bottom: "Convolution323"
  top: "Convolution323"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU323"
  type: "ReLU"
  bottom: "Convolution323"
  top: "Convolution323"
}
layer {
  name: "Convolution324"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution324"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm324"
  type: "BatchNorm"
  bottom: "Convolution324"
  top: "Convolution324"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale324"
  type: "Scale"
  bottom: "Convolution324"
  top: "Convolution324"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU324"
  type: "ReLU"
  bottom: "Convolution324"
  top: "Convolution324"
}
layer {
  name: "Convolution325"
  type: "Convolution"
  bottom: "Convolution324"
  top: "Convolution325"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm325"
  type: "BatchNorm"
  bottom: "Convolution325"
  top: "Convolution325"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale325"
  type: "Scale"
  bottom: "Convolution325"
  top: "Convolution325"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU325"
  type: "ReLU"
  bottom: "Convolution325"
  top: "Convolution325"
}
layer {
  name: "Convolution326"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution326"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm326"
  type: "BatchNorm"
  bottom: "Convolution326"
  top: "Convolution326"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale326"
  type: "Scale"
  bottom: "Convolution326"
  top: "Convolution326"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU326"
  type: "ReLU"
  bottom: "Convolution326"
  top: "Convolution326"
}
layer {
  name: "Convolution327"
  type: "Convolution"
  bottom: "Convolution326"
  top: "Convolution327"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm327"
  type: "BatchNorm"
  bottom: "Convolution327"
  top: "Convolution327"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale327"
  type: "Scale"
  bottom: "Convolution327"
  top: "Convolution327"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU327"
  type: "ReLU"
  bottom: "Convolution327"
  top: "Convolution327"
}
layer {
  name: "Convolution328"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution328"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm328"
  type: "BatchNorm"
  bottom: "Convolution328"
  top: "Convolution328"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale328"
  type: "Scale"
  bottom: "Convolution328"
  top: "Convolution328"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU328"
  type: "ReLU"
  bottom: "Convolution328"
  top: "Convolution328"
}
layer {
  name: "Convolution329"
  type: "Convolution"
  bottom: "Convolution328"
  top: "Convolution329"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm329"
  type: "BatchNorm"
  bottom: "Convolution329"
  top: "Convolution329"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale329"
  type: "Scale"
  bottom: "Convolution329"
  top: "Convolution329"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU329"
  type: "ReLU"
  bottom: "Convolution329"
  top: "Convolution329"
}
layer {
  name: "Concat5"
  type: "Concat"
  bottom: "Convolution267"
  bottom: "Convolution269"
  bottom: "Convolution271"
  bottom: "Convolution273"
  bottom: "Convolution275"
  bottom: "Convolution277"
  bottom: "Convolution279"
  bottom: "Convolution281"
  bottom: "Convolution283"
  bottom: "Convolution285"
  bottom: "Convolution287"
  bottom: "Convolution289"
  bottom: "Convolution291"
  bottom: "Convolution293"
  bottom: "Convolution295"
  bottom: "Convolution297"
  bottom: "Convolution299"
  bottom: "Convolution301"
  bottom: "Convolution303"
  bottom: "Convolution305"
  bottom: "Convolution307"
  bottom: "Convolution309"
  bottom: "Convolution311"
  bottom: "Convolution313"
  bottom: "Convolution315"
  bottom: "Convolution317"
  bottom: "Convolution319"
  bottom: "Convolution321"
  bottom: "Convolution323"
  bottom: "Convolution325"
  bottom: "Convolution327"
  bottom: "Convolution329"
  top: "Concat5"
}
layer {
  name: "Convolution330"
  type: "Convolution"
  bottom: "Concat5"
  top: "Convolution330"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm330"
  type: "BatchNorm"
  bottom: "Convolution330"
  top: "Convolution330"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale330"
  type: "Scale"
  bottom: "Convolution330"
  top: "Convolution330"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU330"
  type: "ReLU"
  bottom: "Convolution330"
  top: "Convolution330"
}
layer {
  name: "Convolution331"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution331"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm331"
  type: "BatchNorm"
  bottom: "Convolution331"
  top: "Convolution331"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale331"
  type: "Scale"
  bottom: "Convolution331"
  top: "Convolution331"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU331"
  type: "ReLU"
  bottom: "Convolution331"
  top: "Convolution331"
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Convolution330"
  bottom: "Convolution331"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution332"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution332"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm332"
  type: "BatchNorm"
  bottom: "Convolution332"
  top: "Convolution332"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale332"
  type: "Scale"
  bottom: "Convolution332"
  top: "Convolution332"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU332"
  type: "ReLU"
  bottom: "Convolution332"
  top: "Convolution332"
}
layer {
  name: "Convolution333"
  type: "Convolution"
  bottom: "Convolution332"
  top: "Convolution333"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm333"
  type: "BatchNorm"
  bottom: "Convolution333"
  top: "Convolution333"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale333"
  type: "Scale"
  bottom: "Convolution333"
  top: "Convolution333"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU333"
  type: "ReLU"
  bottom: "Convolution333"
  top: "Convolution333"
}
layer {
  name: "Convolution334"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution334"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm334"
  type: "BatchNorm"
  bottom: "Convolution334"
  top: "Convolution334"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale334"
  type: "Scale"
  bottom: "Convolution334"
  top: "Convolution334"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU334"
  type: "ReLU"
  bottom: "Convolution334"
  top: "Convolution334"
}
layer {
  name: "Convolution335"
  type: "Convolution"
  bottom: "Convolution334"
  top: "Convolution335"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm335"
  type: "BatchNorm"
  bottom: "Convolution335"
  top: "Convolution335"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale335"
  type: "Scale"
  bottom: "Convolution335"
  top: "Convolution335"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU335"
  type: "ReLU"
  bottom: "Convolution335"
  top: "Convolution335"
}
layer {
  name: "Convolution336"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution336"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm336"
  type: "BatchNorm"
  bottom: "Convolution336"
  top: "Convolution336"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale336"
  type: "Scale"
  bottom: "Convolution336"
  top: "Convolution336"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU336"
  type: "ReLU"
  bottom: "Convolution336"
  top: "Convolution336"
}
layer {
  name: "Convolution337"
  type: "Convolution"
  bottom: "Convolution336"
  top: "Convolution337"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm337"
  type: "BatchNorm"
  bottom: "Convolution337"
  top: "Convolution337"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale337"
  type: "Scale"
  bottom: "Convolution337"
  top: "Convolution337"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU337"
  type: "ReLU"
  bottom: "Convolution337"
  top: "Convolution337"
}
layer {
  name: "Convolution338"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution338"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm338"
  type: "BatchNorm"
  bottom: "Convolution338"
  top: "Convolution338"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale338"
  type: "Scale"
  bottom: "Convolution338"
  top: "Convolution338"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU338"
  type: "ReLU"
  bottom: "Convolution338"
  top: "Convolution338"
}
layer {
  name: "Convolution339"
  type: "Convolution"
  bottom: "Convolution338"
  top: "Convolution339"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm339"
  type: "BatchNorm"
  bottom: "Convolution339"
  top: "Convolution339"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale339"
  type: "Scale"
  bottom: "Convolution339"
  top: "Convolution339"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU339"
  type: "ReLU"
  bottom: "Convolution339"
  top: "Convolution339"
}
layer {
  name: "Convolution340"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution340"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm340"
  type: "BatchNorm"
  bottom: "Convolution340"
  top: "Convolution340"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale340"
  type: "Scale"
  bottom: "Convolution340"
  top: "Convolution340"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU340"
  type: "ReLU"
  bottom: "Convolution340"
  top: "Convolution340"
}
layer {
  name: "Convolution341"
  type: "Convolution"
  bottom: "Convolution340"
  top: "Convolution341"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm341"
  type: "BatchNorm"
  bottom: "Convolution341"
  top: "Convolution341"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale341"
  type: "Scale"
  bottom: "Convolution341"
  top: "Convolution341"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU341"
  type: "ReLU"
  bottom: "Convolution341"
  top: "Convolution341"
}
layer {
  name: "Convolution342"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution342"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm342"
  type: "BatchNorm"
  bottom: "Convolution342"
  top: "Convolution342"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale342"
  type: "Scale"
  bottom: "Convolution342"
  top: "Convolution342"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU342"
  type: "ReLU"
  bottom: "Convolution342"
  top: "Convolution342"
}
layer {
  name: "Convolution343"
  type: "Convolution"
  bottom: "Convolution342"
  top: "Convolution343"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm343"
  type: "BatchNorm"
  bottom: "Convolution343"
  top: "Convolution343"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale343"
  type: "Scale"
  bottom: "Convolution343"
  top: "Convolution343"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU343"
  type: "ReLU"
  bottom: "Convolution343"
  top: "Convolution343"
}
layer {
  name: "Convolution344"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution344"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm344"
  type: "BatchNorm"
  bottom: "Convolution344"
  top: "Convolution344"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale344"
  type: "Scale"
  bottom: "Convolution344"
  top: "Convolution344"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU344"
  type: "ReLU"
  bottom: "Convolution344"
  top: "Convolution344"
}
layer {
  name: "Convolution345"
  type: "Convolution"
  bottom: "Convolution344"
  top: "Convolution345"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm345"
  type: "BatchNorm"
  bottom: "Convolution345"
  top: "Convolution345"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale345"
  type: "Scale"
  bottom: "Convolution345"
  top: "Convolution345"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU345"
  type: "ReLU"
  bottom: "Convolution345"
  top: "Convolution345"
}
layer {
  name: "Convolution346"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution346"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm346"
  type: "BatchNorm"
  bottom: "Convolution346"
  top: "Convolution346"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale346"
  type: "Scale"
  bottom: "Convolution346"
  top: "Convolution346"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU346"
  type: "ReLU"
  bottom: "Convolution346"
  top: "Convolution346"
}
layer {
  name: "Convolution347"
  type: "Convolution"
  bottom: "Convolution346"
  top: "Convolution347"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm347"
  type: "BatchNorm"
  bottom: "Convolution347"
  top: "Convolution347"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale347"
  type: "Scale"
  bottom: "Convolution347"
  top: "Convolution347"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU347"
  type: "ReLU"
  bottom: "Convolution347"
  top: "Convolution347"
}
layer {
  name: "Convolution348"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution348"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm348"
  type: "BatchNorm"
  bottom: "Convolution348"
  top: "Convolution348"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale348"
  type: "Scale"
  bottom: "Convolution348"
  top: "Convolution348"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU348"
  type: "ReLU"
  bottom: "Convolution348"
  top: "Convolution348"
}
layer {
  name: "Convolution349"
  type: "Convolution"
  bottom: "Convolution348"
  top: "Convolution349"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm349"
  type: "BatchNorm"
  bottom: "Convolution349"
  top: "Convolution349"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale349"
  type: "Scale"
  bottom: "Convolution349"
  top: "Convolution349"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU349"
  type: "ReLU"
  bottom: "Convolution349"
  top: "Convolution349"
}
layer {
  name: "Convolution350"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution350"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm350"
  type: "BatchNorm"
  bottom: "Convolution350"
  top: "Convolution350"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale350"
  type: "Scale"
  bottom: "Convolution350"
  top: "Convolution350"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU350"
  type: "ReLU"
  bottom: "Convolution350"
  top: "Convolution350"
}
layer {
  name: "Convolution351"
  type: "Convolution"
  bottom: "Convolution350"
  top: "Convolution351"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm351"
  type: "BatchNorm"
  bottom: "Convolution351"
  top: "Convolution351"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale351"
  type: "Scale"
  bottom: "Convolution351"
  top: "Convolution351"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU351"
  type: "ReLU"
  bottom: "Convolution351"
  top: "Convolution351"
}
layer {
  name: "Convolution352"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution352"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm352"
  type: "BatchNorm"
  bottom: "Convolution352"
  top: "Convolution352"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale352"
  type: "Scale"
  bottom: "Convolution352"
  top: "Convolution352"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU352"
  type: "ReLU"
  bottom: "Convolution352"
  top: "Convolution352"
}
layer {
  name: "Convolution353"
  type: "Convolution"
  bottom: "Convolution352"
  top: "Convolution353"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm353"
  type: "BatchNorm"
  bottom: "Convolution353"
  top: "Convolution353"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale353"
  type: "Scale"
  bottom: "Convolution353"
  top: "Convolution353"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU353"
  type: "ReLU"
  bottom: "Convolution353"
  top: "Convolution353"
}
layer {
  name: "Convolution354"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution354"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm354"
  type: "BatchNorm"
  bottom: "Convolution354"
  top: "Convolution354"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale354"
  type: "Scale"
  bottom: "Convolution354"
  top: "Convolution354"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU354"
  type: "ReLU"
  bottom: "Convolution354"
  top: "Convolution354"
}
layer {
  name: "Convolution355"
  type: "Convolution"
  bottom: "Convolution354"
  top: "Convolution355"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm355"
  type: "BatchNorm"
  bottom: "Convolution355"
  top: "Convolution355"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale355"
  type: "Scale"
  bottom: "Convolution355"
  top: "Convolution355"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU355"
  type: "ReLU"
  bottom: "Convolution355"
  top: "Convolution355"
}
layer {
  name: "Convolution356"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution356"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm356"
  type: "BatchNorm"
  bottom: "Convolution356"
  top: "Convolution356"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale356"
  type: "Scale"
  bottom: "Convolution356"
  top: "Convolution356"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU356"
  type: "ReLU"
  bottom: "Convolution356"
  top: "Convolution356"
}
layer {
  name: "Convolution357"
  type: "Convolution"
  bottom: "Convolution356"
  top: "Convolution357"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm357"
  type: "BatchNorm"
  bottom: "Convolution357"
  top: "Convolution357"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale357"
  type: "Scale"
  bottom: "Convolution357"
  top: "Convolution357"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU357"
  type: "ReLU"
  bottom: "Convolution357"
  top: "Convolution357"
}
layer {
  name: "Convolution358"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution358"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm358"
  type: "BatchNorm"
  bottom: "Convolution358"
  top: "Convolution358"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale358"
  type: "Scale"
  bottom: "Convolution358"
  top: "Convolution358"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU358"
  type: "ReLU"
  bottom: "Convolution358"
  top: "Convolution358"
}
layer {
  name: "Convolution359"
  type: "Convolution"
  bottom: "Convolution358"
  top: "Convolution359"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm359"
  type: "BatchNorm"
  bottom: "Convolution359"
  top: "Convolution359"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale359"
  type: "Scale"
  bottom: "Convolution359"
  top: "Convolution359"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU359"
  type: "ReLU"
  bottom: "Convolution359"
  top: "Convolution359"
}
layer {
  name: "Convolution360"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution360"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm360"
  type: "BatchNorm"
  bottom: "Convolution360"
  top: "Convolution360"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale360"
  type: "Scale"
  bottom: "Convolution360"
  top: "Convolution360"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU360"
  type: "ReLU"
  bottom: "Convolution360"
  top: "Convolution360"
}
layer {
  name: "Convolution361"
  type: "Convolution"
  bottom: "Convolution360"
  top: "Convolution361"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm361"
  type: "BatchNorm"
  bottom: "Convolution361"
  top: "Convolution361"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale361"
  type: "Scale"
  bottom: "Convolution361"
  top: "Convolution361"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU361"
  type: "ReLU"
  bottom: "Convolution361"
  top: "Convolution361"
}
layer {
  name: "Convolution362"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution362"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm362"
  type: "BatchNorm"
  bottom: "Convolution362"
  top: "Convolution362"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale362"
  type: "Scale"
  bottom: "Convolution362"
  top: "Convolution362"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU362"
  type: "ReLU"
  bottom: "Convolution362"
  top: "Convolution362"
}
layer {
  name: "Convolution363"
  type: "Convolution"
  bottom: "Convolution362"
  top: "Convolution363"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm363"
  type: "BatchNorm"
  bottom: "Convolution363"
  top: "Convolution363"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale363"
  type: "Scale"
  bottom: "Convolution363"
  top: "Convolution363"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU363"
  type: "ReLU"
  bottom: "Convolution363"
  top: "Convolution363"
}
layer {
  name: "Convolution364"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution364"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm364"
  type: "BatchNorm"
  bottom: "Convolution364"
  top: "Convolution364"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale364"
  type: "Scale"
  bottom: "Convolution364"
  top: "Convolution364"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU364"
  type: "ReLU"
  bottom: "Convolution364"
  top: "Convolution364"
}
layer {
  name: "Convolution365"
  type: "Convolution"
  bottom: "Convolution364"
  top: "Convolution365"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm365"
  type: "BatchNorm"
  bottom: "Convolution365"
  top: "Convolution365"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale365"
  type: "Scale"
  bottom: "Convolution365"
  top: "Convolution365"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU365"
  type: "ReLU"
  bottom: "Convolution365"
  top: "Convolution365"
}
layer {
  name: "Convolution366"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution366"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm366"
  type: "BatchNorm"
  bottom: "Convolution366"
  top: "Convolution366"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale366"
  type: "Scale"
  bottom: "Convolution366"
  top: "Convolution366"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU366"
  type: "ReLU"
  bottom: "Convolution366"
  top: "Convolution366"
}
layer {
  name: "Convolution367"
  type: "Convolution"
  bottom: "Convolution366"
  top: "Convolution367"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm367"
  type: "BatchNorm"
  bottom: "Convolution367"
  top: "Convolution367"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale367"
  type: "Scale"
  bottom: "Convolution367"
  top: "Convolution367"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU367"
  type: "ReLU"
  bottom: "Convolution367"
  top: "Convolution367"
}
layer {
  name: "Convolution368"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution368"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm368"
  type: "BatchNorm"
  bottom: "Convolution368"
  top: "Convolution368"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale368"
  type: "Scale"
  bottom: "Convolution368"
  top: "Convolution368"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU368"
  type: "ReLU"
  bottom: "Convolution368"
  top: "Convolution368"
}
layer {
  name: "Convolution369"
  type: "Convolution"
  bottom: "Convolution368"
  top: "Convolution369"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm369"
  type: "BatchNorm"
  bottom: "Convolution369"
  top: "Convolution369"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale369"
  type: "Scale"
  bottom: "Convolution369"
  top: "Convolution369"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU369"
  type: "ReLU"
  bottom: "Convolution369"
  top: "Convolution369"
}
layer {
  name: "Convolution370"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution370"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm370"
  type: "BatchNorm"
  bottom: "Convolution370"
  top: "Convolution370"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale370"
  type: "Scale"
  bottom: "Convolution370"
  top: "Convolution370"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU370"
  type: "ReLU"
  bottom: "Convolution370"
  top: "Convolution370"
}
layer {
  name: "Convolution371"
  type: "Convolution"
  bottom: "Convolution370"
  top: "Convolution371"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm371"
  type: "BatchNorm"
  bottom: "Convolution371"
  top: "Convolution371"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale371"
  type: "Scale"
  bottom: "Convolution371"
  top: "Convolution371"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU371"
  type: "ReLU"
  bottom: "Convolution371"
  top: "Convolution371"
}
layer {
  name: "Convolution372"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution372"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm372"
  type: "BatchNorm"
  bottom: "Convolution372"
  top: "Convolution372"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale372"
  type: "Scale"
  bottom: "Convolution372"
  top: "Convolution372"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU372"
  type: "ReLU"
  bottom: "Convolution372"
  top: "Convolution372"
}
layer {
  name: "Convolution373"
  type: "Convolution"
  bottom: "Convolution372"
  top: "Convolution373"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm373"
  type: "BatchNorm"
  bottom: "Convolution373"
  top: "Convolution373"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale373"
  type: "Scale"
  bottom: "Convolution373"
  top: "Convolution373"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU373"
  type: "ReLU"
  bottom: "Convolution373"
  top: "Convolution373"
}
layer {
  name: "Convolution374"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution374"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm374"
  type: "BatchNorm"
  bottom: "Convolution374"
  top: "Convolution374"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale374"
  type: "Scale"
  bottom: "Convolution374"
  top: "Convolution374"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU374"
  type: "ReLU"
  bottom: "Convolution374"
  top: "Convolution374"
}
layer {
  name: "Convolution375"
  type: "Convolution"
  bottom: "Convolution374"
  top: "Convolution375"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm375"
  type: "BatchNorm"
  bottom: "Convolution375"
  top: "Convolution375"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale375"
  type: "Scale"
  bottom: "Convolution375"
  top: "Convolution375"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU375"
  type: "ReLU"
  bottom: "Convolution375"
  top: "Convolution375"
}
layer {
  name: "Convolution376"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution376"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm376"
  type: "BatchNorm"
  bottom: "Convolution376"
  top: "Convolution376"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale376"
  type: "Scale"
  bottom: "Convolution376"
  top: "Convolution376"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU376"
  type: "ReLU"
  bottom: "Convolution376"
  top: "Convolution376"
}
layer {
  name: "Convolution377"
  type: "Convolution"
  bottom: "Convolution376"
  top: "Convolution377"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm377"
  type: "BatchNorm"
  bottom: "Convolution377"
  top: "Convolution377"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale377"
  type: "Scale"
  bottom: "Convolution377"
  top: "Convolution377"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU377"
  type: "ReLU"
  bottom: "Convolution377"
  top: "Convolution377"
}
layer {
  name: "Convolution378"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution378"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm378"
  type: "BatchNorm"
  bottom: "Convolution378"
  top: "Convolution378"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale378"
  type: "Scale"
  bottom: "Convolution378"
  top: "Convolution378"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU378"
  type: "ReLU"
  bottom: "Convolution378"
  top: "Convolution378"
}
layer {
  name: "Convolution379"
  type: "Convolution"
  bottom: "Convolution378"
  top: "Convolution379"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm379"
  type: "BatchNorm"
  bottom: "Convolution379"
  top: "Convolution379"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale379"
  type: "Scale"
  bottom: "Convolution379"
  top: "Convolution379"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU379"
  type: "ReLU"
  bottom: "Convolution379"
  top: "Convolution379"
}
layer {
  name: "Convolution380"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution380"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm380"
  type: "BatchNorm"
  bottom: "Convolution380"
  top: "Convolution380"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale380"
  type: "Scale"
  bottom: "Convolution380"
  top: "Convolution380"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU380"
  type: "ReLU"
  bottom: "Convolution380"
  top: "Convolution380"
}
layer {
  name: "Convolution381"
  type: "Convolution"
  bottom: "Convolution380"
  top: "Convolution381"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm381"
  type: "BatchNorm"
  bottom: "Convolution381"
  top: "Convolution381"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale381"
  type: "Scale"
  bottom: "Convolution381"
  top: "Convolution381"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU381"
  type: "ReLU"
  bottom: "Convolution381"
  top: "Convolution381"
}
layer {
  name: "Convolution382"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution382"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm382"
  type: "BatchNorm"
  bottom: "Convolution382"
  top: "Convolution382"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale382"
  type: "Scale"
  bottom: "Convolution382"
  top: "Convolution382"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU382"
  type: "ReLU"
  bottom: "Convolution382"
  top: "Convolution382"
}
layer {
  name: "Convolution383"
  type: "Convolution"
  bottom: "Convolution382"
  top: "Convolution383"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm383"
  type: "BatchNorm"
  bottom: "Convolution383"
  top: "Convolution383"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale383"
  type: "Scale"
  bottom: "Convolution383"
  top: "Convolution383"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU383"
  type: "ReLU"
  bottom: "Convolution383"
  top: "Convolution383"
}
layer {
  name: "Convolution384"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution384"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm384"
  type: "BatchNorm"
  bottom: "Convolution384"
  top: "Convolution384"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale384"
  type: "Scale"
  bottom: "Convolution384"
  top: "Convolution384"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU384"
  type: "ReLU"
  bottom: "Convolution384"
  top: "Convolution384"
}
layer {
  name: "Convolution385"
  type: "Convolution"
  bottom: "Convolution384"
  top: "Convolution385"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm385"
  type: "BatchNorm"
  bottom: "Convolution385"
  top: "Convolution385"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale385"
  type: "Scale"
  bottom: "Convolution385"
  top: "Convolution385"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU385"
  type: "ReLU"
  bottom: "Convolution385"
  top: "Convolution385"
}
layer {
  name: "Convolution386"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution386"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm386"
  type: "BatchNorm"
  bottom: "Convolution386"
  top: "Convolution386"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale386"
  type: "Scale"
  bottom: "Convolution386"
  top: "Convolution386"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU386"
  type: "ReLU"
  bottom: "Convolution386"
  top: "Convolution386"
}
layer {
  name: "Convolution387"
  type: "Convolution"
  bottom: "Convolution386"
  top: "Convolution387"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm387"
  type: "BatchNorm"
  bottom: "Convolution387"
  top: "Convolution387"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale387"
  type: "Scale"
  bottom: "Convolution387"
  top: "Convolution387"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU387"
  type: "ReLU"
  bottom: "Convolution387"
  top: "Convolution387"
}
layer {
  name: "Convolution388"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution388"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm388"
  type: "BatchNorm"
  bottom: "Convolution388"
  top: "Convolution388"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale388"
  type: "Scale"
  bottom: "Convolution388"
  top: "Convolution388"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU388"
  type: "ReLU"
  bottom: "Convolution388"
  top: "Convolution388"
}
layer {
  name: "Convolution389"
  type: "Convolution"
  bottom: "Convolution388"
  top: "Convolution389"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm389"
  type: "BatchNorm"
  bottom: "Convolution389"
  top: "Convolution389"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale389"
  type: "Scale"
  bottom: "Convolution389"
  top: "Convolution389"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU389"
  type: "ReLU"
  bottom: "Convolution389"
  top: "Convolution389"
}
layer {
  name: "Convolution390"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution390"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm390"
  type: "BatchNorm"
  bottom: "Convolution390"
  top: "Convolution390"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale390"
  type: "Scale"
  bottom: "Convolution390"
  top: "Convolution390"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU390"
  type: "ReLU"
  bottom: "Convolution390"
  top: "Convolution390"
}
layer {
  name: "Convolution391"
  type: "Convolution"
  bottom: "Convolution390"
  top: "Convolution391"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm391"
  type: "BatchNorm"
  bottom: "Convolution391"
  top: "Convolution391"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale391"
  type: "Scale"
  bottom: "Convolution391"
  top: "Convolution391"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU391"
  type: "ReLU"
  bottom: "Convolution391"
  top: "Convolution391"
}
layer {
  name: "Convolution392"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution392"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm392"
  type: "BatchNorm"
  bottom: "Convolution392"
  top: "Convolution392"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale392"
  type: "Scale"
  bottom: "Convolution392"
  top: "Convolution392"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU392"
  type: "ReLU"
  bottom: "Convolution392"
  top: "Convolution392"
}
layer {
  name: "Convolution393"
  type: "Convolution"
  bottom: "Convolution392"
  top: "Convolution393"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm393"
  type: "BatchNorm"
  bottom: "Convolution393"
  top: "Convolution393"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale393"
  type: "Scale"
  bottom: "Convolution393"
  top: "Convolution393"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU393"
  type: "ReLU"
  bottom: "Convolution393"
  top: "Convolution393"
}
layer {
  name: "Convolution394"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution394"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm394"
  type: "BatchNorm"
  bottom: "Convolution394"
  top: "Convolution394"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale394"
  type: "Scale"
  bottom: "Convolution394"
  top: "Convolution394"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU394"
  type: "ReLU"
  bottom: "Convolution394"
  top: "Convolution394"
}
layer {
  name: "Convolution395"
  type: "Convolution"
  bottom: "Convolution394"
  top: "Convolution395"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm395"
  type: "BatchNorm"
  bottom: "Convolution395"
  top: "Convolution395"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale395"
  type: "Scale"
  bottom: "Convolution395"
  top: "Convolution395"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU395"
  type: "ReLU"
  bottom: "Convolution395"
  top: "Convolution395"
}
layer {
  name: "Concat6"
  type: "Concat"
  bottom: "Convolution333"
  bottom: "Convolution335"
  bottom: "Convolution337"
  bottom: "Convolution339"
  bottom: "Convolution341"
  bottom: "Convolution343"
  bottom: "Convolution345"
  bottom: "Convolution347"
  bottom: "Convolution349"
  bottom: "Convolution351"
  bottom: "Convolution353"
  bottom: "Convolution355"
  bottom: "Convolution357"
  bottom: "Convolution359"
  bottom: "Convolution361"
  bottom: "Convolution363"
  bottom: "Convolution365"
  bottom: "Convolution367"
  bottom: "Convolution369"
  bottom: "Convolution371"
  bottom: "Convolution373"
  bottom: "Convolution375"
  bottom: "Convolution377"
  bottom: "Convolution379"
  bottom: "Convolution381"
  bottom: "Convolution383"
  bottom: "Convolution385"
  bottom: "Convolution387"
  bottom: "Convolution389"
  bottom: "Convolution391"
  bottom: "Convolution393"
  bottom: "Convolution395"
  top: "Concat6"
}
layer {
  name: "Convolution396"
  type: "Convolution"
  bottom: "Concat6"
  top: "Convolution396"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm396"
  type: "BatchNorm"
  bottom: "Convolution396"
  top: "Convolution396"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale396"
  type: "Scale"
  bottom: "Convolution396"
  top: "Convolution396"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU396"
  type: "ReLU"
  bottom: "Convolution396"
  top: "Convolution396"
}
layer {
  name: "Convolution397"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution397"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm397"
  type: "BatchNorm"
  bottom: "Convolution397"
  top: "Convolution397"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale397"
  type: "Scale"
  bottom: "Convolution397"
  top: "Convolution397"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU397"
  type: "ReLU"
  bottom: "Convolution397"
  top: "Convolution397"
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution396"
  bottom: "Convolution397"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution398"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution398"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm398"
  type: "BatchNorm"
  bottom: "Convolution398"
  top: "Convolution398"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale398"
  type: "Scale"
  bottom: "Convolution398"
  top: "Convolution398"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU398"
  type: "ReLU"
  bottom: "Convolution398"
  top: "Convolution398"
}
layer {
  name: "Convolution399"
  type: "Convolution"
  bottom: "Convolution398"
  top: "Convolution399"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm399"
  type: "BatchNorm"
  bottom: "Convolution399"
  top: "Convolution399"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale399"
  type: "Scale"
  bottom: "Convolution399"
  top: "Convolution399"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU399"
  type: "ReLU"
  bottom: "Convolution399"
  top: "Convolution399"
}
layer {
  name: "Convolution400"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution400"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm400"
  type: "BatchNorm"
  bottom: "Convolution400"
  top: "Convolution400"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale400"
  type: "Scale"
  bottom: "Convolution400"
  top: "Convolution400"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU400"
  type: "ReLU"
  bottom: "Convolution400"
  top: "Convolution400"
}
layer {
  name: "Convolution401"
  type: "Convolution"
  bottom: "Convolution400"
  top: "Convolution401"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm401"
  type: "BatchNorm"
  bottom: "Convolution401"
  top: "Convolution401"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale401"
  type: "Scale"
  bottom: "Convolution401"
  top: "Convolution401"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU401"
  type: "ReLU"
  bottom: "Convolution401"
  top: "Convolution401"
}
layer {
  name: "Convolution402"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution402"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm402"
  type: "BatchNorm"
  bottom: "Convolution402"
  top: "Convolution402"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale402"
  type: "Scale"
  bottom: "Convolution402"
  top: "Convolution402"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU402"
  type: "ReLU"
  bottom: "Convolution402"
  top: "Convolution402"
}
layer {
  name: "Convolution403"
  type: "Convolution"
  bottom: "Convolution402"
  top: "Convolution403"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm403"
  type: "BatchNorm"
  bottom: "Convolution403"
  top: "Convolution403"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale403"
  type: "Scale"
  bottom: "Convolution403"
  top: "Convolution403"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU403"
  type: "ReLU"
  bottom: "Convolution403"
  top: "Convolution403"
}
layer {
  name: "Convolution404"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution404"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm404"
  type: "BatchNorm"
  bottom: "Convolution404"
  top: "Convolution404"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale404"
  type: "Scale"
  bottom: "Convolution404"
  top: "Convolution404"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU404"
  type: "ReLU"
  bottom: "Convolution404"
  top: "Convolution404"
}
layer {
  name: "Convolution405"
  type: "Convolution"
  bottom: "Convolution404"
  top: "Convolution405"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm405"
  type: "BatchNorm"
  bottom: "Convolution405"
  top: "Convolution405"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale405"
  type: "Scale"
  bottom: "Convolution405"
  top: "Convolution405"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU405"
  type: "ReLU"
  bottom: "Convolution405"
  top: "Convolution405"
}
layer {
  name: "Convolution406"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution406"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm406"
  type: "BatchNorm"
  bottom: "Convolution406"
  top: "Convolution406"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale406"
  type: "Scale"
  bottom: "Convolution406"
  top: "Convolution406"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU406"
  type: "ReLU"
  bottom: "Convolution406"
  top: "Convolution406"
}
layer {
  name: "Convolution407"
  type: "Convolution"
  bottom: "Convolution406"
  top: "Convolution407"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm407"
  type: "BatchNorm"
  bottom: "Convolution407"
  top: "Convolution407"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale407"
  type: "Scale"
  bottom: "Convolution407"
  top: "Convolution407"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU407"
  type: "ReLU"
  bottom: "Convolution407"
  top: "Convolution407"
}
layer {
  name: "Convolution408"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution408"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm408"
  type: "BatchNorm"
  bottom: "Convolution408"
  top: "Convolution408"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale408"
  type: "Scale"
  bottom: "Convolution408"
  top: "Convolution408"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU408"
  type: "ReLU"
  bottom: "Convolution408"
  top: "Convolution408"
}
layer {
  name: "Convolution409"
  type: "Convolution"
  bottom: "Convolution408"
  top: "Convolution409"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm409"
  type: "BatchNorm"
  bottom: "Convolution409"
  top: "Convolution409"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale409"
  type: "Scale"
  bottom: "Convolution409"
  top: "Convolution409"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU409"
  type: "ReLU"
  bottom: "Convolution409"
  top: "Convolution409"
}
layer {
  name: "Convolution410"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution410"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm410"
  type: "BatchNorm"
  bottom: "Convolution410"
  top: "Convolution410"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale410"
  type: "Scale"
  bottom: "Convolution410"
  top: "Convolution410"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU410"
  type: "ReLU"
  bottom: "Convolution410"
  top: "Convolution410"
}
layer {
  name: "Convolution411"
  type: "Convolution"
  bottom: "Convolution410"
  top: "Convolution411"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm411"
  type: "BatchNorm"
  bottom: "Convolution411"
  top: "Convolution411"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale411"
  type: "Scale"
  bottom: "Convolution411"
  top: "Convolution411"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU411"
  type: "ReLU"
  bottom: "Convolution411"
  top: "Convolution411"
}
layer {
  name: "Convolution412"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution412"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm412"
  type: "BatchNorm"
  bottom: "Convolution412"
  top: "Convolution412"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale412"
  type: "Scale"
  bottom: "Convolution412"
  top: "Convolution412"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU412"
  type: "ReLU"
  bottom: "Convolution412"
  top: "Convolution412"
}
layer {
  name: "Convolution413"
  type: "Convolution"
  bottom: "Convolution412"
  top: "Convolution413"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm413"
  type: "BatchNorm"
  bottom: "Convolution413"
  top: "Convolution413"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale413"
  type: "Scale"
  bottom: "Convolution413"
  top: "Convolution413"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU413"
  type: "ReLU"
  bottom: "Convolution413"
  top: "Convolution413"
}
layer {
  name: "Convolution414"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution414"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm414"
  type: "BatchNorm"
  bottom: "Convolution414"
  top: "Convolution414"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale414"
  type: "Scale"
  bottom: "Convolution414"
  top: "Convolution414"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU414"
  type: "ReLU"
  bottom: "Convolution414"
  top: "Convolution414"
}
layer {
  name: "Convolution415"
  type: "Convolution"
  bottom: "Convolution414"
  top: "Convolution415"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm415"
  type: "BatchNorm"
  bottom: "Convolution415"
  top: "Convolution415"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale415"
  type: "Scale"
  bottom: "Convolution415"
  top: "Convolution415"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU415"
  type: "ReLU"
  bottom: "Convolution415"
  top: "Convolution415"
}
layer {
  name: "Convolution416"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution416"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm416"
  type: "BatchNorm"
  bottom: "Convolution416"
  top: "Convolution416"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale416"
  type: "Scale"
  bottom: "Convolution416"
  top: "Convolution416"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU416"
  type: "ReLU"
  bottom: "Convolution416"
  top: "Convolution416"
}
layer {
  name: "Convolution417"
  type: "Convolution"
  bottom: "Convolution416"
  top: "Convolution417"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm417"
  type: "BatchNorm"
  bottom: "Convolution417"
  top: "Convolution417"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale417"
  type: "Scale"
  bottom: "Convolution417"
  top: "Convolution417"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU417"
  type: "ReLU"
  bottom: "Convolution417"
  top: "Convolution417"
}
layer {
  name: "Convolution418"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution418"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm418"
  type: "BatchNorm"
  bottom: "Convolution418"
  top: "Convolution418"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale418"
  type: "Scale"
  bottom: "Convolution418"
  top: "Convolution418"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU418"
  type: "ReLU"
  bottom: "Convolution418"
  top: "Convolution418"
}
layer {
  name: "Convolution419"
  type: "Convolution"
  bottom: "Convolution418"
  top: "Convolution419"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm419"
  type: "BatchNorm"
  bottom: "Convolution419"
  top: "Convolution419"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale419"
  type: "Scale"
  bottom: "Convolution419"
  top: "Convolution419"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU419"
  type: "ReLU"
  bottom: "Convolution419"
  top: "Convolution419"
}
layer {
  name: "Convolution420"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution420"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm420"
  type: "BatchNorm"
  bottom: "Convolution420"
  top: "Convolution420"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale420"
  type: "Scale"
  bottom: "Convolution420"
  top: "Convolution420"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU420"
  type: "ReLU"
  bottom: "Convolution420"
  top: "Convolution420"
}
layer {
  name: "Convolution421"
  type: "Convolution"
  bottom: "Convolution420"
  top: "Convolution421"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm421"
  type: "BatchNorm"
  bottom: "Convolution421"
  top: "Convolution421"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale421"
  type: "Scale"
  bottom: "Convolution421"
  top: "Convolution421"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU421"
  type: "ReLU"
  bottom: "Convolution421"
  top: "Convolution421"
}
layer {
  name: "Convolution422"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution422"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm422"
  type: "BatchNorm"
  bottom: "Convolution422"
  top: "Convolution422"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale422"
  type: "Scale"
  bottom: "Convolution422"
  top: "Convolution422"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU422"
  type: "ReLU"
  bottom: "Convolution422"
  top: "Convolution422"
}
layer {
  name: "Convolution423"
  type: "Convolution"
  bottom: "Convolution422"
  top: "Convolution423"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm423"
  type: "BatchNorm"
  bottom: "Convolution423"
  top: "Convolution423"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale423"
  type: "Scale"
  bottom: "Convolution423"
  top: "Convolution423"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU423"
  type: "ReLU"
  bottom: "Convolution423"
  top: "Convolution423"
}
layer {
  name: "Convolution424"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution424"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm424"
  type: "BatchNorm"
  bottom: "Convolution424"
  top: "Convolution424"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale424"
  type: "Scale"
  bottom: "Convolution424"
  top: "Convolution424"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU424"
  type: "ReLU"
  bottom: "Convolution424"
  top: "Convolution424"
}
layer {
  name: "Convolution425"
  type: "Convolution"
  bottom: "Convolution424"
  top: "Convolution425"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm425"
  type: "BatchNorm"
  bottom: "Convolution425"
  top: "Convolution425"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale425"
  type: "Scale"
  bottom: "Convolution425"
  top: "Convolution425"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU425"
  type: "ReLU"
  bottom: "Convolution425"
  top: "Convolution425"
}
layer {
  name: "Convolution426"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution426"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm426"
  type: "BatchNorm"
  bottom: "Convolution426"
  top: "Convolution426"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale426"
  type: "Scale"
  bottom: "Convolution426"
  top: "Convolution426"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU426"
  type: "ReLU"
  bottom: "Convolution426"
  top: "Convolution426"
}
layer {
  name: "Convolution427"
  type: "Convolution"
  bottom: "Convolution426"
  top: "Convolution427"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm427"
  type: "BatchNorm"
  bottom: "Convolution427"
  top: "Convolution427"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale427"
  type: "Scale"
  bottom: "Convolution427"
  top: "Convolution427"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU427"
  type: "ReLU"
  bottom: "Convolution427"
  top: "Convolution427"
}
layer {
  name: "Convolution428"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution428"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm428"
  type: "BatchNorm"
  bottom: "Convolution428"
  top: "Convolution428"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale428"
  type: "Scale"
  bottom: "Convolution428"
  top: "Convolution428"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU428"
  type: "ReLU"
  bottom: "Convolution428"
  top: "Convolution428"
}
layer {
  name: "Convolution429"
  type: "Convolution"
  bottom: "Convolution428"
  top: "Convolution429"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm429"
  type: "BatchNorm"
  bottom: "Convolution429"
  top: "Convolution429"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale429"
  type: "Scale"
  bottom: "Convolution429"
  top: "Convolution429"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU429"
  type: "ReLU"
  bottom: "Convolution429"
  top: "Convolution429"
}
layer {
  name: "Convolution430"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution430"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm430"
  type: "BatchNorm"
  bottom: "Convolution430"
  top: "Convolution430"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale430"
  type: "Scale"
  bottom: "Convolution430"
  top: "Convolution430"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU430"
  type: "ReLU"
  bottom: "Convolution430"
  top: "Convolution430"
}
layer {
  name: "Convolution431"
  type: "Convolution"
  bottom: "Convolution430"
  top: "Convolution431"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm431"
  type: "BatchNorm"
  bottom: "Convolution431"
  top: "Convolution431"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale431"
  type: "Scale"
  bottom: "Convolution431"
  top: "Convolution431"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU431"
  type: "ReLU"
  bottom: "Convolution431"
  top: "Convolution431"
}
layer {
  name: "Convolution432"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution432"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm432"
  type: "BatchNorm"
  bottom: "Convolution432"
  top: "Convolution432"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale432"
  type: "Scale"
  bottom: "Convolution432"
  top: "Convolution432"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU432"
  type: "ReLU"
  bottom: "Convolution432"
  top: "Convolution432"
}
layer {
  name: "Convolution433"
  type: "Convolution"
  bottom: "Convolution432"
  top: "Convolution433"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm433"
  type: "BatchNorm"
  bottom: "Convolution433"
  top: "Convolution433"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale433"
  type: "Scale"
  bottom: "Convolution433"
  top: "Convolution433"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU433"
  type: "ReLU"
  bottom: "Convolution433"
  top: "Convolution433"
}
layer {
  name: "Convolution434"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution434"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm434"
  type: "BatchNorm"
  bottom: "Convolution434"
  top: "Convolution434"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale434"
  type: "Scale"
  bottom: "Convolution434"
  top: "Convolution434"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU434"
  type: "ReLU"
  bottom: "Convolution434"
  top: "Convolution434"
}
layer {
  name: "Convolution435"
  type: "Convolution"
  bottom: "Convolution434"
  top: "Convolution435"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm435"
  type: "BatchNorm"
  bottom: "Convolution435"
  top: "Convolution435"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale435"
  type: "Scale"
  bottom: "Convolution435"
  top: "Convolution435"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU435"
  type: "ReLU"
  bottom: "Convolution435"
  top: "Convolution435"
}
layer {
  name: "Convolution436"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution436"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm436"
  type: "BatchNorm"
  bottom: "Convolution436"
  top: "Convolution436"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale436"
  type: "Scale"
  bottom: "Convolution436"
  top: "Convolution436"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU436"
  type: "ReLU"
  bottom: "Convolution436"
  top: "Convolution436"
}
layer {
  name: "Convolution437"
  type: "Convolution"
  bottom: "Convolution436"
  top: "Convolution437"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm437"
  type: "BatchNorm"
  bottom: "Convolution437"
  top: "Convolution437"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale437"
  type: "Scale"
  bottom: "Convolution437"
  top: "Convolution437"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU437"
  type: "ReLU"
  bottom: "Convolution437"
  top: "Convolution437"
}
layer {
  name: "Convolution438"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution438"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm438"
  type: "BatchNorm"
  bottom: "Convolution438"
  top: "Convolution438"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale438"
  type: "Scale"
  bottom: "Convolution438"
  top: "Convolution438"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU438"
  type: "ReLU"
  bottom: "Convolution438"
  top: "Convolution438"
}
layer {
  name: "Convolution439"
  type: "Convolution"
  bottom: "Convolution438"
  top: "Convolution439"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm439"
  type: "BatchNorm"
  bottom: "Convolution439"
  top: "Convolution439"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale439"
  type: "Scale"
  bottom: "Convolution439"
  top: "Convolution439"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU439"
  type: "ReLU"
  bottom: "Convolution439"
  top: "Convolution439"
}
layer {
  name: "Convolution440"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution440"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm440"
  type: "BatchNorm"
  bottom: "Convolution440"
  top: "Convolution440"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale440"
  type: "Scale"
  bottom: "Convolution440"
  top: "Convolution440"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU440"
  type: "ReLU"
  bottom: "Convolution440"
  top: "Convolution440"
}
layer {
  name: "Convolution441"
  type: "Convolution"
  bottom: "Convolution440"
  top: "Convolution441"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm441"
  type: "BatchNorm"
  bottom: "Convolution441"
  top: "Convolution441"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale441"
  type: "Scale"
  bottom: "Convolution441"
  top: "Convolution441"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU441"
  type: "ReLU"
  bottom: "Convolution441"
  top: "Convolution441"
}
layer {
  name: "Convolution442"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution442"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm442"
  type: "BatchNorm"
  bottom: "Convolution442"
  top: "Convolution442"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale442"
  type: "Scale"
  bottom: "Convolution442"
  top: "Convolution442"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU442"
  type: "ReLU"
  bottom: "Convolution442"
  top: "Convolution442"
}
layer {
  name: "Convolution443"
  type: "Convolution"
  bottom: "Convolution442"
  top: "Convolution443"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm443"
  type: "BatchNorm"
  bottom: "Convolution443"
  top: "Convolution443"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale443"
  type: "Scale"
  bottom: "Convolution443"
  top: "Convolution443"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU443"
  type: "ReLU"
  bottom: "Convolution443"
  top: "Convolution443"
}
layer {
  name: "Convolution444"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution444"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm444"
  type: "BatchNorm"
  bottom: "Convolution444"
  top: "Convolution444"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale444"
  type: "Scale"
  bottom: "Convolution444"
  top: "Convolution444"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU444"
  type: "ReLU"
  bottom: "Convolution444"
  top: "Convolution444"
}
layer {
  name: "Convolution445"
  type: "Convolution"
  bottom: "Convolution444"
  top: "Convolution445"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm445"
  type: "BatchNorm"
  bottom: "Convolution445"
  top: "Convolution445"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale445"
  type: "Scale"
  bottom: "Convolution445"
  top: "Convolution445"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU445"
  type: "ReLU"
  bottom: "Convolution445"
  top: "Convolution445"
}
layer {
  name: "Convolution446"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution446"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm446"
  type: "BatchNorm"
  bottom: "Convolution446"
  top: "Convolution446"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale446"
  type: "Scale"
  bottom: "Convolution446"
  top: "Convolution446"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU446"
  type: "ReLU"
  bottom: "Convolution446"
  top: "Convolution446"
}
layer {
  name: "Convolution447"
  type: "Convolution"
  bottom: "Convolution446"
  top: "Convolution447"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm447"
  type: "BatchNorm"
  bottom: "Convolution447"
  top: "Convolution447"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale447"
  type: "Scale"
  bottom: "Convolution447"
  top: "Convolution447"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU447"
  type: "ReLU"
  bottom: "Convolution447"
  top: "Convolution447"
}
layer {
  name: "Convolution448"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution448"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm448"
  type: "BatchNorm"
  bottom: "Convolution448"
  top: "Convolution448"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale448"
  type: "Scale"
  bottom: "Convolution448"
  top: "Convolution448"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU448"
  type: "ReLU"
  bottom: "Convolution448"
  top: "Convolution448"
}
layer {
  name: "Convolution449"
  type: "Convolution"
  bottom: "Convolution448"
  top: "Convolution449"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm449"
  type: "BatchNorm"
  bottom: "Convolution449"
  top: "Convolution449"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale449"
  type: "Scale"
  bottom: "Convolution449"
  top: "Convolution449"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU449"
  type: "ReLU"
  bottom: "Convolution449"
  top: "Convolution449"
}
layer {
  name: "Convolution450"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution450"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm450"
  type: "BatchNorm"
  bottom: "Convolution450"
  top: "Convolution450"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale450"
  type: "Scale"
  bottom: "Convolution450"
  top: "Convolution450"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU450"
  type: "ReLU"
  bottom: "Convolution450"
  top: "Convolution450"
}
layer {
  name: "Convolution451"
  type: "Convolution"
  bottom: "Convolution450"
  top: "Convolution451"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm451"
  type: "BatchNorm"
  bottom: "Convolution451"
  top: "Convolution451"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale451"
  type: "Scale"
  bottom: "Convolution451"
  top: "Convolution451"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU451"
  type: "ReLU"
  bottom: "Convolution451"
  top: "Convolution451"
}
layer {
  name: "Convolution452"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution452"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm452"
  type: "BatchNorm"
  bottom: "Convolution452"
  top: "Convolution452"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale452"
  type: "Scale"
  bottom: "Convolution452"
  top: "Convolution452"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU452"
  type: "ReLU"
  bottom: "Convolution452"
  top: "Convolution452"
}
layer {
  name: "Convolution453"
  type: "Convolution"
  bottom: "Convolution452"
  top: "Convolution453"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm453"
  type: "BatchNorm"
  bottom: "Convolution453"
  top: "Convolution453"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale453"
  type: "Scale"
  bottom: "Convolution453"
  top: "Convolution453"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU453"
  type: "ReLU"
  bottom: "Convolution453"
  top: "Convolution453"
}
layer {
  name: "Convolution454"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution454"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm454"
  type: "BatchNorm"
  bottom: "Convolution454"
  top: "Convolution454"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale454"
  type: "Scale"
  bottom: "Convolution454"
  top: "Convolution454"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU454"
  type: "ReLU"
  bottom: "Convolution454"
  top: "Convolution454"
}
layer {
  name: "Convolution455"
  type: "Convolution"
  bottom: "Convolution454"
  top: "Convolution455"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm455"
  type: "BatchNorm"
  bottom: "Convolution455"
  top: "Convolution455"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale455"
  type: "Scale"
  bottom: "Convolution455"
  top: "Convolution455"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU455"
  type: "ReLU"
  bottom: "Convolution455"
  top: "Convolution455"
}
layer {
  name: "Convolution456"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution456"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm456"
  type: "BatchNorm"
  bottom: "Convolution456"
  top: "Convolution456"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale456"
  type: "Scale"
  bottom: "Convolution456"
  top: "Convolution456"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU456"
  type: "ReLU"
  bottom: "Convolution456"
  top: "Convolution456"
}
layer {
  name: "Convolution457"
  type: "Convolution"
  bottom: "Convolution456"
  top: "Convolution457"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm457"
  type: "BatchNorm"
  bottom: "Convolution457"
  top: "Convolution457"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale457"
  type: "Scale"
  bottom: "Convolution457"
  top: "Convolution457"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU457"
  type: "ReLU"
  bottom: "Convolution457"
  top: "Convolution457"
}
layer {
  name: "Convolution458"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution458"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm458"
  type: "BatchNorm"
  bottom: "Convolution458"
  top: "Convolution458"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale458"
  type: "Scale"
  bottom: "Convolution458"
  top: "Convolution458"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU458"
  type: "ReLU"
  bottom: "Convolution458"
  top: "Convolution458"
}
layer {
  name: "Convolution459"
  type: "Convolution"
  bottom: "Convolution458"
  top: "Convolution459"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm459"
  type: "BatchNorm"
  bottom: "Convolution459"
  top: "Convolution459"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale459"
  type: "Scale"
  bottom: "Convolution459"
  top: "Convolution459"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU459"
  type: "ReLU"
  bottom: "Convolution459"
  top: "Convolution459"
}
layer {
  name: "Convolution460"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution460"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm460"
  type: "BatchNorm"
  bottom: "Convolution460"
  top: "Convolution460"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale460"
  type: "Scale"
  bottom: "Convolution460"
  top: "Convolution460"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU460"
  type: "ReLU"
  bottom: "Convolution460"
  top: "Convolution460"
}
layer {
  name: "Convolution461"
  type: "Convolution"
  bottom: "Convolution460"
  top: "Convolution461"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm461"
  type: "BatchNorm"
  bottom: "Convolution461"
  top: "Convolution461"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale461"
  type: "Scale"
  bottom: "Convolution461"
  top: "Convolution461"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU461"
  type: "ReLU"
  bottom: "Convolution461"
  top: "Convolution461"
}
layer {
  name: "Concat7"
  type: "Concat"
  bottom: "Convolution399"
  bottom: "Convolution401"
  bottom: "Convolution403"
  bottom: "Convolution405"
  bottom: "Convolution407"
  bottom: "Convolution409"
  bottom: "Convolution411"
  bottom: "Convolution413"
  bottom: "Convolution415"
  bottom: "Convolution417"
  bottom: "Convolution419"
  bottom: "Convolution421"
  bottom: "Convolution423"
  bottom: "Convolution425"
  bottom: "Convolution427"
  bottom: "Convolution429"
  bottom: "Convolution431"
  bottom: "Convolution433"
  bottom: "Convolution435"
  bottom: "Convolution437"
  bottom: "Convolution439"
  bottom: "Convolution441"
  bottom: "Convolution443"
  bottom: "Convolution445"
  bottom: "Convolution447"
  bottom: "Convolution449"
  bottom: "Convolution451"
  bottom: "Convolution453"
  bottom: "Convolution455"
  bottom: "Convolution457"
  bottom: "Convolution459"
  bottom: "Convolution461"
  top: "Concat7"
}
layer {
  name: "Convolution462"
  type: "Convolution"
  bottom: "Concat7"
  top: "Convolution462"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 2048
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm462"
  type: "BatchNorm"
  bottom: "Convolution462"
  top: "Convolution462"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale462"
  type: "Scale"
  bottom: "Convolution462"
  top: "Convolution462"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU462"
  type: "ReLU"
  bottom: "Convolution462"
  top: "Convolution462"
}
layer {
  name: "Convolution463"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution463"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 2048
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm463"
  type: "BatchNorm"
  bottom: "Convolution463"
  top: "Convolution463"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale463"
  type: "Scale"
  bottom: "Convolution463"
  top: "Convolution463"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU463"
  type: "ReLU"
  bottom: "Convolution463"
  top: "Convolution463"
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution462"
  bottom: "Convolution463"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution464"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution464"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm464"
  type: "BatchNorm"
  bottom: "Convolution464"
  top: "Convolution464"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale464"
  type: "Scale"
  bottom: "Convolution464"
  top: "Convolution464"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU464"
  type: "ReLU"
  bottom: "Convolution464"
  top: "Convolution464"
}
layer {
  name: "Convolution465"
  type: "Convolution"
  bottom: "Convolution464"
  top: "Convolution465"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm465"
  type: "BatchNorm"
  bottom: "Convolution465"
  top: "Convolution465"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale465"
  type: "Scale"
  bottom: "Convolution465"
  top: "Convolution465"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU465"
  type: "ReLU"
  bottom: "Convolution465"
  top: "Convolution465"
}
layer {
  name: "Convolution466"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution466"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm466"
  type: "BatchNorm"
  bottom: "Convolution466"
  top: "Convolution466"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale466"
  type: "Scale"
  bottom: "Convolution466"
  top: "Convolution466"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU466"
  type: "ReLU"
  bottom: "Convolution466"
  top: "Convolution466"
}
layer {
  name: "Convolution467"
  type: "Convolution"
  bottom: "Convolution466"
  top: "Convolution467"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm467"
  type: "BatchNorm"
  bottom: "Convolution467"
  top: "Convolution467"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale467"
  type: "Scale"
  bottom: "Convolution467"
  top: "Convolution467"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU467"
  type: "ReLU"
  bottom: "Convolution467"
  top: "Convolution467"
}
layer {
  name: "Convolution468"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution468"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm468"
  type: "BatchNorm"
  bottom: "Convolution468"
  top: "Convolution468"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale468"
  type: "Scale"
  bottom: "Convolution468"
  top: "Convolution468"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU468"
  type: "ReLU"
  bottom: "Convolution468"
  top: "Convolution468"
}
layer {
  name: "Convolution469"
  type: "Convolution"
  bottom: "Convolution468"
  top: "Convolution469"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm469"
  type: "BatchNorm"
  bottom: "Convolution469"
  top: "Convolution469"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale469"
  type: "Scale"
  bottom: "Convolution469"
  top: "Convolution469"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU469"
  type: "ReLU"
  bottom: "Convolution469"
  top: "Convolution469"
}
layer {
  name: "Convolution470"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution470"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm470"
  type: "BatchNorm"
  bottom: "Convolution470"
  top: "Convolution470"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale470"
  type: "Scale"
  bottom: "Convolution470"
  top: "Convolution470"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU470"
  type: "ReLU"
  bottom: "Convolution470"
  top: "Convolution470"
}
layer {
  name: "Convolution471"
  type: "Convolution"
  bottom: "Convolution470"
  top: "Convolution471"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm471"
  type: "BatchNorm"
  bottom: "Convolution471"
  top: "Convolution471"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale471"
  type: "Scale"
  bottom: "Convolution471"
  top: "Convolution471"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU471"
  type: "ReLU"
  bottom: "Convolution471"
  top: "Convolution471"
}
layer {
  name: "Convolution472"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution472"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm472"
  type: "BatchNorm"
  bottom: "Convolution472"
  top: "Convolution472"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale472"
  type: "Scale"
  bottom: "Convolution472"
  top: "Convolution472"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU472"
  type: "ReLU"
  bottom: "Convolution472"
  top: "Convolution472"
}
layer {
  name: "Convolution473"
  type: "Convolution"
  bottom: "Convolution472"
  top: "Convolution473"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm473"
  type: "BatchNorm"
  bottom: "Convolution473"
  top: "Convolution473"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale473"
  type: "Scale"
  bottom: "Convolution473"
  top: "Convolution473"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU473"
  type: "ReLU"
  bottom: "Convolution473"
  top: "Convolution473"
}
layer {
  name: "Convolution474"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution474"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm474"
  type: "BatchNorm"
  bottom: "Convolution474"
  top: "Convolution474"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale474"
  type: "Scale"
  bottom: "Convolution474"
  top: "Convolution474"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU474"
  type: "ReLU"
  bottom: "Convolution474"
  top: "Convolution474"
}
layer {
  name: "Convolution475"
  type: "Convolution"
  bottom: "Convolution474"
  top: "Convolution475"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm475"
  type: "BatchNorm"
  bottom: "Convolution475"
  top: "Convolution475"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale475"
  type: "Scale"
  bottom: "Convolution475"
  top: "Convolution475"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU475"
  type: "ReLU"
  bottom: "Convolution475"
  top: "Convolution475"
}
layer {
  name: "Convolution476"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution476"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm476"
  type: "BatchNorm"
  bottom: "Convolution476"
  top: "Convolution476"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale476"
  type: "Scale"
  bottom: "Convolution476"
  top: "Convolution476"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU476"
  type: "ReLU"
  bottom: "Convolution476"
  top: "Convolution476"
}
layer {
  name: "Convolution477"
  type: "Convolution"
  bottom: "Convolution476"
  top: "Convolution477"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm477"
  type: "BatchNorm"
  bottom: "Convolution477"
  top: "Convolution477"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale477"
  type: "Scale"
  bottom: "Convolution477"
  top: "Convolution477"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU477"
  type: "ReLU"
  bottom: "Convolution477"
  top: "Convolution477"
}
layer {
  name: "Convolution478"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution478"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm478"
  type: "BatchNorm"
  bottom: "Convolution478"
  top: "Convolution478"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale478"
  type: "Scale"
  bottom: "Convolution478"
  top: "Convolution478"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU478"
  type: "ReLU"
  bottom: "Convolution478"
  top: "Convolution478"
}
layer {
  name: "Convolution479"
  type: "Convolution"
  bottom: "Convolution478"
  top: "Convolution479"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm479"
  type: "BatchNorm"
  bottom: "Convolution479"
  top: "Convolution479"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale479"
  type: "Scale"
  bottom: "Convolution479"
  top: "Convolution479"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU479"
  type: "ReLU"
  bottom: "Convolution479"
  top: "Convolution479"
}
layer {
  name: "Convolution480"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution480"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm480"
  type: "BatchNorm"
  bottom: "Convolution480"
  top: "Convolution480"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale480"
  type: "Scale"
  bottom: "Convolution480"
  top: "Convolution480"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU480"
  type: "ReLU"
  bottom: "Convolution480"
  top: "Convolution480"
}
layer {
  name: "Convolution481"
  type: "Convolution"
  bottom: "Convolution480"
  top: "Convolution481"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm481"
  type: "BatchNorm"
  bottom: "Convolution481"
  top: "Convolution481"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale481"
  type: "Scale"
  bottom: "Convolution481"
  top: "Convolution481"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU481"
  type: "ReLU"
  bottom: "Convolution481"
  top: "Convolution481"
}
layer {
  name: "Convolution482"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution482"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm482"
  type: "BatchNorm"
  bottom: "Convolution482"
  top: "Convolution482"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale482"
  type: "Scale"
  bottom: "Convolution482"
  top: "Convolution482"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU482"
  type: "ReLU"
  bottom: "Convolution482"
  top: "Convolution482"
}
layer {
  name: "Convolution483"
  type: "Convolution"
  bottom: "Convolution482"
  top: "Convolution483"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm483"
  type: "BatchNorm"
  bottom: "Convolution483"
  top: "Convolution483"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale483"
  type: "Scale"
  bottom: "Convolution483"
  top: "Convolution483"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU483"
  type: "ReLU"
  bottom: "Convolution483"
  top: "Convolution483"
}
layer {
  name: "Convolution484"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution484"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm484"
  type: "BatchNorm"
  bottom: "Convolution484"
  top: "Convolution484"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale484"
  type: "Scale"
  bottom: "Convolution484"
  top: "Convolution484"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU484"
  type: "ReLU"
  bottom: "Convolution484"
  top: "Convolution484"
}
layer {
  name: "Convolution485"
  type: "Convolution"
  bottom: "Convolution484"
  top: "Convolution485"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm485"
  type: "BatchNorm"
  bottom: "Convolution485"
  top: "Convolution485"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale485"
  type: "Scale"
  bottom: "Convolution485"
  top: "Convolution485"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU485"
  type: "ReLU"
  bottom: "Convolution485"
  top: "Convolution485"
}
layer {
  name: "Convolution486"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution486"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm486"
  type: "BatchNorm"
  bottom: "Convolution486"
  top: "Convolution486"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale486"
  type: "Scale"
  bottom: "Convolution486"
  top: "Convolution486"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU486"
  type: "ReLU"
  bottom: "Convolution486"
  top: "Convolution486"
}
layer {
  name: "Convolution487"
  type: "Convolution"
  bottom: "Convolution486"
  top: "Convolution487"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm487"
  type: "BatchNorm"
  bottom: "Convolution487"
  top: "Convolution487"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale487"
  type: "Scale"
  bottom: "Convolution487"
  top: "Convolution487"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU487"
  type: "ReLU"
  bottom: "Convolution487"
  top: "Convolution487"
}
layer {
  name: "Convolution488"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution488"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm488"
  type: "BatchNorm"
  bottom: "Convolution488"
  top: "Convolution488"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale488"
  type: "Scale"
  bottom: "Convolution488"
  top: "Convolution488"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU488"
  type: "ReLU"
  bottom: "Convolution488"
  top: "Convolution488"
}
layer {
  name: "Convolution489"
  type: "Convolution"
  bottom: "Convolution488"
  top: "Convolution489"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm489"
  type: "BatchNorm"
  bottom: "Convolution489"
  top: "Convolution489"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale489"
  type: "Scale"
  bottom: "Convolution489"
  top: "Convolution489"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU489"
  type: "ReLU"
  bottom: "Convolution489"
  top: "Convolution489"
}
layer {
  name: "Convolution490"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution490"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm490"
  type: "BatchNorm"
  bottom: "Convolution490"
  top: "Convolution490"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale490"
  type: "Scale"
  bottom: "Convolution490"
  top: "Convolution490"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU490"
  type: "ReLU"
  bottom: "Convolution490"
  top: "Convolution490"
}
layer {
  name: "Convolution491"
  type: "Convolution"
  bottom: "Convolution490"
  top: "Convolution491"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm491"
  type: "BatchNorm"
  bottom: "Convolution491"
  top: "Convolution491"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale491"
  type: "Scale"
  bottom: "Convolution491"
  top: "Convolution491"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU491"
  type: "ReLU"
  bottom: "Convolution491"
  top: "Convolution491"
}
layer {
  name: "Convolution492"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution492"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm492"
  type: "BatchNorm"
  bottom: "Convolution492"
  top: "Convolution492"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale492"
  type: "Scale"
  bottom: "Convolution492"
  top: "Convolution492"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU492"
  type: "ReLU"
  bottom: "Convolution492"
  top: "Convolution492"
}
layer {
  name: "Convolution493"
  type: "Convolution"
  bottom: "Convolution492"
  top: "Convolution493"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm493"
  type: "BatchNorm"
  bottom: "Convolution493"
  top: "Convolution493"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale493"
  type: "Scale"
  bottom: "Convolution493"
  top: "Convolution493"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU493"
  type: "ReLU"
  bottom: "Convolution493"
  top: "Convolution493"
}
layer {
  name: "Convolution494"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution494"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm494"
  type: "BatchNorm"
  bottom: "Convolution494"
  top: "Convolution494"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale494"
  type: "Scale"
  bottom: "Convolution494"
  top: "Convolution494"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU494"
  type: "ReLU"
  bottom: "Convolution494"
  top: "Convolution494"
}
layer {
  name: "Convolution495"
  type: "Convolution"
  bottom: "Convolution494"
  top: "Convolution495"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm495"
  type: "BatchNorm"
  bottom: "Convolution495"
  top: "Convolution495"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale495"
  type: "Scale"
  bottom: "Convolution495"
  top: "Convolution495"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU495"
  type: "ReLU"
  bottom: "Convolution495"
  top: "Convolution495"
}
layer {
  name: "Convolution496"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution496"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm496"
  type: "BatchNorm"
  bottom: "Convolution496"
  top: "Convolution496"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale496"
  type: "Scale"
  bottom: "Convolution496"
  top: "Convolution496"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU496"
  type: "ReLU"
  bottom: "Convolution496"
  top: "Convolution496"
}
layer {
  name: "Convolution497"
  type: "Convolution"
  bottom: "Convolution496"
  top: "Convolution497"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm497"
  type: "BatchNorm"
  bottom: "Convolution497"
  top: "Convolution497"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale497"
  type: "Scale"
  bottom: "Convolution497"
  top: "Convolution497"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU497"
  type: "ReLU"
  bottom: "Convolution497"
  top: "Convolution497"
}
layer {
  name: "Convolution498"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution498"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm498"
  type: "BatchNorm"
  bottom: "Convolution498"
  top: "Convolution498"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale498"
  type: "Scale"
  bottom: "Convolution498"
  top: "Convolution498"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU498"
  type: "ReLU"
  bottom: "Convolution498"
  top: "Convolution498"
}
layer {
  name: "Convolution499"
  type: "Convolution"
  bottom: "Convolution498"
  top: "Convolution499"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm499"
  type: "BatchNorm"
  bottom: "Convolution499"
  top: "Convolution499"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale499"
  type: "Scale"
  bottom: "Convolution499"
  top: "Convolution499"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU499"
  type: "ReLU"
  bottom: "Convolution499"
  top: "Convolution499"
}
layer {
  name: "Convolution500"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution500"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm500"
  type: "BatchNorm"
  bottom: "Convolution500"
  top: "Convolution500"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale500"
  type: "Scale"
  bottom: "Convolution500"
  top: "Convolution500"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU500"
  type: "ReLU"
  bottom: "Convolution500"
  top: "Convolution500"
}
layer {
  name: "Convolution501"
  type: "Convolution"
  bottom: "Convolution500"
  top: "Convolution501"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm501"
  type: "BatchNorm"
  bottom: "Convolution501"
  top: "Convolution501"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale501"
  type: "Scale"
  bottom: "Convolution501"
  top: "Convolution501"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU501"
  type: "ReLU"
  bottom: "Convolution501"
  top: "Convolution501"
}
layer {
  name: "Convolution502"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution502"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm502"
  type: "BatchNorm"
  bottom: "Convolution502"
  top: "Convolution502"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale502"
  type: "Scale"
  bottom: "Convolution502"
  top: "Convolution502"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU502"
  type: "ReLU"
  bottom: "Convolution502"
  top: "Convolution502"
}
layer {
  name: "Convolution503"
  type: "Convolution"
  bottom: "Convolution502"
  top: "Convolution503"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm503"
  type: "BatchNorm"
  bottom: "Convolution503"
  top: "Convolution503"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale503"
  type: "Scale"
  bottom: "Convolution503"
  top: "Convolution503"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU503"
  type: "ReLU"
  bottom: "Convolution503"
  top: "Convolution503"
}
layer {
  name: "Convolution504"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution504"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm504"
  type: "BatchNorm"
  bottom: "Convolution504"
  top: "Convolution504"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale504"
  type: "Scale"
  bottom: "Convolution504"
  top: "Convolution504"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU504"
  type: "ReLU"
  bottom: "Convolution504"
  top: "Convolution504"
}
layer {
  name: "Convolution505"
  type: "Convolution"
  bottom: "Convolution504"
  top: "Convolution505"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm505"
  type: "BatchNorm"
  bottom: "Convolution505"
  top: "Convolution505"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale505"
  type: "Scale"
  bottom: "Convolution505"
  top: "Convolution505"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU505"
  type: "ReLU"
  bottom: "Convolution505"
  top: "Convolution505"
}
layer {
  name: "Convolution506"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution506"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm506"
  type: "BatchNorm"
  bottom: "Convolution506"
  top: "Convolution506"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale506"
  type: "Scale"
  bottom: "Convolution506"
  top: "Convolution506"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU506"
  type: "ReLU"
  bottom: "Convolution506"
  top: "Convolution506"
}
layer {
  name: "Convolution507"
  type: "Convolution"
  bottom: "Convolution506"
  top: "Convolution507"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm507"
  type: "BatchNorm"
  bottom: "Convolution507"
  top: "Convolution507"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale507"
  type: "Scale"
  bottom: "Convolution507"
  top: "Convolution507"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU507"
  type: "ReLU"
  bottom: "Convolution507"
  top: "Convolution507"
}
layer {
  name: "Convolution508"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution508"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm508"
  type: "BatchNorm"
  bottom: "Convolution508"
  top: "Convolution508"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale508"
  type: "Scale"
  bottom: "Convolution508"
  top: "Convolution508"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU508"
  type: "ReLU"
  bottom: "Convolution508"
  top: "Convolution508"
}
layer {
  name: "Convolution509"
  type: "Convolution"
  bottom: "Convolution508"
  top: "Convolution509"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm509"
  type: "BatchNorm"
  bottom: "Convolution509"
  top: "Convolution509"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale509"
  type: "Scale"
  bottom: "Convolution509"
  top: "Convolution509"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU509"
  type: "ReLU"
  bottom: "Convolution509"
  top: "Convolution509"
}
layer {
  name: "Convolution510"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution510"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm510"
  type: "BatchNorm"
  bottom: "Convolution510"
  top: "Convolution510"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale510"
  type: "Scale"
  bottom: "Convolution510"
  top: "Convolution510"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU510"
  type: "ReLU"
  bottom: "Convolution510"
  top: "Convolution510"
}
layer {
  name: "Convolution511"
  type: "Convolution"
  bottom: "Convolution510"
  top: "Convolution511"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm511"
  type: "BatchNorm"
  bottom: "Convolution511"
  top: "Convolution511"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale511"
  type: "Scale"
  bottom: "Convolution511"
  top: "Convolution511"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU511"
  type: "ReLU"
  bottom: "Convolution511"
  top: "Convolution511"
}
layer {
  name: "Convolution512"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution512"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm512"
  type: "BatchNorm"
  bottom: "Convolution512"
  top: "Convolution512"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale512"
  type: "Scale"
  bottom: "Convolution512"
  top: "Convolution512"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU512"
  type: "ReLU"
  bottom: "Convolution512"
  top: "Convolution512"
}
layer {
  name: "Convolution513"
  type: "Convolution"
  bottom: "Convolution512"
  top: "Convolution513"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm513"
  type: "BatchNorm"
  bottom: "Convolution513"
  top: "Convolution513"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale513"
  type: "Scale"
  bottom: "Convolution513"
  top: "Convolution513"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU513"
  type: "ReLU"
  bottom: "Convolution513"
  top: "Convolution513"
}
layer {
  name: "Convolution514"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution514"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm514"
  type: "BatchNorm"
  bottom: "Convolution514"
  top: "Convolution514"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale514"
  type: "Scale"
  bottom: "Convolution514"
  top: "Convolution514"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU514"
  type: "ReLU"
  bottom: "Convolution514"
  top: "Convolution514"
}
layer {
  name: "Convolution515"
  type: "Convolution"
  bottom: "Convolution514"
  top: "Convolution515"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm515"
  type: "BatchNorm"
  bottom: "Convolution515"
  top: "Convolution515"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale515"
  type: "Scale"
  bottom: "Convolution515"
  top: "Convolution515"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU515"
  type: "ReLU"
  bottom: "Convolution515"
  top: "Convolution515"
}
layer {
  name: "Convolution516"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution516"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm516"
  type: "BatchNorm"
  bottom: "Convolution516"
  top: "Convolution516"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale516"
  type: "Scale"
  bottom: "Convolution516"
  top: "Convolution516"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU516"
  type: "ReLU"
  bottom: "Convolution516"
  top: "Convolution516"
}
layer {
  name: "Convolution517"
  type: "Convolution"
  bottom: "Convolution516"
  top: "Convolution517"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm517"
  type: "BatchNorm"
  bottom: "Convolution517"
  top: "Convolution517"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale517"
  type: "Scale"
  bottom: "Convolution517"
  top: "Convolution517"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU517"
  type: "ReLU"
  bottom: "Convolution517"
  top: "Convolution517"
}
layer {
  name: "Convolution518"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution518"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm518"
  type: "BatchNorm"
  bottom: "Convolution518"
  top: "Convolution518"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale518"
  type: "Scale"
  bottom: "Convolution518"
  top: "Convolution518"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU518"
  type: "ReLU"
  bottom: "Convolution518"
  top: "Convolution518"
}
layer {
  name: "Convolution519"
  type: "Convolution"
  bottom: "Convolution518"
  top: "Convolution519"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm519"
  type: "BatchNorm"
  bottom: "Convolution519"
  top: "Convolution519"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale519"
  type: "Scale"
  bottom: "Convolution519"
  top: "Convolution519"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU519"
  type: "ReLU"
  bottom: "Convolution519"
  top: "Convolution519"
}
layer {
  name: "Convolution520"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution520"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm520"
  type: "BatchNorm"
  bottom: "Convolution520"
  top: "Convolution520"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale520"
  type: "Scale"
  bottom: "Convolution520"
  top: "Convolution520"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU520"
  type: "ReLU"
  bottom: "Convolution520"
  top: "Convolution520"
}
layer {
  name: "Convolution521"
  type: "Convolution"
  bottom: "Convolution520"
  top: "Convolution521"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm521"
  type: "BatchNorm"
  bottom: "Convolution521"
  top: "Convolution521"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale521"
  type: "Scale"
  bottom: "Convolution521"
  top: "Convolution521"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU521"
  type: "ReLU"
  bottom: "Convolution521"
  top: "Convolution521"
}
layer {
  name: "Convolution522"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution522"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm522"
  type: "BatchNorm"
  bottom: "Convolution522"
  top: "Convolution522"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale522"
  type: "Scale"
  bottom: "Convolution522"
  top: "Convolution522"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU522"
  type: "ReLU"
  bottom: "Convolution522"
  top: "Convolution522"
}
layer {
  name: "Convolution523"
  type: "Convolution"
  bottom: "Convolution522"
  top: "Convolution523"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm523"
  type: "BatchNorm"
  bottom: "Convolution523"
  top: "Convolution523"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale523"
  type: "Scale"
  bottom: "Convolution523"
  top: "Convolution523"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU523"
  type: "ReLU"
  bottom: "Convolution523"
  top: "Convolution523"
}
layer {
  name: "Convolution524"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution524"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm524"
  type: "BatchNorm"
  bottom: "Convolution524"
  top: "Convolution524"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale524"
  type: "Scale"
  bottom: "Convolution524"
  top: "Convolution524"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU524"
  type: "ReLU"
  bottom: "Convolution524"
  top: "Convolution524"
}
layer {
  name: "Convolution525"
  type: "Convolution"
  bottom: "Convolution524"
  top: "Convolution525"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm525"
  type: "BatchNorm"
  bottom: "Convolution525"
  top: "Convolution525"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale525"
  type: "Scale"
  bottom: "Convolution525"
  top: "Convolution525"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU525"
  type: "ReLU"
  bottom: "Convolution525"
  top: "Convolution525"
}
layer {
  name: "Convolution526"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution526"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm526"
  type: "BatchNorm"
  bottom: "Convolution526"
  top: "Convolution526"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale526"
  type: "Scale"
  bottom: "Convolution526"
  top: "Convolution526"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU526"
  type: "ReLU"
  bottom: "Convolution526"
  top: "Convolution526"
}
layer {
  name: "Convolution527"
  type: "Convolution"
  bottom: "Convolution526"
  top: "Convolution527"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm527"
  type: "BatchNorm"
  bottom: "Convolution527"
  top: "Convolution527"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale527"
  type: "Scale"
  bottom: "Convolution527"
  top: "Convolution527"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU527"
  type: "ReLU"
  bottom: "Convolution527"
  top: "Convolution527"
}
layer {
  name: "Concat8"
  type: "Concat"
  bottom: "Convolution465"
  bottom: "Convolution467"
  bottom: "Convolution469"
  bottom: "Convolution471"
  bottom: "Convolution473"
  bottom: "Convolution475"
  bottom: "Convolution477"
  bottom: "Convolution479"
  bottom: "Convolution481"
  bottom: "Convolution483"
  bottom: "Convolution485"
  bottom: "Convolution487"
  bottom: "Convolution489"
  bottom: "Convolution491"
  bottom: "Convolution493"
  bottom: "Convolution495"
  bottom: "Convolution497"
  bottom: "Convolution499"
  bottom: "Convolution501"
  bottom: "Convolution503"
  bottom: "Convolution505"
  bottom: "Convolution507"
  bottom: "Convolution509"
  bottom: "Convolution511"
  bottom: "Convolution513"
  bottom: "Convolution515"
  bottom: "Convolution517"
  bottom: "Convolution519"
  bottom: "Convolution521"
  bottom: "Convolution523"
  bottom: "Convolution525"
  bottom: "Convolution527"
  top: "Concat8"
}
layer {
  name: "Convolution528"
  type: "Convolution"
  bottom: "Concat8"
  top: "Convolution528"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm528"
  type: "BatchNorm"
  bottom: "Convolution528"
  top: "Convolution528"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale528"
  type: "Scale"
  bottom: "Convolution528"
  top: "Convolution528"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU528"
  type: "ReLU"
  bottom: "Convolution528"
  top: "Convolution528"
}
layer {
  name: "Convolution529"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution529"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm529"
  type: "BatchNorm"
  bottom: "Convolution529"
  top: "Convolution529"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale529"
  type: "Scale"
  bottom: "Convolution529"
  top: "Convolution529"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU529"
  type: "ReLU"
  bottom: "Convolution529"
  top: "Convolution529"
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Convolution528"
  bottom: "Convolution529"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution530"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution530"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm530"
  type: "BatchNorm"
  bottom: "Convolution530"
  top: "Convolution530"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale530"
  type: "Scale"
  bottom: "Convolution530"
  top: "Convolution530"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU530"
  type: "ReLU"
  bottom: "Convolution530"
  top: "Convolution530"
}
layer {
  name: "Convolution531"
  type: "Convolution"
  bottom: "Convolution530"
  top: "Convolution531"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm531"
  type: "BatchNorm"
  bottom: "Convolution531"
  top: "Convolution531"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale531"
  type: "Scale"
  bottom: "Convolution531"
  top: "Convolution531"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU531"
  type: "ReLU"
  bottom: "Convolution531"
  top: "Convolution531"
}
layer {
  name: "Convolution532"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution532"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm532"
  type: "BatchNorm"
  bottom: "Convolution532"
  top: "Convolution532"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale532"
  type: "Scale"
  bottom: "Convolution532"
  top: "Convolution532"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU532"
  type: "ReLU"
  bottom: "Convolution532"
  top: "Convolution532"
}
layer {
  name: "Convolution533"
  type: "Convolution"
  bottom: "Convolution532"
  top: "Convolution533"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm533"
  type: "BatchNorm"
  bottom: "Convolution533"
  top: "Convolution533"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale533"
  type: "Scale"
  bottom: "Convolution533"
  top: "Convolution533"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU533"
  type: "ReLU"
  bottom: "Convolution533"
  top: "Convolution533"
}
layer {
  name: "Convolution534"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution534"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm534"
  type: "BatchNorm"
  bottom: "Convolution534"
  top: "Convolution534"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale534"
  type: "Scale"
  bottom: "Convolution534"
  top: "Convolution534"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU534"
  type: "ReLU"
  bottom: "Convolution534"
  top: "Convolution534"
}
layer {
  name: "Convolution535"
  type: "Convolution"
  bottom: "Convolution534"
  top: "Convolution535"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm535"
  type: "BatchNorm"
  bottom: "Convolution535"
  top: "Convolution535"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale535"
  type: "Scale"
  bottom: "Convolution535"
  top: "Convolution535"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU535"
  type: "ReLU"
  bottom: "Convolution535"
  top: "Convolution535"
}
layer {
  name: "Convolution536"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution536"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm536"
  type: "BatchNorm"
  bottom: "Convolution536"
  top: "Convolution536"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale536"
  type: "Scale"
  bottom: "Convolution536"
  top: "Convolution536"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU536"
  type: "ReLU"
  bottom: "Convolution536"
  top: "Convolution536"
}
layer {
  name: "Convolution537"
  type: "Convolution"
  bottom: "Convolution536"
  top: "Convolution537"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm537"
  type: "BatchNorm"
  bottom: "Convolution537"
  top: "Convolution537"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale537"
  type: "Scale"
  bottom: "Convolution537"
  top: "Convolution537"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU537"
  type: "ReLU"
  bottom: "Convolution537"
  top: "Convolution537"
}
layer {
  name: "Convolution538"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution538"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm538"
  type: "BatchNorm"
  bottom: "Convolution538"
  top: "Convolution538"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale538"
  type: "Scale"
  bottom: "Convolution538"
  top: "Convolution538"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU538"
  type: "ReLU"
  bottom: "Convolution538"
  top: "Convolution538"
}
layer {
  name: "Convolution539"
  type: "Convolution"
  bottom: "Convolution538"
  top: "Convolution539"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm539"
  type: "BatchNorm"
  bottom: "Convolution539"
  top: "Convolution539"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale539"
  type: "Scale"
  bottom: "Convolution539"
  top: "Convolution539"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU539"
  type: "ReLU"
  bottom: "Convolution539"
  top: "Convolution539"
}
layer {
  name: "Convolution540"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution540"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm540"
  type: "BatchNorm"
  bottom: "Convolution540"
  top: "Convolution540"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale540"
  type: "Scale"
  bottom: "Convolution540"
  top: "Convolution540"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU540"
  type: "ReLU"
  bottom: "Convolution540"
  top: "Convolution540"
}
layer {
  name: "Convolution541"
  type: "Convolution"
  bottom: "Convolution540"
  top: "Convolution541"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm541"
  type: "BatchNorm"
  bottom: "Convolution541"
  top: "Convolution541"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale541"
  type: "Scale"
  bottom: "Convolution541"
  top: "Convolution541"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU541"
  type: "ReLU"
  bottom: "Convolution541"
  top: "Convolution541"
}
layer {
  name: "Convolution542"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution542"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm542"
  type: "BatchNorm"
  bottom: "Convolution542"
  top: "Convolution542"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale542"
  type: "Scale"
  bottom: "Convolution542"
  top: "Convolution542"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU542"
  type: "ReLU"
  bottom: "Convolution542"
  top: "Convolution542"
}
layer {
  name: "Convolution543"
  type: "Convolution"
  bottom: "Convolution542"
  top: "Convolution543"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm543"
  type: "BatchNorm"
  bottom: "Convolution543"
  top: "Convolution543"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale543"
  type: "Scale"
  bottom: "Convolution543"
  top: "Convolution543"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU543"
  type: "ReLU"
  bottom: "Convolution543"
  top: "Convolution543"
}
layer {
  name: "Convolution544"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution544"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm544"
  type: "BatchNorm"
  bottom: "Convolution544"
  top: "Convolution544"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale544"
  type: "Scale"
  bottom: "Convolution544"
  top: "Convolution544"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU544"
  type: "ReLU"
  bottom: "Convolution544"
  top: "Convolution544"
}
layer {
  name: "Convolution545"
  type: "Convolution"
  bottom: "Convolution544"
  top: "Convolution545"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm545"
  type: "BatchNorm"
  bottom: "Convolution545"
  top: "Convolution545"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale545"
  type: "Scale"
  bottom: "Convolution545"
  top: "Convolution545"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU545"
  type: "ReLU"
  bottom: "Convolution545"
  top: "Convolution545"
}
layer {
  name: "Convolution546"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution546"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm546"
  type: "BatchNorm"
  bottom: "Convolution546"
  top: "Convolution546"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale546"
  type: "Scale"
  bottom: "Convolution546"
  top: "Convolution546"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU546"
  type: "ReLU"
  bottom: "Convolution546"
  top: "Convolution546"
}
layer {
  name: "Convolution547"
  type: "Convolution"
  bottom: "Convolution546"
  top: "Convolution547"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm547"
  type: "BatchNorm"
  bottom: "Convolution547"
  top: "Convolution547"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale547"
  type: "Scale"
  bottom: "Convolution547"
  top: "Convolution547"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU547"
  type: "ReLU"
  bottom: "Convolution547"
  top: "Convolution547"
}
layer {
  name: "Convolution548"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution548"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm548"
  type: "BatchNorm"
  bottom: "Convolution548"
  top: "Convolution548"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale548"
  type: "Scale"
  bottom: "Convolution548"
  top: "Convolution548"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU548"
  type: "ReLU"
  bottom: "Convolution548"
  top: "Convolution548"
}
layer {
  name: "Convolution549"
  type: "Convolution"
  bottom: "Convolution548"
  top: "Convolution549"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm549"
  type: "BatchNorm"
  bottom: "Convolution549"
  top: "Convolution549"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale549"
  type: "Scale"
  bottom: "Convolution549"
  top: "Convolution549"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU549"
  type: "ReLU"
  bottom: "Convolution549"
  top: "Convolution549"
}
layer {
  name: "Convolution550"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution550"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm550"
  type: "BatchNorm"
  bottom: "Convolution550"
  top: "Convolution550"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale550"
  type: "Scale"
  bottom: "Convolution550"
  top: "Convolution550"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU550"
  type: "ReLU"
  bottom: "Convolution550"
  top: "Convolution550"
}
layer {
  name: "Convolution551"
  type: "Convolution"
  bottom: "Convolution550"
  top: "Convolution551"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm551"
  type: "BatchNorm"
  bottom: "Convolution551"
  top: "Convolution551"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale551"
  type: "Scale"
  bottom: "Convolution551"
  top: "Convolution551"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU551"
  type: "ReLU"
  bottom: "Convolution551"
  top: "Convolution551"
}
layer {
  name: "Convolution552"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution552"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm552"
  type: "BatchNorm"
  bottom: "Convolution552"
  top: "Convolution552"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale552"
  type: "Scale"
  bottom: "Convolution552"
  top: "Convolution552"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU552"
  type: "ReLU"
  bottom: "Convolution552"
  top: "Convolution552"
}
layer {
  name: "Convolution553"
  type: "Convolution"
  bottom: "Convolution552"
  top: "Convolution553"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm553"
  type: "BatchNorm"
  bottom: "Convolution553"
  top: "Convolution553"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale553"
  type: "Scale"
  bottom: "Convolution553"
  top: "Convolution553"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU553"
  type: "ReLU"
  bottom: "Convolution553"
  top: "Convolution553"
}
layer {
  name: "Convolution554"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution554"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm554"
  type: "BatchNorm"
  bottom: "Convolution554"
  top: "Convolution554"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale554"
  type: "Scale"
  bottom: "Convolution554"
  top: "Convolution554"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU554"
  type: "ReLU"
  bottom: "Convolution554"
  top: "Convolution554"
}
layer {
  name: "Convolution555"
  type: "Convolution"
  bottom: "Convolution554"
  top: "Convolution555"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm555"
  type: "BatchNorm"
  bottom: "Convolution555"
  top: "Convolution555"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale555"
  type: "Scale"
  bottom: "Convolution555"
  top: "Convolution555"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU555"
  type: "ReLU"
  bottom: "Convolution555"
  top: "Convolution555"
}
layer {
  name: "Convolution556"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution556"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm556"
  type: "BatchNorm"
  bottom: "Convolution556"
  top: "Convolution556"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale556"
  type: "Scale"
  bottom: "Convolution556"
  top: "Convolution556"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU556"
  type: "ReLU"
  bottom: "Convolution556"
  top: "Convolution556"
}
layer {
  name: "Convolution557"
  type: "Convolution"
  bottom: "Convolution556"
  top: "Convolution557"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm557"
  type: "BatchNorm"
  bottom: "Convolution557"
  top: "Convolution557"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale557"
  type: "Scale"
  bottom: "Convolution557"
  top: "Convolution557"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU557"
  type: "ReLU"
  bottom: "Convolution557"
  top: "Convolution557"
}
layer {
  name: "Convolution558"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution558"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm558"
  type: "BatchNorm"
  bottom: "Convolution558"
  top: "Convolution558"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale558"
  type: "Scale"
  bottom: "Convolution558"
  top: "Convolution558"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU558"
  type: "ReLU"
  bottom: "Convolution558"
  top: "Convolution558"
}
layer {
  name: "Convolution559"
  type: "Convolution"
  bottom: "Convolution558"
  top: "Convolution559"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm559"
  type: "BatchNorm"
  bottom: "Convolution559"
  top: "Convolution559"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale559"
  type: "Scale"
  bottom: "Convolution559"
  top: "Convolution559"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU559"
  type: "ReLU"
  bottom: "Convolution559"
  top: "Convolution559"
}
layer {
  name: "Convolution560"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution560"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm560"
  type: "BatchNorm"
  bottom: "Convolution560"
  top: "Convolution560"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale560"
  type: "Scale"
  bottom: "Convolution560"
  top: "Convolution560"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU560"
  type: "ReLU"
  bottom: "Convolution560"
  top: "Convolution560"
}
layer {
  name: "Convolution561"
  type: "Convolution"
  bottom: "Convolution560"
  top: "Convolution561"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm561"
  type: "BatchNorm"
  bottom: "Convolution561"
  top: "Convolution561"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale561"
  type: "Scale"
  bottom: "Convolution561"
  top: "Convolution561"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU561"
  type: "ReLU"
  bottom: "Convolution561"
  top: "Convolution561"
}
layer {
  name: "Convolution562"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution562"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm562"
  type: "BatchNorm"
  bottom: "Convolution562"
  top: "Convolution562"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale562"
  type: "Scale"
  bottom: "Convolution562"
  top: "Convolution562"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU562"
  type: "ReLU"
  bottom: "Convolution562"
  top: "Convolution562"
}
layer {
  name: "Convolution563"
  type: "Convolution"
  bottom: "Convolution562"
  top: "Convolution563"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm563"
  type: "BatchNorm"
  bottom: "Convolution563"
  top: "Convolution563"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale563"
  type: "Scale"
  bottom: "Convolution563"
  top: "Convolution563"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU563"
  type: "ReLU"
  bottom: "Convolution563"
  top: "Convolution563"
}
layer {
  name: "Convolution564"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution564"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm564"
  type: "BatchNorm"
  bottom: "Convolution564"
  top: "Convolution564"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale564"
  type: "Scale"
  bottom: "Convolution564"
  top: "Convolution564"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU564"
  type: "ReLU"
  bottom: "Convolution564"
  top: "Convolution564"
}
layer {
  name: "Convolution565"
  type: "Convolution"
  bottom: "Convolution564"
  top: "Convolution565"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm565"
  type: "BatchNorm"
  bottom: "Convolution565"
  top: "Convolution565"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale565"
  type: "Scale"
  bottom: "Convolution565"
  top: "Convolution565"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU565"
  type: "ReLU"
  bottom: "Convolution565"
  top: "Convolution565"
}
layer {
  name: "Convolution566"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution566"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm566"
  type: "BatchNorm"
  bottom: "Convolution566"
  top: "Convolution566"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale566"
  type: "Scale"
  bottom: "Convolution566"
  top: "Convolution566"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU566"
  type: "ReLU"
  bottom: "Convolution566"
  top: "Convolution566"
}
layer {
  name: "Convolution567"
  type: "Convolution"
  bottom: "Convolution566"
  top: "Convolution567"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm567"
  type: "BatchNorm"
  bottom: "Convolution567"
  top: "Convolution567"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale567"
  type: "Scale"
  bottom: "Convolution567"
  top: "Convolution567"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU567"
  type: "ReLU"
  bottom: "Convolution567"
  top: "Convolution567"
}
layer {
  name: "Convolution568"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution568"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm568"
  type: "BatchNorm"
  bottom: "Convolution568"
  top: "Convolution568"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale568"
  type: "Scale"
  bottom: "Convolution568"
  top: "Convolution568"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU568"
  type: "ReLU"
  bottom: "Convolution568"
  top: "Convolution568"
}
layer {
  name: "Convolution569"
  type: "Convolution"
  bottom: "Convolution568"
  top: "Convolution569"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm569"
  type: "BatchNorm"
  bottom: "Convolution569"
  top: "Convolution569"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale569"
  type: "Scale"
  bottom: "Convolution569"
  top: "Convolution569"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU569"
  type: "ReLU"
  bottom: "Convolution569"
  top: "Convolution569"
}
layer {
  name: "Convolution570"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution570"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm570"
  type: "BatchNorm"
  bottom: "Convolution570"
  top: "Convolution570"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale570"
  type: "Scale"
  bottom: "Convolution570"
  top: "Convolution570"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU570"
  type: "ReLU"
  bottom: "Convolution570"
  top: "Convolution570"
}
layer {
  name: "Convolution571"
  type: "Convolution"
  bottom: "Convolution570"
  top: "Convolution571"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm571"
  type: "BatchNorm"
  bottom: "Convolution571"
  top: "Convolution571"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale571"
  type: "Scale"
  bottom: "Convolution571"
  top: "Convolution571"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU571"
  type: "ReLU"
  bottom: "Convolution571"
  top: "Convolution571"
}
layer {
  name: "Convolution572"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution572"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm572"
  type: "BatchNorm"
  bottom: "Convolution572"
  top: "Convolution572"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale572"
  type: "Scale"
  bottom: "Convolution572"
  top: "Convolution572"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU572"
  type: "ReLU"
  bottom: "Convolution572"
  top: "Convolution572"
}
layer {
  name: "Convolution573"
  type: "Convolution"
  bottom: "Convolution572"
  top: "Convolution573"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm573"
  type: "BatchNorm"
  bottom: "Convolution573"
  top: "Convolution573"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale573"
  type: "Scale"
  bottom: "Convolution573"
  top: "Convolution573"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU573"
  type: "ReLU"
  bottom: "Convolution573"
  top: "Convolution573"
}
layer {
  name: "Convolution574"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution574"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm574"
  type: "BatchNorm"
  bottom: "Convolution574"
  top: "Convolution574"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale574"
  type: "Scale"
  bottom: "Convolution574"
  top: "Convolution574"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU574"
  type: "ReLU"
  bottom: "Convolution574"
  top: "Convolution574"
}
layer {
  name: "Convolution575"
  type: "Convolution"
  bottom: "Convolution574"
  top: "Convolution575"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm575"
  type: "BatchNorm"
  bottom: "Convolution575"
  top: "Convolution575"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale575"
  type: "Scale"
  bottom: "Convolution575"
  top: "Convolution575"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU575"
  type: "ReLU"
  bottom: "Convolution575"
  top: "Convolution575"
}
layer {
  name: "Convolution576"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution576"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm576"
  type: "BatchNorm"
  bottom: "Convolution576"
  top: "Convolution576"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale576"
  type: "Scale"
  bottom: "Convolution576"
  top: "Convolution576"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU576"
  type: "ReLU"
  bottom: "Convolution576"
  top: "Convolution576"
}
layer {
  name: "Convolution577"
  type: "Convolution"
  bottom: "Convolution576"
  top: "Convolution577"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm577"
  type: "BatchNorm"
  bottom: "Convolution577"
  top: "Convolution577"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale577"
  type: "Scale"
  bottom: "Convolution577"
  top: "Convolution577"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU577"
  type: "ReLU"
  bottom: "Convolution577"
  top: "Convolution577"
}
layer {
  name: "Convolution578"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution578"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm578"
  type: "BatchNorm"
  bottom: "Convolution578"
  top: "Convolution578"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale578"
  type: "Scale"
  bottom: "Convolution578"
  top: "Convolution578"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU578"
  type: "ReLU"
  bottom: "Convolution578"
  top: "Convolution578"
}
layer {
  name: "Convolution579"
  type: "Convolution"
  bottom: "Convolution578"
  top: "Convolution579"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm579"
  type: "BatchNorm"
  bottom: "Convolution579"
  top: "Convolution579"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale579"
  type: "Scale"
  bottom: "Convolution579"
  top: "Convolution579"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU579"
  type: "ReLU"
  bottom: "Convolution579"
  top: "Convolution579"
}
layer {
  name: "Convolution580"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution580"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm580"
  type: "BatchNorm"
  bottom: "Convolution580"
  top: "Convolution580"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale580"
  type: "Scale"
  bottom: "Convolution580"
  top: "Convolution580"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU580"
  type: "ReLU"
  bottom: "Convolution580"
  top: "Convolution580"
}
layer {
  name: "Convolution581"
  type: "Convolution"
  bottom: "Convolution580"
  top: "Convolution581"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm581"
  type: "BatchNorm"
  bottom: "Convolution581"
  top: "Convolution581"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale581"
  type: "Scale"
  bottom: "Convolution581"
  top: "Convolution581"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU581"
  type: "ReLU"
  bottom: "Convolution581"
  top: "Convolution581"
}
layer {
  name: "Convolution582"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution582"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm582"
  type: "BatchNorm"
  bottom: "Convolution582"
  top: "Convolution582"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale582"
  type: "Scale"
  bottom: "Convolution582"
  top: "Convolution582"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU582"
  type: "ReLU"
  bottom: "Convolution582"
  top: "Convolution582"
}
layer {
  name: "Convolution583"
  type: "Convolution"
  bottom: "Convolution582"
  top: "Convolution583"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm583"
  type: "BatchNorm"
  bottom: "Convolution583"
  top: "Convolution583"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale583"
  type: "Scale"
  bottom: "Convolution583"
  top: "Convolution583"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU583"
  type: "ReLU"
  bottom: "Convolution583"
  top: "Convolution583"
}
layer {
  name: "Convolution584"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution584"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm584"
  type: "BatchNorm"
  bottom: "Convolution584"
  top: "Convolution584"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale584"
  type: "Scale"
  bottom: "Convolution584"
  top: "Convolution584"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU584"
  type: "ReLU"
  bottom: "Convolution584"
  top: "Convolution584"
}
layer {
  name: "Convolution585"
  type: "Convolution"
  bottom: "Convolution584"
  top: "Convolution585"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm585"
  type: "BatchNorm"
  bottom: "Convolution585"
  top: "Convolution585"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale585"
  type: "Scale"
  bottom: "Convolution585"
  top: "Convolution585"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU585"
  type: "ReLU"
  bottom: "Convolution585"
  top: "Convolution585"
}
layer {
  name: "Convolution586"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution586"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm586"
  type: "BatchNorm"
  bottom: "Convolution586"
  top: "Convolution586"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale586"
  type: "Scale"
  bottom: "Convolution586"
  top: "Convolution586"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU586"
  type: "ReLU"
  bottom: "Convolution586"
  top: "Convolution586"
}
layer {
  name: "Convolution587"
  type: "Convolution"
  bottom: "Convolution586"
  top: "Convolution587"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm587"
  type: "BatchNorm"
  bottom: "Convolution587"
  top: "Convolution587"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale587"
  type: "Scale"
  bottom: "Convolution587"
  top: "Convolution587"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU587"
  type: "ReLU"
  bottom: "Convolution587"
  top: "Convolution587"
}
layer {
  name: "Convolution588"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution588"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm588"
  type: "BatchNorm"
  bottom: "Convolution588"
  top: "Convolution588"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale588"
  type: "Scale"
  bottom: "Convolution588"
  top: "Convolution588"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU588"
  type: "ReLU"
  bottom: "Convolution588"
  top: "Convolution588"
}
layer {
  name: "Convolution589"
  type: "Convolution"
  bottom: "Convolution588"
  top: "Convolution589"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm589"
  type: "BatchNorm"
  bottom: "Convolution589"
  top: "Convolution589"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale589"
  type: "Scale"
  bottom: "Convolution589"
  top: "Convolution589"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU589"
  type: "ReLU"
  bottom: "Convolution589"
  top: "Convolution589"
}
layer {
  name: "Convolution590"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution590"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm590"
  type: "BatchNorm"
  bottom: "Convolution590"
  top: "Convolution590"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale590"
  type: "Scale"
  bottom: "Convolution590"
  top: "Convolution590"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU590"
  type: "ReLU"
  bottom: "Convolution590"
  top: "Convolution590"
}
layer {
  name: "Convolution591"
  type: "Convolution"
  bottom: "Convolution590"
  top: "Convolution591"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm591"
  type: "BatchNorm"
  bottom: "Convolution591"
  top: "Convolution591"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale591"
  type: "Scale"
  bottom: "Convolution591"
  top: "Convolution591"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU591"
  type: "ReLU"
  bottom: "Convolution591"
  top: "Convolution591"
}
layer {
  name: "Convolution592"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution592"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm592"
  type: "BatchNorm"
  bottom: "Convolution592"
  top: "Convolution592"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale592"
  type: "Scale"
  bottom: "Convolution592"
  top: "Convolution592"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU592"
  type: "ReLU"
  bottom: "Convolution592"
  top: "Convolution592"
}
layer {
  name: "Convolution593"
  type: "Convolution"
  bottom: "Convolution592"
  top: "Convolution593"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm593"
  type: "BatchNorm"
  bottom: "Convolution593"
  top: "Convolution593"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale593"
  type: "Scale"
  bottom: "Convolution593"
  top: "Convolution593"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU593"
  type: "ReLU"
  bottom: "Convolution593"
  top: "Convolution593"
}
layer {
  name: "Concat9"
  type: "Concat"
  bottom: "Convolution531"
  bottom: "Convolution533"
  bottom: "Convolution535"
  bottom: "Convolution537"
  bottom: "Convolution539"
  bottom: "Convolution541"
  bottom: "Convolution543"
  bottom: "Convolution545"
  bottom: "Convolution547"
  bottom: "Convolution549"
  bottom: "Convolution551"
  bottom: "Convolution553"
  bottom: "Convolution555"
  bottom: "Convolution557"
  bottom: "Convolution559"
  bottom: "Convolution561"
  bottom: "Convolution563"
  bottom: "Convolution565"
  bottom: "Convolution567"
  bottom: "Convolution569"
  bottom: "Convolution571"
  bottom: "Convolution573"
  bottom: "Convolution575"
  bottom: "Convolution577"
  bottom: "Convolution579"
  bottom: "Convolution581"
  bottom: "Convolution583"
  bottom: "Convolution585"
  bottom: "Convolution587"
  bottom: "Convolution589"
  bottom: "Convolution591"
  bottom: "Convolution593"
  top: "Concat9"
}
layer {
  name: "Convolution594"
  type: "Convolution"
  bottom: "Concat9"
  top: "Convolution594"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm594"
  type: "BatchNorm"
  bottom: "Convolution594"
  top: "Convolution594"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale594"
  type: "Scale"
  bottom: "Convolution594"
  top: "Convolution594"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU594"
  type: "ReLU"
  bottom: "Convolution594"
  top: "Convolution594"
}
layer {
  name: "Convolution595"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution595"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm595"
  type: "BatchNorm"
  bottom: "Convolution595"
  top: "Convolution595"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale595"
  type: "Scale"
  bottom: "Convolution595"
  top: "Convolution595"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU595"
  type: "ReLU"
  bottom: "Convolution595"
  top: "Convolution595"
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Convolution594"
  bottom: "Convolution595"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "Accuracy1"
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
